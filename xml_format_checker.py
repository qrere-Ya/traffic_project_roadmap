#!/usr/bin/env python3
# debug_fusion_files.py - èåˆæª”æ¡ˆè¨ºæ–·è…³æœ¬

"""
èåˆæª”æ¡ˆè¨ºæ–·å·¥å…·
================

æª¢æŸ¥èåˆæ•¸æ“šæª”æ¡ˆçš„è©³ç´°ç‹€æ³
å¹«åŠ©è¨ºæ–·æ¸¬è©¦å¤±æ•—çš„åŸå› 

ä½¿ç”¨æ–¹å¼ï¼š
python debug_fusion_files.py
"""

import pandas as pd
from pathlib import Path

def diagnose_fusion_files():
    """è¨ºæ–·èåˆæª”æ¡ˆç‹€æ³"""
    print("ğŸ” èåˆæª”æ¡ˆè¨ºæ–·é–‹å§‹")
    print("=" * 40)
    
    fusion_folder = Path("data/processed/fusion")
    
    if not fusion_folder.exists():
        print("âŒ èåˆè³‡æ–™å¤¾ä¸å­˜åœ¨")
        return
    
    date_folders = [d for d in fusion_folder.iterdir() 
                   if d.is_dir() and len(d.name.split('-')) == 3]
    
    if not date_folders:
        print("âŒ æ²’æœ‰æ‰¾åˆ°æ—¥æœŸè³‡æ–™å¤¾")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(date_folders)} å€‹æ—¥æœŸè³‡æ–™å¤¾")
    
    # è©³ç´°æª¢æŸ¥æ¯å€‹è³‡æ–™å¤¾
    for i, date_folder in enumerate(date_folders):
        print(f"\nğŸ“… æª¢æŸ¥ {date_folder.name} ({i+1}/{len(date_folders)})")
        print("-" * 30)
        
        # æª¢æŸ¥æª”æ¡ˆå­˜åœ¨æ€§
        files = {
            'vd_etag_aligned.csv': 'æ™‚ç©ºå°é½Šæ•¸æ“š',
            'fusion_features.csv': 'èåˆç‰¹å¾µæ•¸æ“š',
            'fusion_quality.json': 'èåˆå“è³ªå ±å‘Š',
            'alignment_summary.json': 'å°é½Šæ‘˜è¦'
        }
        
        for filename, description in files.items():
            file_path = date_folder / filename
            if file_path.exists():
                file_size = file_path.stat().st_size / 1024  # KB
                print(f"   âœ… {filename}: {file_size:.1f}KB - {description}")
                
                # è©³ç´°æª¢æŸ¥CSVæª”æ¡ˆ
                if filename.endswith('.csv'):
                    try:
                        df = pd.read_csv(file_path, nrows=3)
                        print(f"      ğŸ“Š {len(df)} ç­†æ¨£æœ¬, {len(df.columns)} æ¬„ä½")
                        print(f"      ğŸ·ï¸ æ¬„ä½: {list(df.columns)[:5]}...")  # é¡¯ç¤ºå‰5å€‹æ¬„ä½
                        
                        # æª¢æŸ¥ç‰¹å®šé‡è¦æ¬„ä½
                        if filename == 'fusion_features.csv':
                            important_cols = ['datetime', 'speed_mean', 'region', 'etag_pair']
                            missing_important = [col for col in important_cols if col not in df.columns]
                            if missing_important:
                                print(f"      âš ï¸ ç¼ºå°‘é‡è¦æ¬„ä½: {missing_important}")
                            else:
                                print(f"      âœ… é‡è¦æ¬„ä½å®Œæ•´")
                                
                    except Exception as e:
                        print(f"      âŒ è®€å–å¤±æ•—: {e}")
                        
            else:
                print(f"   âŒ {filename}: ä¸å­˜åœ¨ - {description}")
    
    # æ¯”è¼ƒæ‰€æœ‰èåˆç‰¹å¾µæª”æ¡ˆçš„çµæ§‹
    print(f"\nğŸ“‹ èåˆç‰¹å¾µæª”æ¡ˆçµæ§‹æ¯”è¼ƒ")
    print("=" * 40)
    
    feature_files = []
    for date_folder in date_folders:
        feature_file = date_folder / 'fusion_features.csv'
        if feature_file.exists():
            try:
                df = pd.read_csv(feature_file, nrows=1)
                feature_files.append({
                    'date': date_folder.name,
                    'columns': len(df.columns),
                    'column_names': list(df.columns),
                    'file_size': feature_file.stat().st_size / 1024
                })
            except Exception as e:
                print(f"âŒ {date_folder.name}: è®€å–å¤±æ•— - {e}")
    
    if feature_files:
        # åˆ†ææ¬„ä½æ•¸é‡åˆ†å¸ƒ
        column_counts = [f['columns'] for f in feature_files]
        unique_counts = set(column_counts)
        
        print(f"ğŸ“Š æ¬„ä½æ•¸é‡åˆ†å¸ƒ:")
        for count in sorted(unique_counts):
            dates_with_count = [f['date'] for f in feature_files if f['columns'] == count]
            print(f"   {count} æ¬„ä½: {len(dates_with_count)} æª”æ¡ˆ - {dates_with_count}")
        
        # æª¢æŸ¥æ¬„ä½å·®ç•°
        if len(unique_counts) > 1:
            print(f"\nğŸ” æ¬„ä½å·®ç•°åˆ†æ:")
            
            # æ‰¾å‡ºæœ€å¸¸è¦‹çš„æ¬„ä½æ•¸é‡
            from collections import Counter
            count_freq = Counter(column_counts)
            most_common_count = count_freq.most_common(1)[0][0]
            
            print(f"   æœ€å¸¸è¦‹æ¬„ä½æ•¸: {most_common_count}")
            
            # æ¯”è¼ƒæ¬„ä½å·®ç•°
            reference_file = next(f for f in feature_files if f['columns'] == most_common_count)
            reference_cols = set(reference_file['column_names'])
            
            for f in feature_files:
                if f['columns'] != most_common_count:
                    current_cols = set(f['column_names'])
                    extra_cols = current_cols - reference_cols
                    missing_cols = reference_cols - current_cols
                    
                    print(f"   {f['date']} ({f['columns']} æ¬„ä½):")
                    if extra_cols:
                        print(f"      é¡å¤–æ¬„ä½: {list(extra_cols)[:3]}...")
                    if missing_cols:
                        print(f"      ç¼ºå°‘æ¬„ä½: {list(missing_cols)[:3]}...")
        
        # æª”æ¡ˆå¤§å°åˆ†æ
        print(f"\nğŸ’¾ æª”æ¡ˆå¤§å°åˆ†æ:")
        file_sizes = [f['file_size'] for f in feature_files]
        avg_size = sum(file_sizes) / len(file_sizes)
        min_size = min(file_sizes)
        max_size = max(file_sizes)
        
        print(f"   å¹³å‡å¤§å°: {avg_size:.1f}KB")
        print(f"   å¤§å°ç¯„åœ: {min_size:.1f}KB - {max_size:.1f}KB")
        
        # æª¢æŸ¥ç•°å¸¸æª”æ¡ˆ
        for f in feature_files:
            if f['file_size'] < avg_size * 0.5:  # å°æ–¼å¹³å‡ä¸€åŠ
                print(f"   âš ï¸ {f['date']}: æª”æ¡ˆéå° ({f['file_size']:.1f}KB)")
            elif f['file_size'] > avg_size * 2:  # å¤§æ–¼å¹³å‡å…©å€
                print(f"   âš ï¸ {f['date']}: æª”æ¡ˆéå¤§ ({f['file_size']:.1f}KB)")
    
    # ç¸½çµ
    print(f"\nğŸ“‹ è¨ºæ–·ç¸½çµ")
    print("=" * 40)
    
    total_expected = len(date_folders) * 4  # æ¯å€‹æ—¥æœŸ4å€‹æª”æ¡ˆ
    total_existing = sum(len([f for f in date_folder.iterdir() if f.is_file()]) 
                        for date_folder in date_folders)
    
    print(f"ğŸ“ è³‡æ–™å¤¾æ•¸é‡: {len(date_folders)}")
    print(f"ğŸ“„ æª”æ¡ˆå®Œæ•´æ€§: {total_existing}/{total_expected}")
    print(f"ğŸ¯ èåˆç‰¹å¾µæª”æ¡ˆ: {len(feature_files)}/{len(date_folders)}")
    
    if len(feature_files) == len(date_folders):
        print(f"âœ… æ‰€æœ‰èåˆç‰¹å¾µæª”æ¡ˆéƒ½å­˜åœ¨")
        
        if len(unique_counts) == 1:
            print(f"âœ… æ‰€æœ‰æª”æ¡ˆæ¬„ä½æ•¸é‡ä¸€è‡´ ({list(unique_counts)[0]} æ¬„ä½)")
        else:
            print(f"âš ï¸ æª”æ¡ˆæ¬„ä½æ•¸é‡ä¸ä¸€è‡´: {sorted(unique_counts)}")
            print(f"ğŸ’¡ é€™é€šå¸¸æ˜¯æ­£å¸¸çš„ï¼Œç¬¬ä¸€å€‹æª”æ¡ˆå¯èƒ½åŒ…å«é¡å¤–èª¿è©¦æ¬„ä½")
        
        print(f"ğŸ‰ èåˆæ•¸æ“šç”ŸæˆæˆåŠŸï¼")
    else:
        missing_count = len(date_folders) - len(feature_files)
        print(f"âŒ ç¼ºå°‘ {missing_count} å€‹èåˆç‰¹å¾µæª”æ¡ˆ")
        
        missing_dates = [d.name for d in date_folders 
                        if not (d / 'fusion_features.csv').exists()]
        print(f"ğŸ“… ç¼ºå°‘çš„æ—¥æœŸ: {missing_dates}")


if __name__ == "__main__":
    diagnose_fusion_files()