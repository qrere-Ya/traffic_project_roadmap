# test_loader.py - ç°¡åŒ–ç‰ˆ

"""
VDæ•¸æ“šè¼‰å…¥å™¨æ¸¬è©¦ç¨‹å¼ - ç°¡åŒ–ç‰ˆ
==========================================

æ¸¬è©¦é‡é»ï¼š
1. å°ˆæ³¨Rawæ•¸æ“šè™•ç†æ¸¬è©¦
2. å¾Œå°è¨˜æ†¶é«”å„ªåŒ–ï¼ˆä¸é¡¯ç¤ºè©³ç´°ä¿¡æ¯ï¼‰
3. æ™ºæ…§Archiveæª¢æŸ¥æ¸¬è©¦
4. ä¿ç•™æ‰€æœ‰åŸæœ¬æ¸¬è©¦åŠŸèƒ½ï¼Œç°¡åŒ–è¼¸å‡º

æ ¸å¿ƒç‰¹è‰²ï¼š
1. ä¸€æ¬¡æ€§è™•ç†rawæ‰€æœ‰æª”æ¡ˆï¼ŒæŒ‰æ—¥æœŸåˆ†é¡
2. 3-5åˆ†é˜è™•ç†1åƒè¬ç­†è¨˜éŒ„
3. è‡ªå‹•åˆ†é¡ä¸¦ç”Ÿæˆ6ç¨®æª”æ¡ˆï¼ˆæ¯å€‹æ—¥æœŸè³‡æ–™å¤¾ï¼‰
4. æ”¯æ´æŒ‡å®šæ—¥æœŸå’Œå…¨æ—¥æœŸè¼‰å…¥
5. ğŸ’¾ å¾Œå°è¨˜æ†¶é«”å„ªåŒ–ï¼šéœé»˜ç®¡ç†
6. ğŸ“‚ ç°¡æ½”æ¸¬è©¦è¼¸å‡ºï¼šå°ˆæ³¨ä¸»è¦åŠŸèƒ½
"""

import sys
import os
import time
from pathlib import Path
import pandas as pd
from datetime import datetime, timedelta
import psutil
import gc

# æ·»åŠ srcç›®éŒ„åˆ°Pythonè·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

try:
    from data_loader import VDDataLoader
except ImportError:
    print("âŒ ç„¡æ³•å°å…¥VDDataLoaderï¼Œè«‹ç¢ºèªæª”æ¡ˆä½ç½®")
    sys.exit(1)


def test_simplified_initialization():
    """æ¸¬è©¦1: ç°¡åŒ–ç‰ˆåˆå§‹åŒ–æ¸¬è©¦"""
    print("ğŸ§ª æ¸¬è©¦1: ç°¡åŒ–ç‰ˆåˆå§‹åŒ–æ¸¬è©¦")
    print("-" * 50)
    
    # æ¸¬è©¦éœé»˜åˆå§‹åŒ–
    loader = VDDataLoader(verbose=False)
    
    print(f"âœ… ç°¡åŒ–ç‰ˆåˆå§‹åŒ–æˆåŠŸ")
    print(f"   ğŸ“ åŸºç¤è³‡æ–™å¤¾: {loader.base_folder}")
    print(f"   ğŸ§µ è™•ç†ç·šç¨‹: {loader.max_workers}")
    print(f"   ğŸ’¾ æ‰¹æ¬¡å¤§å°: {loader.internal_batch_size}")
    print(f"   ğŸ¯ ç›®æ¨™è·¯æ®µ: {len(loader.target_route_vd_ids)}å€‹")
    
    # æ¸¬è©¦è©³ç´°æ¨¡å¼
    print(f"\nğŸ” æ¸¬è©¦è©³ç´°æ¨¡å¼:")
    loader_verbose = VDDataLoader(verbose=True)
    print(f"   âœ… è©³ç´°æ¨¡å¼åˆå§‹åŒ–æˆåŠŸ")
    
    return True


def test_archive_check_simplified():
    """æ¸¬è©¦2: ç°¡åŒ–Archiveæª¢æŸ¥æ¸¬è©¦"""
    print("\nğŸ§ª æ¸¬è©¦2: ç°¡åŒ–Archiveæª¢æŸ¥æ¸¬è©¦")
    print("-" * 50)
    
    loader = VDDataLoader()
    
    print("ğŸ“‚ æ¸¬è©¦éœé»˜Archiveæª¢æŸ¥:")
    start_time = time.time()
    
    # éœé»˜Archiveæª¢æŸ¥
    archive_status = loader.check_archive_status_silent()
    check_time = time.time() - start_time
    
    print(f"   â±ï¸ Archiveæª¢æŸ¥æ™‚é–“: {check_time:.3f} ç§’")
    print(f"   ğŸ“Š æª¢æŸ¥çµæœ:")
    print(f"      â€¢ Archiveå­˜åœ¨: {'âœ…' if archive_status['archive_exists'] else 'âŒ'}")
    print(f"      â€¢ å·²æ­¸æª”æ—¥æœŸ: {archive_status['archived_date_count']} å€‹")
    
    if archive_status['archived_dates']:
        print(f"      â€¢ æ—¥æœŸç¯„åœ: {archive_status['archived_dates'][0]} ~ {archive_status['archived_dates'][-1]}")
        print(f"   ğŸ¯ å„ªå‹¢: ä¸è®€å–æª”æ¡ˆå…§å®¹ï¼Œåªæª¢æŸ¥è³‡æ–™å¤¾å­˜åœ¨æ€§")
    
    return True


def test_raw_folder_check_simplified():
    """æ¸¬è©¦3: ç°¡åŒ–Rawè³‡æ–™å¤¾æª¢æŸ¥æ¸¬è©¦"""
    print("\nğŸ§ª æ¸¬è©¦3: ç°¡åŒ–Rawè³‡æ–™å¤¾æª¢æŸ¥æ¸¬è©¦")
    print("-" * 50)
    
    loader = VDDataLoader()
    
    print("ğŸ” æ¸¬è©¦ç°¡åŒ–Rawè³‡æ–™å¤¾æª¢æŸ¥:")
    start_time = time.time()
    
    # ç°¡åŒ–Rawæª¢æŸ¥
    folder_status = loader.check_raw_folder()
    check_time = time.time() - start_time
    
    print(f"   â±ï¸ Rawæª¢æŸ¥æ™‚é–“: {check_time:.3f} ç§’")
    print(f"   ğŸ“Š æª¢æ¸¬çµæœ:")
    print(f"      â€¢ è³‡æ–™å¤¾å­˜åœ¨: {'âœ…' if folder_status['exists'] else 'âŒ'}")
    print(f"      â€¢ VDæª”æ¡ˆæ•¸: {folder_status['vd_files']}")
    print(f"      â€¢ å¾…è™•ç†æª”æ¡ˆ: {folder_status['unprocessed']}")
    print(f"      â€¢ å·²æ­¸æª”æ—¥æœŸ: {folder_status['archived_dates']}")
    
    if folder_status['unprocessed'] > 0:
        estimated_minutes = folder_status['unprocessed'] * 0.005
        print(f"      â€¢ é ä¼°è™•ç†æ™‚é–“: {estimated_minutes:.1f} åˆ†é˜")
        print(f"   ğŸ¯ ç‰¹è‰²: å°ˆæ³¨ä¸»è¦ä¿¡æ¯ï¼Œå¾Œå°è‡ªå‹•è¨˜æ†¶é«”å„ªåŒ–")
    
    return True


def test_date_folder_detection_simplified():
    """æ¸¬è©¦4: ç°¡åŒ–æ—¥æœŸè³‡æ–™å¤¾æª¢æ¸¬"""
    print("\nğŸ§ª æ¸¬è©¦4: ç°¡åŒ–æ—¥æœŸè³‡æ–™å¤¾æª¢æ¸¬")
    print("-" * 50)
    
    loader = VDDataLoader()
    
    # æª¢æ¸¬ç¾æœ‰æ—¥æœŸè³‡æ–™å¤¾
    available_dates = loader.list_available_dates()
    
    print(f"ğŸ“… æª¢æ¸¬çµæœ:")
    if available_dates:
        print(f"   â€¢ å¯ç”¨æ—¥æœŸ: {len(available_dates)} å€‹")
        print(f"   â€¢ æ—¥æœŸç¯„åœ: {available_dates[0]} ~ {available_dates[-1]}")
        
        # é¡¯ç¤ºå‰å¹¾å€‹æ—¥æœŸ
        for date_str in available_dates[:3]:
            print(f"      - {date_str}")
        if len(available_dates) > 3:
            print(f"      - ... ä»¥åŠå…¶ä»– {len(available_dates) - 3} å€‹æ—¥æœŸ")
    else:
        print(f"   âš ï¸ æ²’æœ‰æ‰¾åˆ°æ—¥æœŸè³‡æ–™å¤¾")
    
    # ç°¡åŒ–æ—¥æœŸæ‘˜è¦
    if available_dates:
        print(f"\nğŸ“Š ç”Ÿæˆç°¡åŒ–æ—¥æœŸæ‘˜è¦:")
        try:
            start_time = time.time()
            date_summary = loader.get_date_summary()
            summary_time = time.time() - start_time
            
            print(f"   â±ï¸ æ‘˜è¦ç”Ÿæˆæ™‚é–“: {summary_time:.3f} ç§’")
            
            total_dates = date_summary["ç¸½è¦½"]["å¯ç”¨æ—¥æœŸæ•¸"]
            total_records = date_summary["ç¸½è¦½"]["ç¸½è¨˜éŒ„æ•¸"]
            date_range = date_summary["ç¸½è¦½"]["æ—¥æœŸç¯„åœ"]
            
            print(f"   ğŸ“Š æ‘˜è¦çµæœ:")
            print(f"      â€¢ å¯ç”¨æ—¥æœŸæ•¸: {total_dates}")
            print(f"      â€¢ ç¸½è¨˜éŒ„æ•¸: {total_records:,}")
            print(f"      â€¢ æ—¥æœŸç¯„åœ: {date_range['æœ€æ—©']} ~ {date_range['æœ€æ™š']}")
            
            return True
            
        except Exception as e:
            print(f"   âŒ æ—¥æœŸæ‘˜è¦ç”Ÿæˆå¤±æ•—: {e}")
            return False
    
    return True


def test_vectorized_performance_simplified():
    """æ¸¬è©¦5: ç°¡åŒ–å‘é‡åŒ–æ•ˆèƒ½æ¸¬è©¦"""
    print("\nğŸ§ª æ¸¬è©¦5: ç°¡åŒ–å‘é‡åŒ–æ•ˆèƒ½æ¸¬è©¦")
    print("-" * 50)
    
    loader = VDDataLoader()
    
    print("âš¡ å‘é‡åŒ–åˆ†é¡æ•ˆèƒ½æ¸¬è©¦:")
    
    # å»ºç«‹æ¸¬è©¦æ•¸æ“š
    test_size = 100000
    test_times = []
    
    base_date = datetime(2025, 6, 23)
    for day in range(7):
        current_date = base_date + timedelta(days=day)
        for hour in range(24):
            for minute in range(0, 60, 10):
                test_times.append(current_date.replace(hour=hour, minute=minute))
                if len(test_times) >= test_size:
                    break
            if len(test_times) >= test_size:
                break
        if len(test_times) >= test_size:
            break
    
    time_series = pd.Series(test_times)
    
    # æ¸¬è©¦æ™‚é–“åˆ†é¡
    start_time = time.time()
    result_series = loader.classify_peak_hours_vectorized(time_series)
    process_time = time.time() - start_time
    
    print(f"   ğŸ“Š æ™‚é–“åˆ†é¡æ¸¬è©¦:")
    print(f"      â€¢ è™•ç†è¨˜éŒ„: {len(time_series):,}")
    print(f"      â€¢ è™•ç†æ™‚é–“: {process_time:.4f} ç§’")
    print(f"      â€¢ è™•ç†é€Ÿåº¦: {len(time_series)/process_time:,.0f} è¨˜éŒ„/ç§’")
    
    # æª¢æŸ¥çµæœ
    peak_count = result_series.str.contains('å°–å³°').sum()
    print(f"      â€¢ å°–å³°æ¯”ä¾‹: {peak_count/len(result_series)*100:.1f}%")
    
    # æ¸…ç†æ¸¬è©¦æ•¸æ“š
    del time_series, result_series
    
    # æ¸¬è©¦è·¯æ®µåˆ†é¡
    target_vd_ids = loader.target_route_vd_ids
    non_target_vd_ids = ['VD-N3-N-25-O-SE-1-æœ¨æŸµä¼‘æ¯ç«™', 'VD-N2-S-100.5-M-MAIN']
    
    test_vd_ids = (target_vd_ids * (test_size // (len(target_vd_ids) * 2)) + 
                   non_target_vd_ids * (test_size // (len(non_target_vd_ids) * 2)))[:test_size]
    
    vd_series = pd.Series(test_vd_ids)
    
    start_time = time.time()
    route_result = loader.is_target_route_vectorized(vd_series)
    process_time = time.time() - start_time
    
    print(f"   ğŸ›£ï¸ è·¯æ®µåˆ†é¡æ¸¬è©¦:")
    print(f"      â€¢ è™•ç†è¨˜éŒ„: {len(vd_series):,}")
    print(f"      â€¢ è™•ç†æ™‚é–“: {process_time:.4f} ç§’")
    print(f"      â€¢ è™•ç†é€Ÿåº¦: {len(vd_series)/process_time:,.0f} è¨˜éŒ„/ç§’")
    
    target_count = route_result.sum()
    print(f"      â€¢ ç›®æ¨™è·¯æ®µæ¯”ä¾‹: {target_count/len(route_result)*100:.1f}%")
    
    # æ¸…ç†æ¸¬è©¦æ•¸æ“š
    del vd_series, route_result
    
    print(f"   âœ… å‘é‡åŒ–æ•ˆèƒ½æ¸¬è©¦å®Œæˆ")
    return True


def test_data_loading_simplified():
    """æ¸¬è©¦6: ç°¡åŒ–æ•¸æ“šè¼‰å…¥æ¸¬è©¦"""
    print("\nğŸ§ª æ¸¬è©¦6: ç°¡åŒ–æ•¸æ“šè¼‰å…¥æ¸¬è©¦")
    print("-" * 50)
    
    loader = VDDataLoader()
    
    # ç²å–å¯ç”¨æ—¥æœŸ
    available_dates = loader.list_available_dates()
    
    if not available_dates:
        print("âš ï¸ æ²’æœ‰å¯ç”¨çš„æ—¥æœŸè³‡æ–™å¤¾ï¼Œè·³éè¼‰å…¥æ¸¬è©¦")
        return True
    
    print(f"ğŸ“… å¯ç”¨æ—¥æœŸ: {len(available_dates)} å€‹")
    
    # æ¸¬è©¦è¼‰å…¥ç‰¹å®šæ—¥æœŸ
    test_date = available_dates[0]
    print(f"\nğŸ¯ æ¸¬è©¦è¼‰å…¥ {test_date} æ•¸æ“š...")
    
    try:
        start_time = time.time()
        classified_data = loader.load_classified_data(target_date=test_date)
        load_time = time.time() - start_time
        
        print(f"   â±ï¸ è¼‰å…¥æ™‚é–“: {load_time:.3f} ç§’")
        
        # ç°¡åŒ–çµæœé¡¯ç¤º
        file_types = ['all', 'peak', 'offpeak', 'target_route', 'target_route_peak', 'target_route_offpeak']
        total_records = 0
        
        for file_type in file_types:
            df = classified_data.get(file_type, pd.DataFrame())
            if not df.empty:
                total_records += len(df)
        
        print(f"   ğŸ“Š è¼‰å…¥çµæœ:")
        print(f"      â€¢ ç¸½è¨˜éŒ„æ•¸: {total_records:,}")
        print(f"      â€¢ æª”æ¡ˆé¡å‹: {len([k for k, v in classified_data.items() if not v.empty])} ç¨®")
        
        # æ¸…ç†è¼‰å…¥çš„æ•¸æ“š
        del classified_data
        
        # æ¸¬è©¦è¼‰å…¥æ‰€æœ‰æ—¥æœŸï¼ˆå¦‚æœæœ‰å¤šå€‹æ—¥æœŸï¼‰
        if len(available_dates) > 1:
            print(f"\nğŸ”„ æ¸¬è©¦è¼‰å…¥æ‰€æœ‰æ—¥æœŸæ•¸æ“š...")
            
            start_time = time.time()
            all_data = loader.load_classified_data()
            load_time = time.time() - start_time
            
            print(f"   â±ï¸ åˆä½µè¼‰å…¥æ™‚é–“: {load_time:.3f} ç§’")
            
            combined_total = 0
            for file_type in file_types:
                df = all_data.get(file_type, pd.DataFrame())
                if not df.empty:
                    combined_total += len(df)
            
            print(f"   ğŸ“Š åˆä½µçµæœ:")
            print(f"      â€¢ ç¸½è¨˜éŒ„æ•¸: {combined_total:,}")
            print(f"      â€¢ æ¶µè“‹æ—¥æœŸ: {len(available_dates)} å€‹")
            
            # æ¸…ç†åˆä½µæ•¸æ“š
            del all_data
        
        return True
        
    except Exception as e:
        print(f"   âŒ æ•¸æ“šè¼‰å…¥æ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_raw_processing_simplified():
    """æ¸¬è©¦7: ç°¡åŒ–Rawè™•ç†æ¸¬è©¦"""
    print("\nğŸ§ª æ¸¬è©¦7: ç°¡åŒ–Rawè™•ç†æ¸¬è©¦")
    print("-" * 50)
    
    loader = VDDataLoader()
    
    # æª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™
    folder_status = loader.check_raw_folder()
    
    if not folder_status["exists"]:
        print("âš ï¸ rawè³‡æ–™å¤¾ä¸å­˜åœ¨ï¼Œè·³éRawè™•ç†æ¸¬è©¦")
        return True
    
    if folder_status["unprocessed"] == 0:
        print("â„¹ï¸ ç„¡å¾…è™•ç†æª”æ¡ˆï¼Œæ¸¬è©¦è¼‰å…¥ç¾æœ‰æ•¸æ“š")
        
        # æ¸¬è©¦å¿«é€Ÿè¼‰å…¥
        available_dates = loader.list_available_dates()
        
        if available_dates:
            print(f"ğŸ“… ç™¼ç¾ {len(available_dates)} å€‹æ—¥æœŸè³‡æ–™å¤¾")
            
            # æ¸¬è©¦è¼‰å…¥ç‰¹å®šæ—¥æœŸ
            test_date = available_dates[0]
            print(f"   ğŸ¯ æ¸¬è©¦å¿«é€Ÿè¼‰å…¥ {test_date}...")
            
            start_time = time.time()
            date_data = loader.quick_load_existing_data(target_date=test_date)
            load_time = time.time() - start_time
            
            if not date_data.empty:
                print(f"   âœ… è¼‰å…¥æˆåŠŸ: {len(date_data):,} ç­†è¨˜éŒ„")
                print(f"   â±ï¸ è¼‰å…¥æ™‚é–“: {load_time:.3f} ç§’")
                print(f"   ğŸš€ è¼‰å…¥é€Ÿåº¦: {len(date_data)/load_time:,.0f} è¨˜éŒ„/ç§’")
                
                # æ¸…ç†æ•¸æ“š
                del date_data
        else:
            print("âš ï¸ ç„¡æ—¥æœŸè³‡æ–™å¤¾")
        
        return True
    
    else:
        print(f"ğŸš€ ç™¼ç¾ {folder_status['unprocessed']} å€‹å¾…è™•ç†æª”æ¡ˆ")
        print("ç°¡åŒ–ç‰ˆRawè™•ç†ç‰¹è‰²ï¼š")
        print("   â€¢ å°ˆæ³¨Rawæ•¸æ“šè™•ç†é€²åº¦é¡¯ç¤º")
        print("   â€¢ å¾Œå°è‡ªå‹•è¨˜æ†¶é«”å„ªåŒ–")
        print("   â€¢ æ™ºæ…§Archiveæª¢æŸ¥é¿å…é‡è¤‡")
        print("   â€¢ æŒ‰æ—¥æœŸçµ„ç¹”è¼¸å‡º")
        
        estimated_minutes = folder_status['unprocessed'] * 0.005
        estimated_records = folder_status['unprocessed'] * 1500
        
        print(f"\né ä¼°ï¼š")
        print(f"   â±ï¸ è™•ç†æ™‚é–“: {estimated_minutes:.1f} åˆ†é˜")
        print(f"   ğŸ“Š é ä¼°è¨˜éŒ„: {estimated_records:,} ç­†")
        print(f"   ğŸ“ è¼¸å‡º: data/processed/YYYY-MM-DD/")
        
        response = input("æ˜¯å¦é€²è¡Œç°¡åŒ–ç‰ˆRawè™•ç†æ¸¬è©¦ï¼Ÿ(y/N): ")
        
        if response.lower() in ['y', 'yes']:
            print("\nğŸš€ é–‹å§‹ç°¡åŒ–ç‰ˆRawè™•ç†æ¸¬è©¦...")
            
            start_time = time.time()
            df = loader.process_all_files()
            process_time = time.time() - start_time
            
            print(f"\nğŸ“Š ç°¡åŒ–ç‰ˆè™•ç†çµæœ:")
            print(f"   â±ï¸ ç¸½æ™‚é–“: {process_time/60:.2f} åˆ†é˜")
            
            if not df.empty:
                print(f"   âœ… è™•ç†æˆåŠŸ")
                print(f"   ğŸ“Š ç¸½è¨˜éŒ„æ•¸: {len(df):,}")
                print(f"   ğŸš€ è™•ç†é€Ÿåº¦: {len(df)/(process_time/60):,.0f} è¨˜éŒ„/åˆ†é˜")
                
                # æª¢æŸ¥æ—¥æœŸè³‡æ–™å¤¾
                available_dates = loader.list_available_dates()
                print(f"   ğŸ“… å»ºç«‹æ—¥æœŸè³‡æ–™å¤¾: {len(available_dates)} å€‹")
                
                # æ¸…ç†ä¸»æ•¸æ“š
                del df
                
                return True
            else:
                print("   âŒ è™•ç†å¤±æ•—")
                return False
        else:
            print("è·³éç°¡åŒ–ç‰ˆRawè™•ç†æ¸¬è©¦")
            return True


def test_convenience_functions_simplified():
    """æ¸¬è©¦8: ç°¡åŒ–ä¾¿åˆ©å‡½æ•¸æ¸¬è©¦"""
    print("\nğŸ§ª æ¸¬è©¦8: ç°¡åŒ–ä¾¿åˆ©å‡½æ•¸æ¸¬è©¦")
    print("-" * 50)
    
    try:
        from data_loader import (
            process_all_files_one_shot, 
            load_classified_data_quick, 
            get_date_summary_quick
        )
        
        print("ğŸ”§ æ¸¬è©¦ä¾¿åˆ©å‡½æ•¸å°å…¥...")
        print("   âœ… æˆåŠŸå°å…¥æ‰€æœ‰ä¾¿åˆ©å‡½æ•¸")
        
        # æ¸¬è©¦æ—¥æœŸæ‘˜è¦ä¾¿åˆ©å‡½æ•¸
        print("\nğŸ“Š æ¸¬è©¦æ—¥æœŸæ‘˜è¦ä¾¿åˆ©å‡½æ•¸...")
        
        start_time = time.time()
        summary = get_date_summary_quick()
        summary_time = time.time() - start_time
        
        if summary and "ç¸½è¦½" in summary:
            total_dates = summary["ç¸½è¦½"]["å¯ç”¨æ—¥æœŸæ•¸"]
            print(f"   âœ… get_date_summary_quick(): {total_dates} å€‹æ—¥æœŸ")
            print(f"   â±ï¸ åŸ·è¡Œæ™‚é–“: {summary_time:.3f} ç§’")
        else:
            print(f"   âš ï¸ get_date_summary_quick(): ç„¡çµæœ")
        
        # æ¸¬è©¦è¼‰å…¥ä¾¿åˆ©å‡½æ•¸
        print("\nğŸ“‚ æ¸¬è©¦è¼‰å…¥ä¾¿åˆ©å‡½æ•¸...")
        available_dates = []
        
        processed_base = Path("data/processed")
        if processed_base.exists():
            available_dates = [d.name for d in processed_base.iterdir() 
                             if d.is_dir() and d.name.count('-') == 2]
        
        if available_dates:
            test_date = available_dates[0]
            
            start_time = time.time()
            date_data = load_classified_data_quick(target_date=test_date)
            load_time = time.time() - start_time
            
            if date_data:
                total_records = sum(len(df) for df in date_data.values() if not df.empty)
                print(f"   âœ… load_classified_data_quick({test_date}): {total_records:,} ç­†è¨˜éŒ„")
                print(f"   â±ï¸ è¼‰å…¥æ™‚é–“: {load_time:.3f} ç§’")
                
                # æ¸…ç†æ•¸æ“š
                del date_data
            else:
                print(f"   âš ï¸ load_classified_data_quick({test_date}): ç„¡çµæœ")
        else:
            print(f"   âš ï¸ æ²’æœ‰å¯ç”¨æ—¥æœŸè³‡æ–™å¤¾æ¸¬è©¦")
        
        return True
        
    except Exception as e:
        print(f"   âŒ ä¾¿åˆ©å‡½æ•¸æ¸¬è©¦å¤±æ•—: {e}")
        return False


def show_simplified_usage_guide():
    """é¡¯ç¤ºç°¡åŒ–ç‰ˆä½¿ç”¨æŒ‡å—"""
    print("\nğŸ’¡ ç°¡åŒ–ç‰ˆä½¿ç”¨æŒ‡å—")
    print("=" * 60)
    
    print("ğŸš€ Rawæ•¸æ“šè™•ç†ï¼ˆç°¡åŒ–ç‰ˆï¼‰:")
    print("```python")
    print("from src.data_loader import VDDataLoader")
    print("")
    print("# åˆå§‹åŒ–ï¼ˆå¾Œå°è¨˜æ†¶é«”å„ªåŒ–ï¼‰")
    print("loader = VDDataLoader()  # éœé»˜è¨˜æ†¶é«”å„ªåŒ–")
    print("")
    print("# è™•ç†Rawæ•¸æ“šï¼ˆå°ˆæ³¨é€²åº¦é¡¯ç¤ºï¼‰")
    print("df = loader.process_all_files()  # ç°¡æ½”è¼¸å‡º")
    print("")
    print("# ä¾¿åˆ©å‡½æ•¸ï¼ˆä¸€è¡Œæå®šï¼‰")
    print("from src.data_loader import process_all_files_one_shot")
    print("df = process_all_files_one_shot()")
    print("```")
    
    print("\nğŸ“… æ•¸æ“šè¼‰å…¥ï¼ˆç°¡åŒ–ç‰ˆï¼‰:")
    print("```python")
    print("# è¼‰å…¥ç‰¹å®šæ—¥æœŸ")
    print("data = loader.load_classified_data(target_date='2025-06-27')")
    print("")
    print("# è¼‰å…¥æ‰€æœ‰æ—¥æœŸ")
    print("all_data = loader.load_classified_data()")
    print("")
    print("# ä¾¿åˆ©å‡½æ•¸")
    print("from src.data_loader import load_classified_data_quick")
    print("data = load_classified_data_quick(target_date='2025-06-27')")
    print("```")
    
    print("\nğŸ“Š æ•¸æ“šæ‘˜è¦ï¼ˆç°¡åŒ–ç‰ˆï¼‰:")
    print("```python")
    print("# ç²å–æ—¥æœŸæ‘˜è¦")
    print("summary = loader.get_date_summary()")
    print("")
    print("# ä¾¿åˆ©å‡½æ•¸")
    print("from src.data_loader import get_date_summary_quick")
    print("summary = get_date_summary_quick()")
    print("```")
    
    print("\nğŸ¯ ç°¡åŒ–ç‰ˆç‰¹è‰²:")
    print("   ğŸ“‹ å°ˆæ³¨ä¸»è¦åŠŸèƒ½ï¼šåªé¡¯ç¤ºé‡è¦çš„è™•ç†é€²åº¦")
    print("   ğŸ’¾ å¾Œå°è¨˜æ†¶é«”å„ªåŒ–ï¼šè‡ªå‹•ç®¡ç†ï¼Œä¸é¡¯ç¤ºè©³ç´°ä¿¡æ¯")
    print("   ğŸ“‚ æ™ºæ…§Archiveæª¢æŸ¥ï¼šå¿«é€Ÿæª¢æŸ¥ï¼Œé¿å…é‡è¤‡è™•ç†")
    print("   ğŸš€ ä¿æŒé«˜é€Ÿï¼šç¶­æŒ3-5åˆ†é˜è™•ç†åƒè¬ç­†è¨˜éŒ„")
    print("   ğŸ”„ å®Œæ•´åŠŸèƒ½ï¼šä¿ç•™æ‰€æœ‰åŸåŠŸèƒ½ï¼Œç°¡åŒ–è¼¸å‡º")
    print("   ğŸ“Š ç°¡æ½”å ±å‘Šï¼šå°ˆæ³¨æ ¸å¿ƒçµ±è¨ˆæ•¸æ“š")


def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ VDæ•¸æ“šè¼‰å…¥å™¨ç°¡åŒ–ç‰ˆæ¸¬è©¦")
    print("=" * 70)
    print("ç‰¹è‰²ï¼šå°ˆæ³¨Rawè™•ç† + å¾Œå°è¨˜æ†¶é«”å„ªåŒ– + ç°¡æ½”è¼¸å‡º")
    print("=" * 70)
    
    # é¡¯ç¤ºç³»çµ±åŸºæœ¬è³‡è¨Š
    memory_info = psutil.virtual_memory()
    print(f"ğŸ’¾ ç³»çµ±è¨˜æ†¶é«”: {memory_info.total/(1024**3):.1f}GB (ä½¿ç”¨ç‡: {memory_info.percent:.1f}%)")
    
    start_time = time.time()
    test_results = []
    
    try:
        # æ¸¬è©¦1: ç°¡åŒ–ç‰ˆåˆå§‹åŒ–
        success = test_simplified_initialization()
        test_results.append(("ç°¡åŒ–ç‰ˆåˆå§‹åŒ–", success))
        
        # æ¸¬è©¦2: ç°¡åŒ–Archiveæª¢æŸ¥
        success = test_archive_check_simplified()
        test_results.append(("ç°¡åŒ–Archiveæª¢æŸ¥", success))
        
        # æ¸¬è©¦3: ç°¡åŒ–Rawè³‡æ–™å¤¾æª¢æŸ¥
        success = test_raw_folder_check_simplified()
        test_results.append(("ç°¡åŒ–Rawè³‡æ–™å¤¾æª¢æŸ¥", success))
        
        # æ¸¬è©¦4: ç°¡åŒ–æ—¥æœŸè³‡æ–™å¤¾æª¢æ¸¬
        success = test_date_folder_detection_simplified()
        test_results.append(("ç°¡åŒ–æ—¥æœŸè³‡æ–™å¤¾æª¢æ¸¬", success))
        
        # æ¸¬è©¦5: ç°¡åŒ–å‘é‡åŒ–æ•ˆèƒ½æ¸¬è©¦
        success = test_vectorized_performance_simplified()
        test_results.append(("ç°¡åŒ–å‘é‡åŒ–æ•ˆèƒ½", success))
        
        # æ¸¬è©¦6: ç°¡åŒ–æ•¸æ“šè¼‰å…¥æ¸¬è©¦
        success = test_data_loading_simplified()
        test_results.append(("ç°¡åŒ–æ•¸æ“šè¼‰å…¥", success))
        
        # æ¸¬è©¦7: ç°¡åŒ–Rawè™•ç†æ¸¬è©¦
        success = test_raw_processing_simplified()
        test_results.append(("ç°¡åŒ–Rawè™•ç†", success))
        
        # æ¸¬è©¦8: ç°¡åŒ–ä¾¿åˆ©å‡½æ•¸æ¸¬è©¦
        success = test_convenience_functions_simplified()
        test_results.append(("ç°¡åŒ–ä¾¿åˆ©å‡½æ•¸", success))
        
        # é¡¯ç¤ºä½¿ç”¨æŒ‡å—
        show_simplified_usage_guide()
        
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # æ¸¬è©¦çµæœ
    total_time = time.time() - start_time
    final_memory = psutil.virtual_memory()
    
    print(f"\nğŸ ç°¡åŒ–ç‰ˆæ¸¬è©¦å®Œæˆ")
    print("=" * 70)
    print("ğŸ“‹ æ¸¬è©¦çµæœ:")
    
    passed_tests = 0
    for test_name, success in test_results:
        status = "âœ… é€šé" if success else "âŒ å¤±æ•—"
        print(f"   â€¢ {test_name}: {status}")
        if success:
            passed_tests += 1
    
    print(f"\nğŸ“Š æ¸¬è©¦çµ±è¨ˆ:")
    print(f"   â€¢ ç¸½æ¸¬è©¦é …ç›®: {len(test_results)}")
    print(f"   â€¢ é€šéæ¸¬è©¦: {passed_tests}")
    print(f"   â€¢ æˆåŠŸç‡: {passed_tests/len(test_results)*100:.1f}%")
    print(f"   â€¢ åŸ·è¡Œæ™‚é–“: {total_time:.1f} ç§’")
    print(f"   â€¢ æœ€çµ‚è¨˜æ†¶é«”: {final_memory.percent:.1f}%")
    
    # æœ€çµ‚è©•ä¼°
    if passed_tests == len(test_results):
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼ç°¡åŒ–ç‰ˆåŠŸèƒ½å®Œå…¨å°±ç·’ï¼")
        print("âœ… ç°¡åŒ–ç‰ˆåˆå§‹åŒ–æ­£å¸¸")
        print("âœ… å¾Œå°è¨˜æ†¶é«”å„ªåŒ–æ­£å¸¸")
        print("âœ… æ™ºæ…§Archiveæª¢æŸ¥æ­£å¸¸")
        print("âœ… Rawæ•¸æ“šè™•ç†åŠŸèƒ½æ­£å¸¸")
        print("âœ… ç°¡åŒ–è¼¸å‡ºé¡¯ç¤ºæ­£å¸¸")
        print("âœ… æ‰€æœ‰ä¾¿åˆ©å‡½æ•¸æ­£å¸¸")
        print("ğŸ”¬ å¯ä»¥é–‹å§‹å°ˆæ³¨Rawæ•¸æ“šè™•ç†")
        
        return True
    else:
        print(f"\nâš ï¸ æœ‰ {len(test_results) - passed_tests} å€‹æ¸¬è©¦å¤±æ•—")
        print("å»ºè­°æª¢æŸ¥ç›¸é—œåŠŸèƒ½å¾Œå†ä½¿ç”¨")
        return False


if __name__ == "__main__":
    success = main()
    
    if success:
        print("\nğŸ”¬ ç°¡åŒ–ç‰ˆç³»çµ±æ¸¬è©¦å®Œæˆï¼Œå°ˆæ³¨Rawè™•ç†åŠŸèƒ½å·²å°±ç·’ï¼")
        
        print("\nğŸ’» ç°¡åŒ–ç‰ˆåŸ·è¡Œæµç¨‹:")
        print("1. å°‡æ‰€æœ‰XMLæª”æ¡ˆæ”¾å…¥ data/raw/ è³‡æ–™å¤¾")
        print("2. åŸ·è¡Œ: python test_loader.py æˆ–ç›´æ¥é‹è¡Œ data_loader.py")
        print("3. ç³»çµ±å¾Œå°è‡ªå‹•è¨˜æ†¶é«”å„ªåŒ–ï¼ˆéœé»˜ï¼‰")
        print("4. é¡¯ç¤ºç°¡æ½”çš„Rawè™•ç†é€²åº¦")
        print("5. è‡ªå‹•Archiveæª¢æŸ¥ï¼Œé¿å…é‡è¤‡è™•ç†")
        print("6. æŒ‰æ—¥æœŸçµ„ç¹”è¼¸å‡ºçµæœ")
        
        print("\nğŸ¯ ç°¡åŒ–ç‰ˆå„ªå‹¢:")
        print("   ğŸ“‹ å°ˆæ³¨Rawè™•ç†ï¼šä¸»è¦é¡¯ç¤ºè™•ç†é€²åº¦å’Œçµæœ")
        print("   ğŸ’¾ å¾Œå°è¨˜æ†¶é«”å„ªåŒ–ï¼šè‡ªå‹•ç®¡ç†ï¼Œä¸å¹²æ“¾ç”¨æˆ¶")
        print("   ğŸ“‚ æ™ºæ…§Archiveæª¢æŸ¥ï¼šå¿«é€Ÿæª¢æŸ¥ï¼Œé¿å…é‡è¤‡")
        print("   ğŸ“Š ç°¡æ½”è¼¸å‡ºï¼šåªé¡¯ç¤ºé‡è¦ä¿¡æ¯")
        print("   ğŸš€ ä¿æŒé«˜é€Ÿï¼šç¶­æŒ3-5åˆ†é˜è™•ç†åƒè¬ç­†è¨˜éŒ„")
        print("   ğŸ”„ å®Œæ•´åŠŸèƒ½ï¼šä¿ç•™æ‰€æœ‰åŸåŠŸèƒ½")
        
        print("\nğŸ“ ç°¡åŒ–ç‰ˆè¼¸å‡ºæ¶æ§‹:")
        print("   ğŸ“‚ data/processed/")
        print("      â”œâ”€â”€ 2025-06-27/  ğŸ“… æŒ‰æ—¥æœŸçµ„ç¹”")
        print("      â”‚   â”œâ”€â”€ vd_data_all.csv + _summary.json")
        print("      â”‚   â”œâ”€â”€ vd_data_peak.csv + _summary.json")
        print("      â”‚   â”œâ”€â”€ vd_data_offpeak.csv + _summary.json")
        print("      â”‚   â”œâ”€â”€ target_route_*.csv + _summary.json")
        print("      â”‚   â””â”€â”€ processed_files.json")
        print("      â””â”€â”€ ... (å…¶ä»–æ—¥æœŸ)")
        
        print("\nğŸ“Š ç°¡åŒ–ç‰ˆä½¿ç”¨ç¯„ä¾‹:")
        print("   # ä¸€è¡Œè™•ç†æ‰€æœ‰Rawæ•¸æ“š")
        print("   loader = VDDataLoader()")
        print("   df = loader.process_all_files()  # ç°¡æ½”é€²åº¦é¡¯ç¤º")
        print("   ")
        print("   # è¼‰å…¥ç‰¹å®šæ—¥æœŸæ•¸æ“š")
        print("   data = loader.load_classified_data(target_date='2025-06-27')")
        print("   ")
        print("   # ç²å–æ‘˜è¦")
        print("   summary = loader.get_date_summary()  # ç°¡æ½”æ‘˜è¦")
        
        print("\nğŸš€ æº–å‚™é–‹å§‹Rawæ•¸æ“šè™•ç†:")
        print("   ğŸ“… å°ˆæ³¨Rawæª”æ¡ˆè™•ç†å’ŒæŒ‰æ—¥æœŸçµ„ç¹”")
        print("   ğŸ’¾ äº«å—å¾Œå°è¨˜æ†¶é«”å„ªåŒ–çš„ç©©å®šæ€§")
        print("   ğŸ“Š ç²å¾—ç°¡æ½”æ¸…æ™°çš„è™•ç†é€²åº¦")
        print("   ğŸ¯ å¿«é€Ÿå®Œæˆæ•¸æ“šæº–å‚™å·¥ä½œ")
        
    else:
        print("\nğŸ”§ è«‹è§£æ±ºæ¸¬è©¦ä¸­çš„å•é¡Œ")
    
    print(f"\nğŸ¯ å°ˆæ¡ˆé€²å±•ï¼ˆç°¡åŒ–ç‰ˆï¼‰:")
    print(f"   âœ… åŸºç¤å»ºè¨­")
    print(f"   âœ… æ•¸æ“šè¼‰å…¥")  
    print(f"   âœ… å°–å³°é›¢å³°åˆ†é¡")
    print(f"   âœ… ç›®æ¨™è·¯æ®µç¯©é¸")
    print(f"   âœ… è¶…ç´šé€Ÿåº¦å„ªåŒ–")
    print(f"   âœ… ä¸€æ¬¡æ€§è™•ç†å®Œå–„")
    print(f"   âœ… æ—¥æœŸçµ„ç¹”æ¶æ§‹")
    print(f"   âœ… è¨˜æ†¶é«”å„ªåŒ–ç³»çµ±")
    print(f"   âœ… ç°¡åŒ–ç‰ˆå°ˆæ³¨Rawè™•ç† ğŸ†•")
    print(f"   ğŸ”„ ä¸‹ä¸€æ­¥: AIé æ¸¬æ¨¡å‹é–‹ç™¼")
    
    print(f"\nğŸŠ æ­å–œï¼ç°¡åŒ–ç‰ˆRawæ•¸æ“šè™•ç†ç³»çµ±å·²å®Œå…¨å°±ç·’ï¼")
    print(f"ğŸ¯ æ‚¨ç¾åœ¨æ“æœ‰å°ˆæ³¨ã€é«˜æ•ˆçš„Rawæ•¸æ“šè™•ç†èƒ½åŠ›ï¼š")
    print(f"   â€¢ ç°¡æ½”çš„è™•ç†é€²åº¦é¡¯ç¤º")
    print(f"   â€¢ å¾Œå°è‡ªå‹•è¨˜æ†¶é«”å„ªåŒ–")
    print(f"   â€¢ æ™ºæ…§Archiveæª¢æŸ¥é¿å…é‡è¤‡")
    print(f"   â€¢ å®Œæ•´çš„æŒ‰æ—¥æœŸçµ„ç¹”åŠŸèƒ½")
    print(f"   â€¢ ä¿æŒåŸæœ‰çš„è¶…ç´šè™•ç†é€Ÿåº¦")
    
    print(f"\nğŸš€ Ready for Focused Raw Data Processing! ğŸš€")