# src/fusion_engine.py - VD+eTagæ•¸æ“šèåˆå¼•æ“

"""
VD+eTagæ•¸æ“šèåˆå¼•æ“
==================

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ğŸ”— è¼‰å…¥æ™‚ç©ºå°é½Šå¾Œçš„VD+eTagæ•¸æ“š
2. ğŸ§® å‰µå»ºå¤šæºèåˆç‰¹å¾µå·¥ç¨‹
3. ğŸ¯ è¨“ç·´å¤šæºèåˆé æ¸¬æ¨¡å‹
4. ğŸ“Š è©•ä¼°èåˆæ•ˆæœå’Œæ€§èƒ½æå‡
5. ğŸ’¾ ä¿å­˜èåˆæ¨¡å‹å’Œé…ç½®

èåˆç­–ç•¥ï¼š
- VDç¬æ™‚ç‰¹å¾µï¼šé€Ÿåº¦ã€æµé‡ã€ä½”æœ‰ç‡çµ±è¨ˆ
- eTagå€é–“ç‰¹å¾µï¼šæ—…è¡Œæ™‚é–“ã€å€é–“é€Ÿåº¦ã€è·¯æ®µæµé‡
- ç©ºé–“ç‰¹å¾µï¼šä¸€è‡´æ€§è©•åˆ†ã€é€Ÿåº¦æ¯”ç‡ã€æµé‡ç›¸é—œæ€§
- æ™‚é–“ç‰¹å¾µï¼šæ»¯å¾Œã€æ»¾å‹•çµ±è¨ˆã€é€±æœŸæ€§

æ¨¡å‹æ¶æ§‹ï¼š
- èåˆXGBoostï¼šä¸»åŠ›é«˜ç²¾åº¦æ¨¡å‹
- èåˆéš¨æ©Ÿæ£®æ—ï¼šç©©å®šåŸºç·šæ¨¡å‹
- æ·±åº¦èåˆç¶²çµ¡ï¼šæ¢ç´¢æ€§LSTMè®Šé«”

ä½œè€…: äº¤é€šé æ¸¬å°ˆæ¡ˆåœ˜éšŠ
æ—¥æœŸ: 2025-07-29
"""

import pandas as pd
import numpy as np
import json
import pickle
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
import warnings
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import xgboost as xgb

# TensorFlow for deep fusion network
try:
    import tensorflow as tf
    from tensorflow.keras.models import Sequential, Model
    from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization, Input, concatenate
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.callbacks import EarlyStopping
    TENSORFLOW_AVAILABLE = True
    print("âœ… TensorFlowå·²è¼‰å…¥ï¼Œæ·±åº¦èåˆç¶²çµ¡å°±ç·’")
except ImportError:
    TENSORFLOW_AVAILABLE = False
    print("âš ï¸ TensorFlowæœªå®‰è£ï¼Œæ·±åº¦èåˆåŠŸèƒ½å°‡è¢«ç¦ç”¨")

warnings.filterwarnings('ignore')


class FusionFeatureEngineer:
    """å¤šæºèåˆç‰¹å¾µå·¥ç¨‹å™¨"""
    
    def __init__(self):
        self.scalers = {}
        self.encoders = {}
        self.feature_names = []
        self.vd_features = []
        self.etag_features = []
        self.fusion_features = []
        
        print("ğŸ”§ å¤šæºèåˆç‰¹å¾µå·¥ç¨‹å™¨åˆå§‹åŒ–")
    
    def create_fusion_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """å‰µå»ºå¤šæºèåˆç‰¹å¾µ"""
        print("ğŸ”— å‰µå»ºå¤šæºèåˆç‰¹å¾µ...")
        
        df = df.copy()
        
        # 1. VDç‰¹å¾µè™•ç†
        df = self._process_vd_features(df)
        
        # 2. eTagç‰¹å¾µè™•ç†
        df = self._process_etag_features(df)
        
        # 3. èåˆäº¤äº’ç‰¹å¾µ
        df = self._create_fusion_interactions(df)
        
        # 4. æ™‚é–“ç‰¹å¾µå¢å¼·
        df = self._enhance_temporal_features(df)
        
        # 5. ç©ºé–“ä¸€è‡´æ€§ç‰¹å¾µ
        df = self._enhance_spatial_features(df)
        
        print(f"   âœ… èåˆç‰¹å¾µå®Œæˆ: {len(self.feature_names)} å€‹ç‰¹å¾µ")
        return df
    
    def _process_vd_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """è™•ç†VDç‰¹å¾µ"""
        # VDåŸºç¤ç‰¹å¾µ
        vd_base_features = [
            'vd_speed_mean', 'vd_speed_std', 'vd_speed_min', 'vd_speed_max',
            'vd_volume_total_sum', 'vd_volume_total_mean', 'vd_volume_total_std',
            'vd_occupancy_mean', 'vd_occupancy_std', 'vd_occupancy_max',
            'vd_volume_small_sum', 'vd_volume_large_sum', 'vd_volume_truck_sum'
        ]
        
        # æª¢æŸ¥ä¸¦ä¿ç•™å­˜åœ¨çš„VDç‰¹å¾µ
        existing_vd_features = [f for f in vd_base_features if f in df.columns]
        self.vd_features.extend(existing_vd_features)
        
        # VDè¡ç”Ÿç‰¹å¾µ
        if 'vd_speed_mean' in df.columns and 'vd_occupancy_mean' in df.columns:
            df['vd_speed_occupancy_ratio'] = df['vd_speed_mean'] / (df['vd_occupancy_mean'] + 1)
            self.vd_features.append('vd_speed_occupancy_ratio')
        
        if 'vd_volume_total_sum' in df.columns and 'vd_occupancy_mean' in df.columns:
            df['vd_flow_density'] = df['vd_volume_total_sum'] / (df['vd_occupancy_mean'] + 1)
            self.vd_features.append('vd_flow_density')
        
        # VDè»Šç¨®æ¯”ä¾‹
        vehicle_sum_cols = ['vd_volume_small_sum', 'vd_volume_large_sum', 'vd_volume_truck_sum']
        if all(col in df.columns for col in vehicle_sum_cols):
            total_vehicles = df[vehicle_sum_cols].sum(axis=1)
            df['vd_small_ratio'] = df['vd_volume_small_sum'] / (total_vehicles + 1)
            df['vd_large_ratio'] = df['vd_volume_large_sum'] / (total_vehicles + 1)
            df['vd_truck_ratio'] = df['vd_volume_truck_sum'] / (total_vehicles + 1)
            
            self.vd_features.extend(['vd_small_ratio', 'vd_large_ratio', 'vd_truck_ratio'])
        
        return df
    
    def _process_etag_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """è™•ç†eTagç‰¹å¾µ"""
        # eTagåŸºç¤ç‰¹å¾µ
        etag_base_features = [
            'etag_travel_time_primary', 'etag_speed_primary', 'etag_volume_primary',
            'etag_travel_time_secondary', 'etag_speed_secondary', 'etag_volume_secondary'
        ]
        
        # æª¢æŸ¥ä¸¦ä¿ç•™å­˜åœ¨çš„eTagç‰¹å¾µ
        existing_etag_features = [f for f in etag_base_features if f in df.columns]
        self.etag_features.extend(existing_etag_features)
        
        # eTagè¡ç”Ÿç‰¹å¾µ
        if 'etag_travel_time_primary' in df.columns:
            # æ—…è¡Œæ™‚é–“ç­‰ç´šåˆ†é¡
            df['etag_travel_time_category'] = pd.cut(
                df['etag_travel_time_primary'], 
                bins=[0, 60, 120, 180, float('inf')], 
                labels=['å¿«é€Ÿ', 'ä¸€èˆ¬', 'ç·©æ…¢', 'å£…å¡']
            )
            
            # ç·¨ç¢¼æ—…è¡Œæ™‚é–“é¡åˆ¥
            if 'etag_travel_time_category' not in self.encoders:
                self.encoders['etag_travel_time_category'] = LabelEncoder()
                df['etag_travel_time_encoded'] = self.encoders['etag_travel_time_category'].fit_transform(
                    df['etag_travel_time_category'].fillna('ä¸€èˆ¬')
                )
            
            self.etag_features.append('etag_travel_time_encoded')
        
        # eTagè·¯æ®µæ•ˆç‡æŒ‡æ¨™
        if 'etag_speed_primary' in df.columns and 'etag_travel_time_primary' in df.columns:
            df['etag_efficiency_index'] = df['etag_speed_primary'] / (df['etag_travel_time_primary'] / 60 + 1)
            self.etag_features.append('etag_efficiency_index')
        
        return df
    
    def _create_fusion_interactions(self, df: pd.DataFrame) -> pd.DataFrame:
        """å‰µå»ºVD-eTagèåˆäº¤äº’ç‰¹å¾µ"""
        # é€Ÿåº¦ä¸€è‡´æ€§ç‰¹å¾µ
        if 'vd_speed_mean' in df.columns and 'etag_speed_primary' in df.columns:
            # é€Ÿåº¦å·®ç•°
            df['fusion_speed_difference'] = abs(df['vd_speed_mean'] - df['etag_speed_primary'])
            
            # é€Ÿåº¦æ¯”ç‡
            df['fusion_speed_ratio'] = df['vd_speed_mean'] / (df['etag_speed_primary'] + 1)
            
            # é€Ÿåº¦ä¸€è‡´æ€§è©•åˆ†
            df['fusion_speed_consistency'] = np.exp(-df['fusion_speed_difference'] / 20)
            
            self.fusion_features.extend([
                'fusion_speed_difference', 'fusion_speed_ratio', 'fusion_speed_consistency'
            ])
        
        # æµé‡ç›¸é—œæ€§ç‰¹å¾µ
        if 'vd_volume_total_sum' in df.columns and 'etag_volume_primary' in df.columns:
            # æµé‡æ¯”ç‡
            df['fusion_volume_ratio'] = df['vd_volume_total_sum'] / (df['etag_volume_primary'] + 1)
            
            # æµé‡ç›¸é—œæŒ‡æ•¸
            df['fusion_flow_correlation'] = np.minimum(
                df['vd_volume_total_sum'] / (df['etag_volume_primary'] + 1),
                df['etag_volume_primary'] / (df['vd_volume_total_sum'] + 1)
            )
            
            self.fusion_features.extend(['fusion_volume_ratio', 'fusion_flow_correlation'])
        
        # äº¤é€šç‹€æ…‹èåˆæŒ‡æ¨™
        if ('vd_speed_mean' in df.columns and 'vd_occupancy_mean' in df.columns and 
            'etag_travel_time_primary' in df.columns and 'etag_speed_primary' in df.columns):
            
            # VDäº¤é€šç‹€æ…‹æŒ‡æ•¸
            vd_traffic_index = (df['vd_speed_mean'] / 80) * (1 - df['vd_occupancy_mean'] / 100)
            
            # eTagäº¤é€šç‹€æ…‹æŒ‡æ•¸
            etag_traffic_index = (df['etag_speed_primary'] / 80) * (60 / (df['etag_travel_time_primary'] + 1))
            
            # èåˆäº¤é€šç‹€æ…‹æŒ‡æ•¸
            df['fusion_traffic_state_index'] = (vd_traffic_index + etag_traffic_index) / 2
            
            # äº¤é€šç‹€æ…‹ä¸€è‡´æ€§
            df['fusion_state_consistency'] = 1 - abs(vd_traffic_index - etag_traffic_index)
            
            self.fusion_features.extend(['fusion_traffic_state_index', 'fusion_state_consistency'])
        
        return df
    
    def _enhance_temporal_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¢å¼·æ™‚é–“ç‰¹å¾µ"""
        if 'update_time' not in df.columns:
            return df
        
        df['update_time'] = pd.to_datetime(df['update_time'])
        
        # åŸºæœ¬æ™‚é–“ç‰¹å¾µ
        df['hour'] = df['update_time'].dt.hour
        df['minute'] = df['update_time'].dt.minute
        df['day_of_week'] = df['update_time'].dt.dayofweek
        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
        
        # é€±æœŸæ€§ç‰¹å¾µ
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
        df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
        
        # å°–å³°æ™‚æ®µç‰¹å¾µ
        df['is_morning_peak'] = ((df['hour'] >= 7) & (df['hour'] < 9) & ~df['is_weekend'].astype(bool)).astype(int)
        df['is_evening_peak'] = ((df['hour'] >= 17) & (df['hour'] < 20) & ~df['is_weekend'].astype(bool)).astype(int)
        df['is_peak_hour'] = (df['is_morning_peak'] | df['is_evening_peak']).astype(int)
        
        temporal_features = [
            'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 
            'is_morning_peak', 'is_evening_peak', 'is_peak_hour', 'is_weekend'
        ]
        self.fusion_features.extend(temporal_features)
        
        return df
    
    def _enhance_spatial_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¢å¼·ç©ºé–“ç‰¹å¾µ"""
        # VDç«™é»ç·¨ç¢¼
        if 'vd_id' in df.columns:
            if 'vd_id' not in self.encoders:
                self.encoders['vd_id'] = LabelEncoder()
                df['vd_encoded'] = self.encoders['vd_id'].fit_transform(df['vd_id'].astype(str))
            
            # è·¯æ®µç‰¹å¾µ
            df['is_yuanshan'] = df['vd_id'].str.contains('23', na=False).astype(int)
            df['is_taipei'] = df['vd_id'].str.contains('25', na=False).astype(int)
            df['is_sanchong'] = df['vd_id'].str.contains('27', na=False).astype(int)
            
            spatial_features = ['vd_encoded', 'is_yuanshan', 'is_taipei', 'is_sanchong']
            self.fusion_features.extend(spatial_features)
        
        # ä½¿ç”¨ç¾æœ‰çš„ç©ºé–“ä¸€è‡´æ€§ç‰¹å¾µ
        existing_spatial = [
            'spatial_consistency_score', 'speed_difference', 'speed_ratio',
            'flow_correlation_index', 'volume_ratio'
        ]
        
        for feature in existing_spatial:
            if feature in df.columns:
                self.fusion_features.append(feature)
        
        return df
    
    def fit_transform(self, df: pd.DataFrame, target_cols: List[str] = ['vd_speed_mean']) -> pd.DataFrame:
        """æ“¬åˆä¸¦è½‰æ›å¤šæºèåˆç‰¹å¾µ"""
        print("ğŸ”— åŸ·è¡Œå¤šæºèåˆç‰¹å¾µå·¥ç¨‹...")
        
        # å‰µå»ºèåˆç‰¹å¾µ
        df = self.create_fusion_features(df)
        
        # åˆä½µæ‰€æœ‰ç‰¹å¾µåç¨±
        self.feature_names = self.vd_features + self.etag_features + self.fusion_features
        
        # ç§»é™¤é‡è¤‡ç‰¹å¾µ
        self.feature_names = list(set(self.feature_names))
        
        # ç¢ºä¿æ‰€æœ‰ç‰¹å¾µéƒ½å­˜åœ¨
        missing_features = set(self.feature_names) - set(df.columns)
        if missing_features:
            print(f"   âš ï¸ ç¼ºå°‘ç‰¹å¾µ: {missing_features}")
            self.feature_names = [f for f in self.feature_names if f in df.columns]
        
        # è™•ç†ç¼ºå¤±å€¼
        df[self.feature_names] = df[self.feature_names].fillna(df[self.feature_names].median())
        
        # ç‰¹å¾µç¸®æ”¾
        if self.feature_names:
            self.scalers['features'] = StandardScaler()
            df[self.feature_names] = self.scalers['features'].fit_transform(df[self.feature_names])
        
        print(f"   âœ… èåˆç‰¹å¾µå·¥ç¨‹å®Œæˆ: {len(self.feature_names)} å€‹ç‰¹å¾µ")
        print(f"      ğŸ“Š VDç‰¹å¾µ: {len(self.vd_features)}")
        print(f"      ğŸ·ï¸ eTagç‰¹å¾µ: {len(self.etag_features)}")
        print(f"      ğŸ”— èåˆç‰¹å¾µ: {len(self.fusion_features)}")
        
        return df
    
    def transform(self, df: pd.DataFrame, target_cols: List[str] = ['vd_speed_mean']) -> pd.DataFrame:
        """åƒ…è½‰æ›ç‰¹å¾µï¼ˆç”¨æ–¼é æ¸¬ï¼‰"""
        df = self.create_fusion_features(df)
        
        # ç¢ºä¿æ‰€æœ‰ç‰¹å¾µéƒ½å­˜åœ¨
        missing_features = set(self.feature_names) - set(df.columns)
        for feature in missing_features:
            df[feature] = 0
        
        # è™•ç†ç¼ºå¤±å€¼
        df[self.feature_names] = df[self.feature_names].fillna(0)
        
        # ç‰¹å¾µç¸®æ”¾
        if 'features' in self.scalers:
            df[self.feature_names] = self.scalers['features'].transform(df[self.feature_names])
        
        return df


class FusionXGBoostPredictor:
    """èåˆXGBoosté æ¸¬å™¨"""
    
    def __init__(self):
        self.model = None
        self.is_trained = False
        self.feature_importance = {}
        self.vd_contribution = 0.0
        self.etag_contribution = 0.0
        self.fusion_contribution = 0.0
        
        print("âš¡ èåˆXGBoosté æ¸¬å™¨åˆå§‹åŒ–")
    
    def train(self, X: np.ndarray, y: np.ndarray, feature_names: List[str], 
              vd_features: List[str], etag_features: List[str], 
              fusion_features: List[str]) -> Dict[str, Any]:
        """è¨“ç·´èåˆXGBoostæ¨¡å‹"""
        print("ğŸš€ é–‹å§‹èåˆXGBoostè¨“ç·´...")
        
        # èåˆå„ªåŒ–åƒæ•¸
        fusion_params = {
            'objective': 'reg:squarederror',
            'max_depth': 10,
            'learning_rate': 0.08,
            'n_estimators': 400,
            'subsample': 0.85,
            'colsample_bytree': 0.85,
            'min_child_weight': 2,
            'gamma': 0.05,
            'reg_alpha': 0.1,
            'reg_lambda': 0.2,
            'random_state': 42
        }
        
        self.model = xgb.XGBRegressor(**fusion_params)
        self.model.fit(X, y)
        
        # è¨ˆç®—ç‰¹å¾µé‡è¦æ€§å’Œè²¢ç»åº¦
        if feature_names:
            importance_scores = self.model.feature_importances_
            self.feature_importance = dict(zip(feature_names, importance_scores))
            
            # è¨ˆç®—å„é¡ç‰¹å¾µçš„è²¢ç»åº¦
            self._calculate_feature_contributions(feature_names, vd_features, etag_features, fusion_features)
            
            # é¡¯ç¤ºå‰15å€‹é‡è¦ç‰¹å¾µ
            sorted_features = sorted(self.feature_importance.items(), key=lambda x: x[1], reverse=True)
            print("   ğŸ¯ å‰15å€‹é‡è¦ç‰¹å¾µ:")
            for i, (feature, importance) in enumerate(sorted_features[:15], 1):
                feature_type = self._get_feature_type(feature, vd_features, etag_features, fusion_features)
                print(f"      {i:2d}. {feature}: {importance:.4f} ({feature_type})")
        
        self.is_trained = True
        
        print(f"   âœ… èåˆXGBoostè¨“ç·´å®Œæˆ")
        print(f"      ğŸ“Š VDè²¢ç»åº¦: {self.vd_contribution:.1%}")
        print(f"      ğŸ·ï¸ eTagè²¢ç»åº¦: {self.etag_contribution:.1%}")
        print(f"      ğŸ”— èåˆè²¢ç»åº¦: {self.fusion_contribution:.1%}")
        
        return {
            'feature_count': X.shape[1],
            'training_samples': X.shape[0],
            'vd_contribution': self.vd_contribution,
            'etag_contribution': self.etag_contribution,
            'fusion_contribution': self.fusion_contribution,
            'top_features': sorted_features[:10]
        }
    
    def _calculate_feature_contributions(self, feature_names: List[str], 
                                       vd_features: List[str], etag_features: List[str], 
                                       fusion_features: List[str]):
        """è¨ˆç®—å„é¡ç‰¹å¾µçš„è²¢ç»åº¦"""
        vd_importance = sum(self.feature_importance.get(f, 0) for f in vd_features if f in feature_names)
        etag_importance = sum(self.feature_importance.get(f, 0) for f in etag_features if f in feature_names)
        fusion_importance = sum(self.feature_importance.get(f, 0) for f in fusion_features if f in feature_names)
        
        total_importance = vd_importance + etag_importance + fusion_importance
        
        if total_importance > 0:
            self.vd_contribution = vd_importance / total_importance
            self.etag_contribution = etag_importance / total_importance
            self.fusion_contribution = fusion_importance / total_importance
    
    def _get_feature_type(self, feature: str, vd_features: List[str], 
                         etag_features: List[str], fusion_features: List[str]) -> str:
        """ç²å–ç‰¹å¾µé¡å‹"""
        if feature in vd_features:
            return "VD"
        elif feature in etag_features:
            return "eTag"
        elif feature in fusion_features:
            return "èåˆ"
        else:
            return "å…¶ä»–"
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """é€²è¡Œé æ¸¬"""
        if not self.is_trained:
            raise ValueError("æ¨¡å‹å°šæœªè¨“ç·´")
        return self.model.predict(X)
    
    def save_model(self, filepath: Path):
        """ä¿å­˜æ¨¡å‹"""
        if self.model is not None:
            self.model.save_model(filepath / "fusion_xgboost_model.json")
            
            # ä¿å­˜ç‰¹å¾µé‡è¦æ€§å’Œè²¢ç»åº¦
            fusion_info = {
                'feature_importance': {k: float(v) for k, v in self.feature_importance.items()},
                'vd_contribution': float(self.vd_contribution),
                'etag_contribution': float(self.etag_contribution),
                'fusion_contribution': float(self.fusion_contribution)
            }
            
            with open(filepath / "fusion_xgboost_info.json", 'w') as f:
                json.dump(fusion_info, f, indent=2)
    
    def load_model(self, filepath: Path):
        """è¼‰å…¥æ¨¡å‹"""
        self.model = xgb.XGBRegressor()
        self.model.load_model(filepath / "fusion_xgboost_model.json")
        
        try:
            with open(filepath / "fusion_xgboost_info.json", 'r') as f:
                fusion_info = json.load(f)
                self.feature_importance = fusion_info['feature_importance']
                self.vd_contribution = fusion_info['vd_contribution']
                self.etag_contribution = fusion_info['etag_contribution']
                self.fusion_contribution = fusion_info['fusion_contribution']
        except:
            pass
        
        self.is_trained = True


class FusionRandomForestPredictor:
    """èåˆéš¨æ©Ÿæ£®æ—é æ¸¬å™¨"""
    
    def __init__(self):
        self.model = None
        self.is_trained = False
        self.feature_importance = {}
        
        print("ğŸŒ² èåˆéš¨æ©Ÿæ£®æ—é æ¸¬å™¨åˆå§‹åŒ–")
    
    def train(self, X: np.ndarray, y: np.ndarray, feature_names: List[str]) -> Dict[str, Any]:
        """è¨“ç·´èåˆéš¨æ©Ÿæ£®æ—æ¨¡å‹"""
        print("ğŸš€ é–‹å§‹èåˆéš¨æ©Ÿæ£®æ—è¨“ç·´...")
        
        # èåˆå„ªåŒ–åƒæ•¸
        self.model = RandomForestRegressor(
            n_estimators=300,
            max_depth=20,
            min_samples_split=3,
            min_samples_leaf=2,
            max_features='sqrt',
            random_state=42,
            n_jobs=-1
        )
        
        self.model.fit(X, y)
        
        # ç‰¹å¾µé‡è¦æ€§
        if feature_names:
            importance_scores = self.model.feature_importances_
            self.feature_importance = dict(zip(feature_names, importance_scores))
        
        self.is_trained = True
        print("âœ… èåˆéš¨æ©Ÿæ£®æ—è¨“ç·´å®Œæˆ")
        
        return {
            'n_estimators': self.model.n_estimators,
            'feature_count': X.shape[1],
            'training_samples': X.shape[0]
        }
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """é€²è¡Œé æ¸¬"""
        if not self.is_trained:
            raise ValueError("æ¨¡å‹å°šæœªè¨“ç·´")
        return self.model.predict(X)
    
    def save_model(self, filepath: Path):
        """ä¿å­˜æ¨¡å‹"""
        if self.model is not None:
            with open(filepath / "fusion_random_forest_model.pkl", 'wb') as f:
                pickle.dump(self.model, f)
                
            with open(filepath / "fusion_rf_feature_importance.json", 'w') as f:
                json.dump({k: float(v) for k, v in self.feature_importance.items()}, f, indent=2)
    
    def load_model(self, filepath: Path):
        """è¼‰å…¥æ¨¡å‹"""
        with open(filepath / "fusion_random_forest_model.pkl", 'rb') as f:
            self.model = pickle.load(f)
            
        try:
            with open(filepath / "fusion_rf_feature_importance.json", 'r') as f:
                self.feature_importance = json.load(f)
        except:
            pass
        
        self.is_trained = True


class DeepFusionNetwork:
    """æ·±åº¦èåˆç¥ç¶“ç¶²çµ¡"""
    
    def __init__(self):
        self.model = None
        self.is_trained = False
        self.scaler = StandardScaler()
        
        print("ğŸ§  æ·±åº¦èåˆç¥ç¶“ç¶²çµ¡åˆå§‹åŒ–")
    
    def build_fusion_network(self, vd_input_dim: int, etag_input_dim: int, 
                           fusion_input_dim: int) -> Model:
        """å»ºç«‹å¤šæºèåˆç¥ç¶“ç¶²çµ¡"""
        if not TENSORFLOW_AVAILABLE:
            raise ImportError("TensorFlowæœªå®‰è£ï¼Œç„¡æ³•ä½¿ç”¨æ·±åº¦èåˆç¶²çµ¡")
        
        # VDåˆ†æ”¯
        vd_input = Input(shape=(vd_input_dim,), name='vd_input')
        vd_branch = Dense(64, activation='relu')(vd_input)
        vd_branch = BatchNormalization()(vd_branch)
        vd_branch = Dropout(0.2)(vd_branch)
        vd_branch = Dense(32, activation='relu')(vd_branch)
        
        # eTagåˆ†æ”¯
        etag_input = Input(shape=(etag_input_dim,), name='etag_input')
        etag_branch = Dense(32, activation='relu')(etag_input)
        etag_branch = BatchNormalization()(etag_branch)
        etag_branch = Dropout(0.2)(etag_branch)
        etag_branch = Dense(16, activation='relu')(etag_branch)
        
        # èåˆç‰¹å¾µåˆ†æ”¯
        fusion_input = Input(shape=(fusion_input_dim,), name='fusion_input')
        fusion_branch = Dense(32, activation='relu')(fusion_input)
        fusion_branch = BatchNormalization()(fusion_branch)
        fusion_branch = Dropout(0.2)(fusion_branch)
        
        # åˆä½µæ‰€æœ‰åˆ†æ”¯
        merged = concatenate([vd_branch, etag_branch, fusion_branch])
        
        # èåˆå±¤
        fusion_layer = Dense(64, activation='relu')(merged)
        fusion_layer = BatchNormalization()(fusion_layer)
        fusion_layer = Dropout(0.3)(fusion_layer)
        fusion_layer = Dense(32, activation='relu')(fusion_layer)
        fusion_layer = Dropout(0.2)(fusion_layer)
        
        # è¼¸å‡ºå±¤
        output = Dense(1, activation='linear', name='speed_output')(fusion_layer)
        
        model = Model(inputs=[vd_input, etag_input, fusion_input], outputs=output)
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )
        
        return model
    
    def train(self, X_vd: np.ndarray, X_etag: np.ndarray, X_fusion: np.ndarray, 
              y: np.ndarray) -> Dict[str, Any]:
        """è¨“ç·´æ·±åº¦èåˆç¶²çµ¡"""
        if not TENSORFLOW_AVAILABLE:
            return {"success": False, "error": "TensorFlowæœªå®‰è£"}
        
        print("ğŸš€ é–‹å§‹æ·±åº¦èåˆç¶²çµ¡è¨“ç·´...")
        
        # æ•¸æ“šç¸®æ”¾
        y_scaled = self.scaler.fit_transform(y.reshape(-1, 1)).flatten()
        
        # å»ºç«‹æ¨¡å‹
        self.model = self.build_fusion_network(
            X_vd.shape[1], X_etag.shape[1], X_fusion.shape[1]
        )
        
        # è¨“ç·´å›èª¿
        callbacks = [
            EarlyStopping(patience=15, restore_best_weights=True)
        ]
        
        # è¨“ç·´æ¨¡å‹
        history = self.model.fit(
            [X_vd, X_etag, X_fusion], y_scaled,
            validation_split=0.2,
            epochs=100,
            batch_size=32,
            callbacks=callbacks,
            verbose=1
        )
        
        self.is_trained = True
        print("âœ… æ·±åº¦èåˆç¶²çµ¡è¨“ç·´å®Œæˆ")
        
        return {
            'final_loss': history.history['loss'][-1],
            'final_val_loss': history.history['val_loss'][-1],
            'epochs_trained': len(history.history['loss'])
        }
    
    def predict(self, X_vd: np.ndarray, X_etag: np.ndarray, X_fusion: np.ndarray) -> np.ndarray:
        """é€²è¡Œé æ¸¬"""
        if not self.is_trained or self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè¨“ç·´")
        
        predictions_scaled = self.model.predict([X_vd, X_etag, X_fusion], verbose=0)
        predictions = self.scaler.inverse_transform(predictions_scaled).flatten()
        
        return predictions
    
    def save_model(self, filepath: Path):
        """ä¿å­˜æ¨¡å‹"""
        if self.model is not None:
            self.model.save(filepath / "deep_fusion_model.keras")
            
            with open(filepath / "deep_fusion_scaler.pkl", 'wb') as f:
                pickle.dump(self.scaler, f)
    
    def load_model(self, filepath: Path):
        """è¼‰å…¥æ¨¡å‹"""
        if TENSORFLOW_AVAILABLE:
            from tensorflow.keras.models import load_model
            self.model = load_model(filepath / "deep_fusion_model.keras")
            
            with open(filepath / "deep_fusion_scaler.pkl", 'rb') as f:
                self.scaler = pickle.load(f)
            
            self.is_trained = True


class VDETagFusionEngine:
    """VD+eTagèåˆå¼•æ“ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, base_folder: str = "data"):
        self.base_folder = Path(base_folder)
        self.fusion_folder = self.base_folder / "processed" / "fusion"
        self.models_folder = Path("models") / "fusion_models"
        self.models_folder.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–çµ„ä»¶
        self.feature_engineer = FusionFeatureEngineer()
        self.fusion_xgboost = FusionXGBoostPredictor()
        self.fusion_rf = FusionRandomForestPredictor()
        self.deep_fusion = DeepFusionNetwork() if TENSORFLOW_AVAILABLE else None
        
        # ç›®æ¨™è®Šæ•¸
        self.target_column = 'vd_speed_mean'
        
        print("ğŸ”— VD+eTagèåˆå¼•æ“åˆå§‹åŒ–")
        print(f"   ğŸ“ èåˆæ•¸æ“š: {self.fusion_folder}")
        print(f"   ğŸ¤– æ¨¡å‹ç›®éŒ„: {self.models_folder}")
        print(f"   ğŸ¯ é æ¸¬ç›®æ¨™: {self.target_column}")
    
    def load_fusion_data(self, sample_rate: float = 1.0) -> pd.DataFrame:
        """è¼‰å…¥èåˆæ•¸æ“š"""
        print("ğŸ“Š è¼‰å…¥VD+eTagèåˆæ•¸æ“š...")
        
        if not self.fusion_folder.exists():
            raise FileNotFoundError(f"èåˆæ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {self.fusion_folder}")
        
        # æ”¶é›†æ‰€æœ‰èåˆæ•¸æ“š
        all_data = []
        date_folders = [d for d in self.fusion_folder.iterdir() 
                       if d.is_dir() and d.name.count('-') == 2]
        
        print(f"   ğŸ” ç™¼ç¾ {len(date_folders)} å€‹èåˆæ—¥æœŸ")
        
        for date_folder in sorted(date_folders):
            fusion_file = date_folder / "fusion_features.csv"
            
            if fusion_file.exists():
                try:
                    df = pd.read_csv(fusion_file, low_memory=True)
                    
                    # æ¡æ¨£
                    if sample_rate < 1.0:
                        df = df.sample(frac=sample_rate, random_state=42)
                    
                    all_data.append(df)
                    print(f"      âœ… {date_folder.name}: {len(df):,} ç­†è¨˜éŒ„")
                    
                except Exception as e:
                    print(f"      âŒ {date_folder.name}: è¼‰å…¥å¤±æ•— - {e}")
        
        if not all_data:
            raise ValueError("æ²’æœ‰å¯ç”¨çš„èåˆæ•¸æ“š")
        
        # åˆä½µæ•¸æ“š
        combined_df = pd.concat(all_data, ignore_index=True)
        combined_df = combined_df.sort_values('update_time').reset_index(drop=True)
        
        print(f"   âœ… èåˆæ•¸æ“šè¼‰å…¥å®Œæˆ: {len(combined_df):,} ç­†è¨˜éŒ„")
        return combined_df
    
    def prepare_fusion_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """æº–å‚™èåˆè¨“ç·´æ•¸æ“š"""
        print("ğŸ”§ æº–å‚™èåˆè¨“ç·´æ•¸æ“š...")
        
        # æª¢æŸ¥ç›®æ¨™æ¬„ä½
        if self.target_column not in df.columns:
            raise ValueError(f"ç›®æ¨™æ¬„ä½ä¸å­˜åœ¨: {self.target_column}")
        
        # ç‰¹å¾µå·¥ç¨‹
        df_features = self.feature_engineer.fit_transform(df, [self.target_column])
        
        # ç¢ºä¿æœ‰è¶³å¤ çš„æ•¸æ“š
        if len(df_features) < 1000:
            raise ValueError(f"èåˆæ•¸æ“šé‡ä¸è¶³ï¼Œåªæœ‰ {len(df_features)} ç­†è¨˜éŒ„")
        
        # æº–å‚™ç‰¹å¾µå’Œç›®æ¨™
        feature_cols = self.feature_engineer.feature_names
        X = df_features[feature_cols].values
        y = df_features[self.target_column].values
        
        # æ™‚é–“åºåˆ—åˆ†å‰²ï¼ˆä¿æŒæ™‚é–“é †åºï¼‰
        split_idx = int(len(X) * 0.8)
        X_train = X[:split_idx]
        X_test = X[split_idx:]
        y_train = y[:split_idx]
        y_test = y[split_idx:]
        
        print(f"   âœ… èåˆæ•¸æ“šæº–å‚™å®Œæˆ")
        print(f"      ğŸ“Š ç‰¹å¾µæ•¸: {X.shape[1]}")
        print(f"      ğŸš‚ è¨“ç·´é›†: {len(X_train):,} ç­†")
        print(f"      ğŸ§ª æ¸¬è©¦é›†: {len(X_test):,} ç­†")
        print(f"      ğŸ”— VDç‰¹å¾µ: {len(self.feature_engineer.vd_features)}")
        print(f"      ğŸ·ï¸ eTagç‰¹å¾µ: {len(self.feature_engineer.etag_features)}")
        print(f"      âš¡ èåˆç‰¹å¾µ: {len(self.feature_engineer.fusion_features)}")
        
        return X_train, X_test, y_train, y_test
    
    def train_fusion_models(self, X_train: np.ndarray, y_train: np.ndarray,
                           X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, Any]:
        """è¨“ç·´æ‰€æœ‰èåˆæ¨¡å‹"""
        print("ğŸš€ é–‹å§‹è¨“ç·´VD+eTagèåˆæ¨¡å‹")
        print("=" * 60)
        
        results = {}
        
        # 1. èåˆXGBoostï¼ˆä¸»åŠ›æ¨¡å‹ï¼‰
        print("\nâš¡ è¨“ç·´èåˆXGBoostæ¨¡å‹...")
        xgb_train_result = self.fusion_xgboost.train(
            X_train, y_train, 
            self.feature_engineer.feature_names,
            self.feature_engineer.vd_features,
            self.feature_engineer.etag_features,
            self.feature_engineer.fusion_features
        )
        
        xgb_pred = self.fusion_xgboost.predict(X_test)
        xgb_metrics = self._calculate_metrics(y_test, xgb_pred)
        
        results['fusion_xgboost'] = {
            'training_result': xgb_train_result,
            'metrics': xgb_metrics,
            'status': 'completed'
        }
        print(f"   âœ… èåˆXGBoost - RMSE: {xgb_metrics['rmse']:.2f}, RÂ²: {xgb_metrics['r2']:.3f}")
        
        # 2. èåˆéš¨æ©Ÿæ£®æ—
        print("\nğŸŒ² è¨“ç·´èåˆéš¨æ©Ÿæ£®æ—æ¨¡å‹...")
        rf_train_result = self.fusion_rf.train(X_train, y_train, self.feature_engineer.feature_names)
        rf_pred = self.fusion_rf.predict(X_test)
        rf_metrics = self._calculate_metrics(y_test, rf_pred)
        
        results['fusion_random_forest'] = {
            'training_result': rf_train_result,
            'metrics': rf_metrics,
            'status': 'completed'
        }
        print(f"   âœ… èåˆéš¨æ©Ÿæ£®æ— - RMSE: {rf_metrics['rmse']:.2f}, RÂ²: {rf_metrics['r2']:.3f}")
        
        # 3. æ·±åº¦èåˆç¶²çµ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.deep_fusion and TENSORFLOW_AVAILABLE and len(X_train) >= 5000:
            try:
                print("\nğŸ§  è¨“ç·´æ·±åº¦èåˆç¶²çµ¡...")
                
                # åˆ†é›¢ä¸åŒé¡å‹çš„ç‰¹å¾µ
                X_vd_train, X_etag_train, X_fusion_train = self._separate_features(X_train)
                X_vd_test, X_etag_test, X_fusion_test = self._separate_features(X_test)
                
                deep_train_result = self.deep_fusion.train(
                    X_vd_train, X_etag_train, X_fusion_train, y_train
                )
                
                deep_pred = self.deep_fusion.predict(X_vd_test, X_etag_test, X_fusion_test)
                deep_metrics = self._calculate_metrics(y_test, deep_pred)
                
                results['deep_fusion'] = {
                    'training_result': deep_train_result,
                    'metrics': deep_metrics,
                    'status': 'completed'
                }
                print(f"   âœ… æ·±åº¦èåˆç¶²çµ¡ - RMSE: {deep_metrics['rmse']:.2f}, RÂ²: {deep_metrics['r2']:.3f}")
                
            except Exception as e:
                results['deep_fusion'] = {'status': 'error', 'error': str(e)}
                print(f"   âŒ æ·±åº¦èåˆç¶²çµ¡è¨“ç·´å¤±æ•—: {e}")
        else:
            reason = "TensorFlowæœªå®‰è£" if not TENSORFLOW_AVAILABLE else "æ•¸æ“šé‡ä¸è¶³"
            results['deep_fusion'] = {'status': 'skipped', 'reason': reason}
            print(f"   âš ï¸ æ·±åº¦èåˆç¶²çµ¡è·³é: {reason}")
        
        # èåˆæ¨¡å‹æ’è¡Œ
        print(f"\nğŸ† èåˆæ¨¡å‹æ€§èƒ½æ’è¡Œ:")
        model_scores = []
        for model_name, result in results.items():
            if result['status'] == 'completed':
                model_scores.append((model_name, result['metrics']['r2']))
        
        model_scores.sort(key=lambda x: x[1], reverse=True)
        for i, (model, score) in enumerate(model_scores, 1):
            emoji = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰"
            print(f"   {emoji} {model}: RÂ² = {score:.3f}")
        
        return results
    
    def _separate_features(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """åˆ†é›¢ä¸åŒé¡å‹çš„ç‰¹å¾µç”¨æ–¼æ·±åº¦å­¸ç¿’"""
        feature_names = self.feature_engineer.feature_names
        vd_indices = [i for i, name in enumerate(feature_names) if name in self.feature_engineer.vd_features]
        etag_indices = [i for i, name in enumerate(feature_names) if name in self.feature_engineer.etag_features]
        fusion_indices = [i for i, name in enumerate(feature_names) if name in self.feature_engineer.fusion_features]
        
        X_vd = X[:, vd_indices] if vd_indices else np.zeros((X.shape[0], 1))
        X_etag = X[:, etag_indices] if etag_indices else np.zeros((X.shape[0], 1))
        X_fusion = X[:, fusion_indices] if fusion_indices else np.zeros((X.shape[0], 1))
        
        return X_vd, X_etag, X_fusion
    
    def _calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:
        """è¨ˆç®—è©•ä¼°æŒ‡æ¨™"""
        return {
            'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
            'mae': mean_absolute_error(y_true, y_pred),
            'r2': r2_score(y_true, y_pred),
            'mape': np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100
        }
    
    def compare_with_vd_only(self, X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, Any]:
        """èˆ‡VDå–®æºæ¨¡å‹æ¯”è¼ƒ"""
        print("ğŸ“Š èˆ‡VDå–®æºæ¨¡å‹æ€§èƒ½æ¯”è¼ƒ...")
        
        comparison_results = {
            'fusion_models': {},
            'vd_only_baseline': {},
            'improvement': {}
        }
        
        # èåˆæ¨¡å‹æ€§èƒ½
        if self.fusion_xgboost.is_trained:
            fusion_pred = self.fusion_xgboost.predict(X_test)
            fusion_metrics = self._calculate_metrics(y_test, fusion_pred)
            comparison_results['fusion_models']['xgboost'] = fusion_metrics
        
        if self.fusion_rf.is_trained:
            rf_pred = self.fusion_rf.predict(X_test)
            rf_metrics = self._calculate_metrics(y_test, rf_pred)
            comparison_results['fusion_models']['random_forest'] = rf_metrics
        
        # å‰µå»ºVDå–®æºåŸºç·šï¼ˆä½¿ç”¨ç›¸åŒæ•¸æ“šçš„VDç‰¹å¾µï¼‰
        vd_features_indices = [i for i, name in enumerate(self.feature_engineer.feature_names) 
                              if name in self.feature_engineer.vd_features]
        
        if vd_features_indices:
            X_vd_only = X_test[:, vd_features_indices]
            
            # è¨“ç·´VDå–®æºXGBoostä½œç‚ºåŸºç·š
            vd_baseline = xgb.XGBRegressor(
                max_depth=8, learning_rate=0.1, n_estimators=300, random_state=42
            )
            
            # ä½¿ç”¨è¨“ç·´é›†çš„VDç‰¹å¾µè¨“ç·´åŸºç·š
            X_train_vd = self.last_X_train[:, vd_features_indices] if hasattr(self, 'last_X_train') else X_vd_only
            y_train_vd = self.last_y_train if hasattr(self, 'last_y_train') else y_test
            
            vd_baseline.fit(X_train_vd, y_train_vd)
            vd_pred = vd_baseline.predict(X_vd_only)
            vd_metrics = self._calculate_metrics(y_test, vd_pred)
            
            comparison_results['vd_only_baseline'] = vd_metrics
            
            # è¨ˆç®—æ”¹å–„å¹…åº¦
            if self.fusion_xgboost.is_trained:
                fusion_r2 = comparison_results['fusion_models']['xgboost']['r2']
                vd_r2 = vd_metrics['r2']
                r2_improvement = ((fusion_r2 - vd_r2) / vd_r2) * 100 if vd_r2 > 0 else 0
                
                comparison_results['improvement'] = {
                    'r2_improvement_percent': r2_improvement,
                    'rmse_reduction': vd_metrics['rmse'] - comparison_results['fusion_models']['xgboost']['rmse'],
                    'mae_reduction': vd_metrics['mae'] - comparison_results['fusion_models']['xgboost']['mae']
                }
                
                print(f"   ğŸ“ˆ RÂ²æ”¹å–„: {r2_improvement:+.2f}%")
                print(f"   ğŸ“‰ RMSEé™ä½: {comparison_results['improvement']['rmse_reduction']:.3f}")
        
        return comparison_results
    
    def predict_15_minutes(self, current_data: pd.DataFrame, 
                          use_ensemble: bool = True) -> Dict[str, Any]:
        """15åˆ†é˜èåˆé æ¸¬"""
        print("ğŸ¯ åŸ·è¡ŒVD+eTagèåˆé æ¸¬...")
        
        if current_data.empty:
            return {'error': 'è¼¸å…¥æ•¸æ“šç‚ºç©º', 'timestamp': datetime.now().isoformat()}
        
        # ç‰¹å¾µå·¥ç¨‹
        processed_data = self.feature_engineer.transform(current_data, [self.target_column])
        
        if processed_data.empty:
            return {'error': 'ç‰¹å¾µå·¥ç¨‹å¾Œæ•¸æ“šç‚ºç©º', 'timestamp': datetime.now().isoformat()}
        
        # ç²å–æœ€æ–°æ•¸æ“šé»
        latest_features = processed_data[self.feature_engineer.feature_names].iloc[-1:].values
        
        predictions = {}
        
        # èåˆXGBoosté æ¸¬
        if self.fusion_xgboost.is_trained:
            xgb_pred = self.fusion_xgboost.predict(latest_features)[0]
            predictions['fusion_xgboost'] = {
                'predicted_speed': round(float(xgb_pred), 1),
                'confidence': 90,
                'model_type': 'èåˆXGBoost',
                'vd_contribution': f"{self.fusion_xgboost.vd_contribution:.1%}",
                'etag_contribution': f"{self.fusion_xgboost.etag_contribution:.1%}",
                'fusion_contribution': f"{self.fusion_xgboost.fusion_contribution:.1%}"
            }
        
        # èåˆéš¨æ©Ÿæ£®æ—é æ¸¬
        if self.fusion_rf.is_trained:
            rf_pred = self.fusion_rf.predict(latest_features)[0]
            predictions['fusion_random_forest'] = {
                'predicted_speed': round(float(rf_pred), 1),
                'confidence': 85,
                'model_type': 'èåˆéš¨æ©Ÿæ£®æ—'
            }
        
        # æ·±åº¦èåˆç¶²çµ¡é æ¸¬
        if self.deep_fusion and self.deep_fusion.is_trained:
            try:
                X_vd, X_etag, X_fusion = self._separate_features(latest_features)
                deep_pred = self.deep_fusion.predict(X_vd, X_etag, X_fusion)[0]
                predictions['deep_fusion'] = {
                    'predicted_speed': round(float(deep_pred), 1),
                    'confidence': 88,
                    'model_type': 'æ·±åº¦èåˆç¶²çµ¡'
                }
            except Exception as e:
                print(f"   âš ï¸ æ·±åº¦èåˆé æ¸¬å¤±æ•—: {e}")
        
        # é›†æˆé æ¸¬
        if predictions and use_ensemble:
            speeds = [pred['predicted_speed'] for pred in predictions.values()]
            confidences = [pred['confidence'] for pred in predictions.values()]
            
            # åŠ æ¬Šå¹³å‡
            weighted_speed = sum(s * c for s, c in zip(speeds, confidences)) / sum(confidences)
            max_confidence = max(confidences)
            
            # äº¤é€šç‹€æ…‹åˆ†é¡
            traffic_status = self._classify_traffic_status(weighted_speed)
            
            result = {
                'predicted_speed': round(weighted_speed, 1),
                'traffic_status': traffic_status,
                'confidence': max_confidence,
                'prediction_time': datetime.now().isoformat(),
                'fusion_models_used': len(predictions),
                'individual_predictions': predictions,
                'fusion_advantages': {
                    'vd_instant_features': 'ç¬æ™‚äº¤é€šç‹€æ…‹',
                    'etag_travel_time': 'è·¯æ®µæ—…è¡Œæ™‚é–“',
                    'spatial_consistency': 'ç©ºé–“ä¸€è‡´æ€§é©—è­‰',
                    'multi_source_validation': 'å¤šæºæ•¸æ“šé©—è­‰'
                },
                'metadata': {
                    'prediction_horizon': '15åˆ†é˜',
                    'target_route': 'åœ‹é“1è™Ÿåœ“å±±-ä¸‰é‡è·¯æ®µ',
                    'fusion_engine_version': '1.0'
                }
            }
        else:
            result = {
                'error': 'æ²’æœ‰å¯ç”¨çš„èåˆæ¨¡å‹' if not predictions else 'å–®æ¨¡å‹é æ¸¬',
                'individual_predictions': predictions,
                'prediction_time': datetime.now().isoformat()
            }
        
        return result
    
    def _classify_traffic_status(self, speed: float) -> str:
        """äº¤é€šç‹€æ…‹åˆ†é¡"""
        if speed >= 80:
            return "æš¢é€šğŸŸ¢"
        elif speed >= 50:
            return "ç·©æ…¢ğŸŸ¡"
        else:
            return "æ“å µğŸ”´"
    
    def save_fusion_models(self):
        """ä¿å­˜æ‰€æœ‰èåˆæ¨¡å‹"""
        print("ğŸ’¾ ä¿å­˜èåˆæ¨¡å‹...")
        
        # ä¿å­˜ç‰¹å¾µå·¥ç¨‹å™¨
        with open(self.models_folder / "fusion_feature_engineer.pkl", 'wb') as f:
            pickle.dump(self.feature_engineer, f)
        
        # ä¿å­˜å„èåˆæ¨¡å‹
        if self.fusion_xgboost.is_trained:
            self.fusion_xgboost.save_model(self.models_folder)
            print("   âœ… èåˆXGBoostæ¨¡å‹å·²ä¿å­˜")
        
        if self.fusion_rf.is_trained:
            self.fusion_rf.save_model(self.models_folder)
            print("   âœ… èåˆéš¨æ©Ÿæ£®æ—æ¨¡å‹å·²ä¿å­˜")
        
        if self.deep_fusion and self.deep_fusion.is_trained:
            self.deep_fusion.save_model(self.models_folder)
            print("   âœ… æ·±åº¦èåˆç¶²çµ¡å·²ä¿å­˜")
        
        # ä¿å­˜èåˆç³»çµ±é…ç½®
        fusion_config = {
            'target_column': self.target_column,
            'feature_counts': {
                'vd_features': len(self.feature_engineer.vd_features),
                'etag_features': len(self.feature_engineer.etag_features),
                'fusion_features': len(self.feature_engineer.fusion_features),
                'total_features': len(self.feature_engineer.feature_names)
            },
            'models_available': {
                'fusion_xgboost': self.fusion_xgboost.is_trained,
                'fusion_random_forest': self.fusion_rf.is_trained,
                'deep_fusion': self.deep_fusion.is_trained if self.deep_fusion else False
            },
            'save_time': datetime.now().isoformat()
        }
        
        with open(self.models_folder / "fusion_system_config.json", 'w') as f:
            json.dump(fusion_config, f, indent=2)
        
        print(f"   ğŸ“ èåˆæ¨¡å‹ä¿å­˜ç›®éŒ„: {self.models_folder}")
    
    def load_fusion_models(self):
        """è¼‰å…¥èåˆæ¨¡å‹"""
        print("ğŸ“‚ è¼‰å…¥èåˆæ¨¡å‹...")
        
        config_file = self.models_folder / "fusion_system_config.json"
        if not config_file.exists():
            raise FileNotFoundError("æ‰¾ä¸åˆ°èåˆç³»çµ±é…ç½®æ–‡ä»¶")
        
        with open(config_file, 'r') as f:
            config = json.load(f)
        
        self.target_column = config['target_column']
        
        # è¼‰å…¥ç‰¹å¾µå·¥ç¨‹å™¨
        with open(self.models_folder / "fusion_feature_engineer.pkl", 'rb') as f:
            self.feature_engineer = pickle.load(f)
        
        # è¼‰å…¥å„èåˆæ¨¡å‹
        if config['models_available']['fusion_xgboost']:
            self.fusion_xgboost.load_model(self.models_folder)
            print("   âœ… èåˆXGBoostæ¨¡å‹å·²è¼‰å…¥")
        
        if config['models_available']['fusion_random_forest']:
            self.fusion_rf.load_model(self.models_folder)
            print("   âœ… èåˆéš¨æ©Ÿæ£®æ—æ¨¡å‹å·²è¼‰å…¥")
        
        if config['models_available']['deep_fusion'] and TENSORFLOW_AVAILABLE:
            self.deep_fusion.load_model(self.models_folder)
            print("   âœ… æ·±åº¦èåˆç¶²çµ¡å·²è¼‰å…¥")
        
        print("ğŸ¯ èåˆæ¨¡å‹è¼‰å…¥å®Œæˆï¼Œå¯é€²è¡Œå¤šæºé æ¸¬")


# ============================================================
# ä¾¿åˆ©å‡½æ•¸
# ============================================================

def train_fusion_system(base_folder: str = "data", sample_rate: float = 1.0) -> VDETagFusionEngine:
    """è¨“ç·´å®Œæ•´çš„VD+eTagèåˆç³»çµ±"""
    print("ğŸš€ å•Ÿå‹•VD+eTagèåˆç³»çµ±è¨“ç·´")
    print("=" * 70)
    
    # åˆå§‹åŒ–èåˆå¼•æ“
    fusion_engine = VDETagFusionEngine(base_folder)
    
    try:
        # è¼‰å…¥èåˆæ•¸æ“š
        df = fusion_engine.load_fusion_data(sample_rate)
        
        # æº–å‚™è¨“ç·´æ•¸æ“š
        X_train, X_test, y_train, y_test = fusion_engine.prepare_fusion_data(df)
        
        # ä¿å­˜è¨“ç·´æ•¸æ“šä¾›æ¯”è¼ƒä½¿ç”¨
        fusion_engine.last_X_train = X_train
        fusion_engine.last_y_train = y_train
        
        # è¨“ç·´æ‰€æœ‰èåˆæ¨¡å‹
        training_results = fusion_engine.train_fusion_models(X_train, y_train, X_test, y_test)
        
        # èˆ‡VDå–®æºæ¨¡å‹æ¯”è¼ƒ
        comparison_results = fusion_engine.compare_with_vd_only(X_test, y_test)
        
        # ä¿å­˜èåˆæ¨¡å‹
        fusion_engine.save_fusion_models()
        
        print(f"\nğŸ‰ VD+eTagèåˆç³»çµ±è¨“ç·´å®Œæˆï¼")
        print(f"ğŸ“Š èåˆè¨“ç·´çµæœ:")
        for model_name, result in training_results.items():
            if result['status'] == 'completed':
                metrics = result['metrics']
                print(f"   â€¢ {model_name}: RMSE={metrics['rmse']:.2f}, RÂ²={metrics['r2']:.3f}")
        
        if 'improvement' in comparison_results:
            improvement = comparison_results['improvement']
            print(f"\nğŸ“ˆ ç›¸æ¯”VDå–®æºæ¨¡å‹çš„æ”¹å–„:")
            print(f"   â€¢ RÂ²æå‡: {improvement['r2_improvement_percent']:+.2f}%")
            print(f"   â€¢ RMSEé™ä½: {improvement['rmse_reduction']:.3f}")
        
        return fusion_engine
        
    except Exception as e:
        print(f"âŒ èåˆç³»çµ±è¨“ç·´å¤±æ•—: {e}")
        raise


def quick_fusion_prediction() -> Dict[str, Any]:
    """å¿«é€Ÿèåˆé æ¸¬æ¼”ç¤º"""
    print("ğŸ¯ å¿«é€ŸVD+eTagèåˆé æ¸¬æ¼”ç¤º")
    print("-" * 40)
    
    try:
        # è¼‰å…¥èåˆç³»çµ±
        fusion_engine = VDETagFusionEngine()
        fusion_engine.load_fusion_models()
        
        # å‰µå»ºæ¨¡æ“¬èåˆæ•¸æ“š
        current_time = datetime.now()
        mock_fusion_data = pd.DataFrame({
            'date': [current_time.strftime('%Y-%m-%d')],
            'update_time': [current_time],
            'vd_id': ['VD-N1-N-25-å°åŒ—'],
            'vd_speed_mean': [75.0],
            'vd_volume_total_sum': [125.0],
            'vd_occupancy_mean': [45.0],
            'vd_volume_small_sum': [100.0],
            'vd_volume_large_sum': [20.0],
            'vd_volume_truck_sum': [5.0],
            'etag_travel_time_primary': [90.0],
            'etag_speed_primary': [72.0],
            'etag_volume_primary': [85.0],
            'spatial_consistency_score': [0.85],
            'speed_difference': [3.0],
            'flow_correlation_index': [0.78]
        })
        
        # 15åˆ†é˜èåˆé æ¸¬
        prediction = fusion_engine.predict_15_minutes(mock_fusion_data)
        
        print(f"âœ… VD+eTagèåˆé æ¸¬çµæœ:")
        if 'predicted_speed' in prediction:
            print(f"   ğŸš— é æ¸¬é€Ÿåº¦: {prediction['predicted_speed']} km/h")
            print(f"   ğŸš¥ äº¤é€šç‹€æ…‹: {prediction['traffic_status']}")
            print(f"   ğŸ¯ ç½®ä¿¡åº¦: {prediction['confidence']}%")
            print(f"   ğŸ”— èåˆæ¨¡å‹æ•¸: {prediction['fusion_models_used']}")
            
            if 'fusion_advantages' in prediction:
                print(f"   ğŸ’¡ èåˆå„ªå‹¢:")
                for key, value in prediction['fusion_advantages'].items():
                    print(f"      â€¢ {value}")
        
        return prediction
        
    except Exception as e:
        print(f"âŒ èåˆé æ¸¬æ¼”ç¤ºå¤±æ•—: {e}")
        return {'error': str(e)}


if __name__ == "__main__":
    print("ğŸ”— VD+eTagæ•¸æ“šèåˆå¼•æ“")
    print("=" * 70)
    print("ğŸ¯ æ ¸å¿ƒåŠŸèƒ½:")
    print("   ğŸ”— å¤šæºæ•¸æ“šç‰¹å¾µèåˆ")
    print("   ğŸ§® æ™ºèƒ½ç‰¹å¾µå·¥ç¨‹ç®¡é“")
    print("   âš¡ èåˆXGBoostä¸»åŠ›æ¨¡å‹")
    print("   ğŸŒ² èåˆéš¨æ©Ÿæ£®æ—åŸºç·š")
    print("   ğŸ§  æ·±åº¦èåˆç¥ç¶“ç¶²çµ¡")
    print("   ğŸ“Š æ¨¡å‹æ€§èƒ½æ¯”è¼ƒåˆ†æ")
    print("=" * 70)
    
    # æª¢æŸ¥æ•¸æ“šå¯ç”¨æ€§
    fusion_engine = VDETagFusionEngine()
    
    try:
        # æª¢æŸ¥èåˆæ•¸æ“š
        fusion_folder = fusion_engine.fusion_folder
        if fusion_folder.exists():
            date_folders = [d for d in fusion_folder.iterdir() 
                           if d.is_dir() and d.name.count('-') == 2]
            
            fusion_dates = []
            for date_folder in date_folders:
                fusion_file = date_folder / "fusion_features.csv"
                if fusion_file.exists():
                    fusion_dates.append(date_folder.name)
            
            if fusion_dates:
                print(f"âœ… ç™¼ç¾ {len(fusion_dates)} å€‹èåˆæ•¸æ“šæ—¥æœŸ")
                for date_str in sorted(fusion_dates):
                    print(f"   â€¢ {date_str}")
                
                response = input("\né–‹å§‹VD+eTagèåˆæ¨¡å‹è¨“ç·´ï¼Ÿ(y/N): ")
                
                if response.lower() in ['y', 'yes']:
                    # é¸æ“‡æ¡æ¨£ç‡
                    sample_response = input("ä½¿ç”¨æ¡æ¨£ç‡ (0.1-1.0, å›è»Šé»˜èª0.3): ")
                    try:
                        sample_rate = float(sample_response) if sample_response else 0.3
                        sample_rate = max(0.1, min(1.0, sample_rate))
                    except:
                        sample_rate = 0.3
                    
                    print(f"ğŸ¯ ä½¿ç”¨æ¡æ¨£ç‡: {sample_rate}")
                    
                    # é–‹å§‹èåˆè¨“ç·´
                    trained_fusion_engine = train_fusion_system(sample_rate=sample_rate)
                    
                    # æ¼”ç¤ºèåˆé æ¸¬
                    print(f"\n" + "="*50)
                    demo_response = input("åŸ·è¡ŒVD+eTagèåˆé æ¸¬æ¼”ç¤ºï¼Ÿ(y/N): ")
                    
                    if demo_response.lower() in ['y', 'yes']:
                        quick_fusion_prediction()
                
                else:
                    print("ğŸ’¡ æ‚¨å¯ä»¥ç¨å¾ŒåŸ·è¡Œ:")
                    print("   python -c \"from src.fusion_engine import train_fusion_system; train_fusion_system()\"")
            else:
                print("âŒ æ²’æœ‰æ‰¾åˆ°èåˆæ•¸æ“š")
                print("ğŸ’¡ è«‹å…ˆåŸ·è¡Œæ™‚ç©ºå°é½Š: python src/spatial_temporal_aligner.py")
        else:
            print("âŒ èåˆæ•¸æ“šç›®éŒ„ä¸å­˜åœ¨")
            print("ğŸ’¡ è«‹å…ˆåŸ·è¡Œå®Œæ•´æ•¸æ“šè™•ç†æµç¨‹:")
            print("   1. VDæ•¸æ“šè™•ç†: python src/data_loader.py")
            print("   2. eTagæ•¸æ“šè™•ç†: python src/etag_processor.py")
            print("   3. æ™‚ç©ºå°é½Š: python src/spatial_temporal_aligner.py")
            print("   4. èåˆè¨“ç·´: python src/fusion_engine.py")
    
    except Exception as e:
        print(f"âŒ ç³»çµ±æª¢æŸ¥å¤±æ•—: {e}")
    
    print(f"\nğŸ¯ VD+eTagèåˆç³»çµ±ç‰¹è‰²:")
    print("   ğŸ”— å¤šæºç‰¹å¾µèåˆ - VDç¬æ™‚+eTagå€é–“ç‰¹å¾µ")
    print("   âš¡ èåˆXGBoost - ä¸»åŠ›é«˜ç²¾åº¦æ¨¡å‹")
    print("   ğŸŒ² èåˆéš¨æ©Ÿæ£®æ— - ç©©å®šå¯é åŸºç·š")
    print("   ğŸ§  æ·±åº¦èåˆç¶²çµ¡ - æ¢ç´¢æ€§ç¥ç¶“ç¶²çµ¡")
    print("   ğŸ“Š æ€§èƒ½æ¯”è¼ƒåˆ†æ - é‡åŒ–èåˆæ•ˆæœ")
    print("   ğŸ¯ 15åˆ†é˜ç²¾æº–é æ¸¬ - å¤šæºé©—è­‰æå‡æº–ç¢ºç‡")
    
    print(f"\nğŸ“ˆ é æœŸèåˆæ•ˆæœ:")
    print("   â€¢ VDå–®æºæ¨¡å‹: RÂ²=1.000 (è¨“ç·´æ•¸æ“š)")
    print("   â€¢ èåˆæ¨¡å‹ç›®æ¨™: RÂ²>0.95 + å¯¦éš›é æ¸¬æå‡")
    print("   â€¢ ç©ºé–“ä¸€è‡´æ€§é©—è­‰: æ¸›å°‘ç•°å¸¸é æ¸¬")
    print("   â€¢ å¤šæºæ•¸æ“šäº’è£œ: æå‡é æ¸¬ç©©å®šæ€§")
    
    print(f"\nğŸš€ Ready for VD+eTag Fusion! ğŸš€")