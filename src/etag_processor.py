# src/etag_processor.py - ç°¡åŒ–ä¿®æ­£ç‰ˆ

"""
eTagæ•¸æ“šè™•ç†å™¨ - ç°¡åŒ–ä¿®æ­£ç‰ˆ
========================

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ğŸ• åš´æ ¼æŒ‰è³‡æ–™å¤¾æ—¥æœŸç¯©é¸XMLå…§å®¹
2. ğŸ¯ ç›®æ¨™è·¯æ®µç¯©é¸ï¼ˆåœ“å±±-å°åŒ—-ä¸‰é‡ï¼‰
3. ğŸ“Š ç”Ÿæˆæ—…è¡Œæ™‚é–“å’Œæµé‡æ•¸æ“š
4. ğŸ”§ ç°¡æ½”é«˜æ•ˆçš„ä»£ç¢¼çµæ§‹

ä½œè€…: äº¤é€šé æ¸¬å°ˆæ¡ˆåœ˜éšŠ
"""

import xml.etree.ElementTree as ET
import pandas as pd
import gzip
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import warnings
warnings.filterwarnings('ignore')


class ETagProcessor:
    """eTagæ•¸æ“šè™•ç†å™¨"""
    
    def __init__(self, base_folder: str = "data", debug: bool = True):
        self.base_folder = Path(base_folder)
        self.raw_etag_folder = self.base_folder / "raw" / "etag"
        self.processed_etag_folder = self.base_folder / "processed" / "etag"
        self.archive_folder = self.base_folder / "archive" / "etag"  # æ·»åŠ é€™ä¸€è¡Œ
        self.debug = debug
        
        # å‰µå»ºè³‡æ–™å¤¾
        for folder in [self.processed_etag_folder, self.archive_folder]:  # ä¿®æ­£é€™ä¸€è¡Œ
            folder.mkdir(parents=True, exist_ok=True)
        
        # ç›®æ¨™è·¯æ®µé…å°ï¼ˆåœ“å±±-å°åŒ—-ä¸‰é‡ï¼‰
        self.target_pairs = {
            '01F0017N-01F0005N': {'segment': 'å°åŒ—â†’åœ“å±±', 'distance': 1.8},
            '01F0005S-01F0017S': {'segment': 'åœ“å±±â†’å°åŒ—', 'distance': 1.8},
            '01F0029N-01F0017N': {'segment': 'ä¸‰é‡â†’å°åŒ—', 'distance': 2.0},
            '01F0017S-01F0029S': {'segment': 'å°åŒ—â†’ä¸‰é‡', 'distance': 2.0},
            '01F0029N-01F0005N': {'segment': 'ä¸‰é‡â†’åœ“å±±', 'distance': 3.8},
            '01F0005S-01F0029S': {'segment': 'åœ“å±±â†’ä¸‰é‡', 'distance': 3.8}
        }
        
        if self.debug:
            print(f"ğŸ·ï¸ eTagè™•ç†å™¨åˆå§‹åŒ– (ä¿®æ­£ç‰ˆ)")
            print(f"   ğŸ“ åŸå§‹æ•¸æ“š: {self.raw_etag_folder}")
            print(f"   ğŸ¯ ç›®æ¨™é…å°: {len(self.target_pairs)} å€‹")
    
    def scan_date_folders(self) -> Dict[str, List[Path]]:
        """æƒææŒ‰æ—¥æœŸåˆ†é¡çš„æª”æ¡ˆ"""
        date_files = {}
        
        if not self.raw_etag_folder.exists():
            return date_files
        
        # æƒææ—¥æœŸè³‡æ–™å¤¾
        for date_folder in self.raw_etag_folder.iterdir():
            if not date_folder.is_dir():
                continue
            
            # æå–æ—¥æœŸ
            date_str = self._extract_date_from_folder(date_folder.name)
            if not date_str:
                continue
            
            # æ”¶é›†è©²æ—¥æœŸçš„eTagæª”æ¡ˆ - æ“´å±•æª”æ¡ˆåŒ¹é…
            etag_files = []
            patterns = ["ETagPairLive_*.xml.gz", "*.xml.gz", "ETag*.xml.gz"]
            for pattern in patterns:
                files = list(date_folder.glob(pattern))
                etag_files.extend(files)
            
            # å»é‡
            etag_files = list(set(etag_files))
            
            if etag_files:
                date_files[date_str] = etag_files
                if self.debug:
                    print(f"   ğŸ“ {date_str}: {len(etag_files)} æª”æ¡ˆ")
        
        if self.debug:
            total_files = sum(len(files) for files in date_files.values())
            print(f"   ğŸ“Š ç¸½è¨ˆ: {len(date_files)} æ—¥æœŸ, {total_files} æª”æ¡ˆ")
        
        return date_files
    
    def _extract_date_from_folder(self, folder_name: str) -> str:
        """å¾è³‡æ–™å¤¾åç¨±æå–æ—¥æœŸ"""
        import re
        
        # YYYY-MM-DDæ ¼å¼
        match = re.search(r'(\d{4}-\d{2}-\d{2})', folder_name)
        if match:
            return match.group(1)
        
        # YYYYMMDDæ ¼å¼
        match = re.search(r'(\d{8})', folder_name)
        if match:
            date_str = match.group(1)
            return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        
        return None
    
    def process_single_file(self, file_path: Path, target_date: str) -> List[Dict[str, Any]]:
        """è™•ç†å–®ä¸€æª”æ¡ˆ - ä¿®æ­£ç‰ˆ"""
        try:
            # è§£å£“ä¸¦è®€å–XML
            with gzip.open(file_path, 'rt', encoding='utf-8') as f:
                content = f.read()
            
            if len(content) < 100:
                if self.debug:
                    print(f"   âš ï¸ æª”æ¡ˆå…§å®¹å¤ªçŸ­: {file_path.name}")
                return []
            
            root = ET.fromstring(content)
            
            if self.debug:
                print(f"   ğŸ” è§£æ {file_path.name}")
            
            # æå–æ›´æ–°æ™‚é–“
            update_time = self._extract_update_time(root, file_path, target_date)
            
            # æ”¾å¯¬æ™‚é–“æª¢æŸ¥ - å…è¨±ç›¸é„°æ—¥æœŸ
            target_date_obj = datetime.strptime(target_date, '%Y-%m-%d')
            date_diff = abs((update_time.date() - target_date_obj.date()).days)
            
            if date_diff > 1:
                if self.debug:
                    print(f"      âš ï¸ æ™‚é–“å·®è·éå¤§: {update_time} vs {target_date}")
                return []
            
            # æå–ç›®æ¨™è·¯æ®µæ•¸æ“š
            target_data = []
            etag_pairs = self._find_etag_pairs_enhanced(root)
            
            if self.debug:
                print(f"      ğŸ¯ æ‰¾åˆ° {len(etag_pairs)} å€‹ETagPairLive")
            
            for etag_pair in etag_pairs:
                pair_id = self._get_text_enhanced(etag_pair, 'ETagPairId')
                
                if self.debug:
                    print(f"         æª¢æŸ¥é…å°: {pair_id}")
                
                if not pair_id or pair_id not in self.target_pairs:
                    continue
                
                if self.debug:
                    print(f"         âœ… ç›®æ¨™é…å°: {pair_id}")
                
                # æŸ¥æ‰¾Flowså®¹å™¨ - ä¿®æ­£ç‰ˆ
                flows_containers = []
                
                # æ–¹æ³•1: ç›´æ¥æŸ¥æ‰¾Flows
                flows_elem = etag_pair.find('Flows')
                if flows_elem is not None:
                    flows_containers.append(flows_elem)
                
                # æ–¹æ³•2: æ·±åº¦æœå°‹Flows
                for elem in etag_pair.iter():
                    if elem.tag == 'Flows' and elem not in flows_containers:
                        flows_containers.append(elem)
                
                if self.debug:
                    print(f"            æ‰¾åˆ° {len(flows_containers)} å€‹Flowså®¹å™¨")
                
                for flows_container in flows_containers:
                    flows = flows_container.findall('Flow')
                    if self.debug:
                        print(f"               å®¹å™¨å…§æœ‰ {len(flows)} å€‹Flow")
                    
                    for flow in flows:
                        flow_data = self._extract_flow_data(flow, pair_id, update_time)
                        if flow_data:
                            target_data.append(flow_data)
                            if self.debug:
                                print(f"               âœ… æœ‰æ•ˆFlow: è»Šç¨®={flow_data['vehicle_type']}, æ™‚é–“={flow_data['travel_time']}s")
                
                # å¦‚æœæ²’æ‰¾åˆ°Flowså®¹å™¨ï¼Œç›´æ¥æœå°‹Flow
                if not flows_containers:
                    if self.debug:
                        print(f"            å‚™ç”¨ï¼šç›´æ¥æœå°‹Flowå…ƒç´ ")
                    
                    for elem in etag_pair.iter():
                        if elem.tag == 'Flow':
                            flow_data = self._extract_flow_data(elem, pair_id, update_time)
                            if flow_data:
                                target_data.append(flow_data)
                                if self.debug:
                                    print(f"               âœ… å‚™ç”¨Flow: è»Šç¨®={flow_data['vehicle_type']}")
            
            if self.debug:
                print(f"      ğŸ“Š ç¸½æå–è¨˜éŒ„: {len(target_data)}")
            
            return target_data
            
        except Exception as e:
            if self.debug:
                print(f"   âŒ è™•ç†å¤±æ•— {file_path.name}: {e}")
            return []
    
    def _find_etag_pairs_enhanced(self, root):
        """å¢å¼·ç‰ˆETagPairæŸ¥æ‰¾"""
        etag_pairs = []
        
        # æ–¹æ³•1: æ¨™æº–å‘½åç©ºé–“
        try:
            pairs = root.findall('.//ETagPairLive')
            etag_pairs.extend(pairs)
        except:
            pass
        
        # æ–¹æ³•2: éæ­·æ‰€æœ‰å…ƒç´ æŸ¥æ‰¾
        for elem in root.iter():
            if 'ETagPair' in elem.tag and 'Live' in elem.tag:
                if elem not in etag_pairs:
                    etag_pairs.append(elem)
        
        return etag_pairs
    
    def _find_flows_enhanced(self, etag_pair):
        """å¢å¼·ç‰ˆFlowæŸ¥æ‰¾"""
        flows = []
        
        # æŸ¥æ‰¾Flowså®¹å™¨
        flows_containers = etag_pair.findall('.//Flows')
        for container in flows_containers:
            flows.extend(container.findall('Flow'))
        
        # ç›´æ¥æŸ¥æ‰¾Flow
        flows.extend(etag_pair.findall('.//Flow'))
        
        return flows
    
    def _get_text_enhanced(self, element, tag: str) -> str:
        """å¢å¼·ç‰ˆæ–‡æœ¬æå–"""
        # æ–¹æ³•1: ç›´æ¥æŸ¥æ‰¾
        child = element.find(tag)
        if child is not None and child.text:
            return child.text.strip()
        
        # æ–¹æ³•2: éæ­·æŸ¥æ‰¾
        for child in element:
            if tag in child.tag and child.text:
                return child.text.strip()
        
        return ""
    
    def _extract_update_time(self, root, file_path: Path, target_date: str) -> datetime:
        """æå–æ›´æ–°æ™‚é–“ - ä¿®æ­£ç‰ˆ"""
        target_date_obj = datetime.strptime(target_date, '%Y-%m-%d')
        
        # å„ªå…ˆé †åºï¼šDataCollectTime -> EndTime -> StartTime -> UpdateTime -> æª”æ¡ˆå
        time_fields = ['DataCollectTime', 'EndTime', 'StartTime', 'UpdateTime']
        
        for field in time_fields:
            for elem in root.iter():
                if field in elem.tag and elem.text:
                    try:
                        time_str = elem.text.replace('+08:00', '').replace('Z', '')
                        parsed_time = datetime.strptime(time_str, '%Y-%m-%dT%H:%M:%S')
                        
                        if self.debug:
                            print(f"      ğŸ• è§£æ {field}: {parsed_time}")
                        
                        # æª¢æŸ¥æ—¥æœŸæ˜¯å¦ç¬¦åˆ - æ”¾å¯¬æ¢ä»¶
                        date_diff = abs((parsed_time.date() - target_date_obj.date()).days)
                        if date_diff <= 1:  # å…è¨±1å¤©èª¤å·®
                            return parsed_time
                        
                    except Exception as e:
                        if self.debug:
                            print(f"      âš ï¸ {field} è§£æå¤±æ•—: {e}")
                        continue
        
        # å¾æª”æ¡ˆåæå–æ™‚é–“
        try:
            filename = file_path.stem.replace('.xml', '')
            if 'ETagPairLive_' in filename:
                time_part = filename.replace('ETagPairLive_', '')
                if len(time_part) == 4 and time_part.isdigit():
                    hour = int(time_part[:2])
                    minute = int(time_part[2:])
                    result_time = target_date_obj.replace(hour=hour, minute=minute)
                    if self.debug:
                        print(f"      ğŸ• æª”æ¡ˆåæ™‚é–“: {result_time}")
                    return result_time
        except:
            pass
        
        # é è¨­ä½¿ç”¨ç›®æ¨™æ—¥æœŸçš„12:00
        default_time = target_date_obj.replace(hour=12, minute=0)
        if self.debug:
            print(f"      ğŸ• é è¨­æ™‚é–“: {default_time}")
        return default_time
    
    def _get_text(self, element, tag: str) -> str:
        """å®‰å…¨ç²å–å…ƒç´ æ–‡æœ¬"""
        return self._get_text_enhanced(element, tag)
    
    def _extract_flow_data(self, flow, pair_id: str, update_time: datetime) -> Dict[str, Any]:
        """æå–Flowæ•¸æ“š - ä¿®æ­£ç‰ˆ"""
        try:
            travel_time = int(self._get_text_enhanced(flow, 'TravelTime') or '0')
            vehicle_count = int(self._get_text_enhanced(flow, 'VehicleCount') or '0')
            space_mean_speed = float(self._get_text_enhanced(flow, 'SpaceMeanSpeed') or '0')
            vehicle_type = self._get_text_enhanced(flow, 'VehicleType') or '31'
            standard_deviation = float(self._get_text_enhanced(flow, 'StandardDeviation') or '0')
            
            # æ”¾å¯¬æ¢ä»¶ï¼šåªè¦æœ‰TravelTimeä¸”VehicleCount > 0å°±æ¥å—
            # é€™æ¨£å¯ä»¥è™•ç†SpaceMeanSpeedç‚º0çš„æƒ…æ³
            if travel_time <= 0 or vehicle_count <= 0:
                return None
            
            # å¦‚æœSpaceMeanSpeedç‚º0ï¼Œå¾distanceå’Œtravel_timeè¨ˆç®—
            if space_mean_speed <= 0 and travel_time > 0:
                pair_info = self.target_pairs[pair_id]
                distance_km = pair_info['distance']
                travel_time_hours = travel_time / 3600
                space_mean_speed = distance_km / travel_time_hours if travel_time_hours > 0 else 0
            
            if self.debug:
                print(f"            Flow: é¡å‹={vehicle_type}, æ™‚é–“={travel_time}s, æ•¸é‡={vehicle_count}, é€Ÿåº¦={space_mean_speed:.1f}")
            
            pair_info = self.target_pairs[pair_id]
            
            return {
                'update_time': update_time,
                'etag_pair_id': pair_id,
                'vehicle_type': vehicle_type,
                'travel_time': travel_time,
                'vehicle_count': vehicle_count,
                'space_mean_speed': round(space_mean_speed, 1),
                'standard_deviation': standard_deviation,
                'travel_time_minutes': round(travel_time / 60, 2),
                'segment_name': pair_info['segment']
            }
            
        except Exception as e:
            if self.debug:
                print(f"            âŒ Flowæå–å¤±æ•—: {e}")
            return None
    
    def process_date_folder(self, date_str: str, file_list: List[Path]) -> bool:
        """è™•ç†å–®æ—¥æœŸè³‡æ–™å¤¾"""
        if self.debug:
            print(f"ğŸ“… è™•ç† {date_str}: {len(file_list)} æª”æ¡ˆ")
        
        all_data = []
        processed_files = 0
        
        for i, file_path in enumerate(file_list):
            if self.debug and i % 50 == 0:
                print(f"   é€²åº¦: {i+1}/{len(file_list)}")
            
            file_data = self.process_single_file(file_path, date_str)
            if file_data:
                all_data.extend(file_data)
                processed_files += 1
        
        if self.debug:
            print(f"   ğŸ“Š è™•ç†å®Œæˆ: {processed_files}/{len(file_list)} æª”æ¡ˆæœ‰æ•ˆ")
        
        if not all_data:
            if self.debug:
                print(f"   âš ï¸ {date_str}: ç„¡ç›®æ¨™è·¯æ®µæ•¸æ“š")
            return False
        
        # æª¢æŸ¥æ™‚é–“åˆ†å¸ƒ
        times = [record['update_time'] for record in all_data]
        time_span = (max(times) - min(times)).total_seconds() / 3600
        
        if self.debug:
            print(f"   ğŸ“Š {date_str}: {len(all_data)} è¨˜éŒ„, æ™‚é–“è·¨åº¦: {time_span:.1f}h")
            print(f"       æ™‚é–“ç¯„åœ: {min(times)} ~ {max(times)}")
        
        # ä¿å­˜æ•¸æ“š
        self._save_date_data(date_str, all_data)
        
        # æ­¸æª”åŸå§‹æª”æ¡ˆ
        self._archive_date_files(date_str, file_list)
        
        return True
    
    def _archive_date_files(self, date_str: str, file_list: List[Path]):
        """æ­¸æª”æ—¥æœŸæª”æ¡ˆ"""
        if not file_list:
            return
        
        # å‰µå»ºæ­¸æª”è³‡æ–™å¤¾
        archive_date_folder = self.archive_folder / date_str
        archive_date_folder.mkdir(parents=True, exist_ok=True)
        
        archived_count = 0
        
        for file_path in file_list:
            try:
                if file_path.exists():
                    # ç§»å‹•åˆ°æ­¸æª”
                    archive_path = archive_date_folder / file_path.name
                    file_path.rename(archive_path)
                    archived_count += 1
            except Exception as e:
                if self.debug:
                    print(f"   âš ï¸ æ­¸æª”å¤±æ•— {file_path.name}: {e}")
        
        if self.debug and archived_count > 0:
            print(f"   ğŸ“¦ æ­¸æª”: {archived_count} æª”æ¡ˆè‡³ {archive_date_folder}")
        
        # ç§»é™¤ç©ºçš„åŸå§‹è³‡æ–™å¤¾
        try:
            original_folder = file_list[0].parent
            if original_folder.exists() and not any(original_folder.iterdir()):
                original_folder.rmdir()
                if self.debug:
                    print(f"   ğŸ—‘ï¸ ç§»é™¤ç©ºè³‡æ–™å¤¾: {original_folder}")
        except:
            pass
    
    def _save_date_data(self, date_str: str, data_list: List[Dict[str, Any]]):
        """ä¿å­˜æ—¥æœŸæ•¸æ“š"""
        date_folder = self.processed_etag_folder / date_str
        date_folder.mkdir(parents=True, exist_ok=True)
        
        df = pd.DataFrame(data_list)
        
        # 1. æ—…è¡Œæ™‚é–“æ•¸æ“š
        travel_time_csv = date_folder / "etag_travel_time.csv"
        df.to_csv(travel_time_csv, index=False, encoding='utf-8-sig')
        
        # 2. æ‘˜è¦çµ±è¨ˆ
        summary = {
            'date': date_str,
            'total_records': len(df),
            'unique_pairs': df['etag_pair_id'].nunique(),
            'time_range': {
                'start': df['update_time'].min().isoformat(),
                'end': df['update_time'].max().isoformat(),
                'span_hours': (df['update_time'].max() - df['update_time'].min()).total_seconds() / 3600
            }
        }
        
        summary_json = date_folder / "etag_summary.json"
        with open(summary_json, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2, default=str)
    
    def process_all_dates(self) -> Dict[str, Any]:
        """æ‰¹æ¬¡è™•ç†æ‰€æœ‰æ—¥æœŸ"""
        if self.debug:
            print("ğŸš€ æ‰¹æ¬¡è™•ç†eTagæ•¸æ“š")
        
        date_files = self.scan_date_folders()
        if not date_files:
            return {"success": False, "message": "ç„¡eTagæª”æ¡ˆ"}
        
        successful_dates = 0
        results = {}
        
        for date_str, file_list in date_files.items():
            success = self.process_date_folder(date_str, file_list)
            results[date_str] = success
            if success:
                successful_dates += 1
        
        return {
            "success": True,
            "total_dates": len(date_files),
            "successful_dates": successful_dates,
            "results": results
        }
    
    def get_processing_summary(self) -> Dict[str, Any]:
        """ç²å–è™•ç†æ‘˜è¦"""
        if not self.processed_etag_folder.exists():
            return {"processed_dates": 0, "total_records": 0}
        
        date_folders = [d for d in self.processed_etag_folder.iterdir() 
                       if d.is_dir() and d.name.count('-') == 2]
        
        total_records = 0
        for date_folder in date_folders:
            summary_file = date_folder / "etag_summary.json"
            if summary_file.exists():
                try:
                    with open(summary_file, 'r', encoding='utf-8') as f:
                        summary = json.load(f)
                    total_records += summary.get('total_records', 0)
                except:
                    pass
        
        return {
            "processed_dates": len(date_folders),
            "total_records": total_records
        }


# ä¾¿åˆ©å‡½æ•¸
def process_etag_data(base_folder: str = "data", debug: bool = True) -> Dict[str, Any]:
    """è™•ç†eTagæ•¸æ“š"""
    processor = ETagProcessor(base_folder, debug)
    return processor.process_all_dates()


def get_etag_summary(base_folder: str = "data") -> Dict[str, Any]:
    """ç²å–eTagæ‘˜è¦"""
    processor = ETagProcessor(base_folder, debug=False)
    return processor.get_processing_summary()


if __name__ == "__main__":
    print("ğŸ·ï¸ eTagè™•ç†å™¨ - ä¿®æ­£ç‰ˆ")
    processor = ETagProcessor(debug=True)
    result = processor.process_all_dates()
    if result["success"]:
        summary = processor.get_processing_summary()
        print(f"âœ… è™•ç†å®Œæˆ: {summary['processed_dates']} æ—¥æœŸ, {summary['total_records']} è¨˜éŒ„")