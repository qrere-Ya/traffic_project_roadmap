# src/etag_processor.py - ç²¾ç°¡é«˜æ•ˆç‰ˆ

"""
eTagæ•¸æ“šè™•ç†å™¨ - ç²¾ç°¡é«˜æ•ˆç‰ˆ
========================

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ğŸ¯ æº–ç¢ºè§£æXMLï¼Œè™•ç†ç›®æ¨™è·¯æ®µï¼ˆåœ“å±±-å°åŒ—-ä¸‰é‡ï¼‰
2. ğŸ“Š è©³ç´°æå–Flowæ•¸æ“šï¼ˆåŒ…å«VehicleTypeåˆ†é¡ï¼‰
3. ğŸ“ è‡ªå‹•æ­¸æª”è™•ç†å®Œæˆçš„æª”æ¡ˆ
4. ğŸ’¾ è¼¸å‡ºç¬¦åˆVDèåˆæ ¼å¼çš„CSVæ•¸æ“š

æª”æ¡ˆè·¯å¾‘ï¼šdata/raw/etag/ETag_Data_YYYYMMDD/ETagPairLive_HHMM.xml.gz
è¼¸å‡ºæ ¼å¼ï¼šdata/processed/etag/YYYY-MM-DD/etag_travel_time.csv

ä½œè€…: äº¤é€šé æ¸¬å°ˆæ¡ˆåœ˜éšŠ
"""

import xml.etree.ElementTree as ET
import pandas as pd
import gzip
import json
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import warnings
warnings.filterwarnings('ignore')


class ETagProcessor:
    """eTagæ•¸æ“šè™•ç†å™¨ - ç²¾ç°¡ç‰ˆ"""
    
    def __init__(self, base_folder: str = "data", debug: bool = True):
        self.base_folder = Path(base_folder)
        self.raw_etag_folder = self.base_folder / "raw" / "etag"
        self.processed_etag_folder = self.base_folder / "processed" / "etag"
        self.archive_folder = self.base_folder / "archive" / "etag"
        self.debug = debug
        
        # å‰µå»ºå¿…è¦è³‡æ–™å¤¾
        for folder in [self.processed_etag_folder, self.archive_folder]:
            folder.mkdir(parents=True, exist_ok=True)
        
        # ç›®æ¨™è·¯æ®µé…å° - æ ¹æ“šå¯¦éš›XMLèª¿æ•´ï¼ˆç§»é™¤ä¸å­˜åœ¨çš„é…å°ï¼‰
        self.target_pairs = {
            '01F0017N-01F0005N': {'segment': 'å°åŒ—â†’åœ“å±±', 'distance': 1.8, 'direction': 'N'},
            '01F0005S-01F0017S': {'segment': 'åœ“å±±â†’å°åŒ—', 'distance': 1.8, 'direction': 'S'},
            '01F0029N-01F0017N': {'segment': 'ä¸‰é‡â†’å°åŒ—', 'distance': 2.0, 'direction': 'N'},
            '01F0017S-01F0029S': {'segment': 'å°åŒ—â†’ä¸‰é‡', 'distance': 2.0, 'direction': 'S'}
            # è¨»ï¼š01F0029N-01F0005N å’Œ 01F0005S-01F0029S åœ¨å¯¦éš›XMLä¸­ä¸å­˜åœ¨
        }
        
        # XMLå‘½åç©ºé–“
        self.namespace = {'ns': 'http://traffic.transportdata.tw/standard/traffic/schema/'}
        
        if self.debug:
            print(f"ğŸ·ï¸ eTagè™•ç†å™¨åˆå§‹åŒ– (ä¿®æ­£ç‰ˆ)")
            print(f"   ğŸ“ åŸå§‹æ•¸æ“š: {self.raw_etag_folder}")
            print(f"   ğŸ¯ ç›®æ¨™é…å°: {len(self.target_pairs)} å€‹ (å¯¦éš›å­˜åœ¨)")
            print(f"   ğŸ“ è¨»ï¼šç§»é™¤XMLä¸­ä¸å­˜åœ¨çš„ä¸‰é‡â†”åœ“å±±é…å°")
    
    def scan_date_folders(self) -> Dict[str, List[Path]]:
        """æƒæETag_Data_YYYYMMDDæ ¼å¼çš„è³‡æ–™å¤¾"""
        date_files = {}
        
        if not self.raw_etag_folder.exists():
            return date_files
        
        # æƒæ ETag_Data_YYYYMMDD æ ¼å¼çš„è³‡æ–™å¤¾
        for date_folder in self.raw_etag_folder.glob("ETag_Data_*"):
            if not date_folder.is_dir():
                continue
            
            # æå–æ—¥æœŸ (ETag_Data_20250621 -> 2025-06-21)
            folder_name = date_folder.name
            if folder_name.startswith('ETag_Data_') and len(folder_name) == 18:
                date_part = folder_name[10:]  # 20250621
                if date_part.isdigit() and len(date_part) == 8:
                    date_str = f"{date_part[:4]}-{date_part[4:6]}-{date_part[6:8]}"
                    
                    # æ”¶é›†ETagPairLive_HHMM.xml.gzæª”æ¡ˆ
                    etag_files = list(date_folder.glob("ETagPairLive_*.xml.gz"))
                    if etag_files:
                        date_files[date_str] = etag_files
                        if self.debug:
                            print(f"   ğŸ“ {date_str}: {len(etag_files)} æª”æ¡ˆ")
        
        if self.debug:
            total_files = sum(len(files) for files in date_files.values())
            print(f"   ğŸ“Š ç¸½è¨ˆ: {len(date_files)} æ—¥æœŸ, {total_files} æª”æ¡ˆ")
        
        return date_files
    
    def process_single_file(self, file_path: Path, target_date: str) -> List[Dict[str, Any]]:
        """è™•ç†å–®ä¸€XMLæª”æ¡ˆ"""
        try:
            # è®€å–ä¸¦è§£æXML
            with gzip.open(file_path, 'rt', encoding='utf-8') as f:
                content = f.read()
            
            root = ET.fromstring(content)
            
            # æå–UpdateTimeï¼ˆå„ªå…ˆä½¿ç”¨è³‡æ–™å¤¾æ—¥æœŸï¼‰
            update_time = self._extract_update_time(root, file_path, target_date)
            
            # å¯¬é¬†çš„æ—¥æœŸæª¢æŸ¥ï¼šå…è¨±Â±1å¤©çš„æ™‚é–“å·®ç•°
            target_date_obj = datetime.strptime(target_date, '%Y-%m-%d')
            time_diff = abs((update_time.date() - target_date_obj.date()).days)
            
            if time_diff > 1:  # è¶…é1å¤©å·®ç•°æ‰éæ¿¾
                if self.debug:
                    print(f"      âš ï¸ æ™‚é–“å·®ç•°éå¤§: XML={update_time.date()}, ç›®æ¨™={target_date}, å·®ç•°={time_diff}å¤©")
                return []
            
            # ä½¿ç”¨è³‡æ–™å¤¾æ—¥æœŸä½œç‚ºä¸»è¦æ™‚é–“ï¼ˆæ›´å¯é ï¼‰
            folder_date = datetime.strptime(target_date, '%Y-%m-%d')
            update_time = folder_date.replace(
                hour=update_time.hour, 
                minute=update_time.minute,
                second=update_time.second
            )
            
            # æå–ç›®æ¨™è·¯æ®µæ•¸æ“š
            target_data = []
            
            # æŸ¥æ‰¾æ‰€æœ‰ETagPairLive
            etag_pairs = root.findall('.//ns:ETagPairLive', self.namespace)
            if not etag_pairs:  # å‚™æ´æŸ¥æ‰¾
                etag_pairs = root.findall('.//ETagPairLive')
            
            if self.debug:
                print(f"      ğŸ” æ‰¾åˆ° {len(etag_pairs)} å€‹ETagPairLive")
                # å¿«é€Ÿæƒææ‰€æœ‰é…å°IDï¼ˆåƒ…debugæ¨¡å¼ï¼‰
                if len(etag_pairs) > 0:
                    sample_pair = etag_pairs[0]
                    pair_id_elem = sample_pair.find('ns:ETagPairId', self.namespace)
                    if pair_id_elem is None:
                        pair_id_elem = sample_pair.find('ETagPairId')
                    if pair_id_elem is not None and pair_id_elem.text:
                        print(f"      ğŸ“‹ ç¤ºä¾‹é…å°: {pair_id_elem.text.strip()}")
            
            for etag_pair in etag_pairs:
                # æå–ETagPairId
                pair_id_elem = etag_pair.find('ns:ETagPairId', self.namespace)
                if pair_id_elem is None:
                    pair_id_elem = etag_pair.find('ETagPairId')
                
                if pair_id_elem is None or not pair_id_elem.text:
                    continue
                
                pair_id = pair_id_elem.text.strip()
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºç›®æ¨™è·¯æ®µ
                if pair_id not in self.target_pairs:
                    continue
                
                if self.debug:
                    print(f"      âœ… è™•ç†ç›®æ¨™é…å°: {pair_id}")
                
                # æå–Flows
                flows_elem = etag_pair.find('ns:Flows', self.namespace)
                if flows_elem is None:
                    flows_elem = etag_pair.find('Flows')
                
                if flows_elem is not None:
                    flows = flows_elem.findall('ns:Flow', self.namespace)
                    if not flows:
                        flows = flows_elem.findall('Flow')
                    
                    flow_count = 0
                    for flow in flows:
                        flow_data = self._extract_flow_data(flow, pair_id, update_time)
                        if flow_data:
                            target_data.append(flow_data)
                            flow_count += 1
                    
                    if self.debug:
                        print(f"         ğŸ“Š æå– {flow_count} å€‹Flowè¨˜éŒ„")
            
            if self.debug and target_data:
                print(f"      ğŸ“Š ç¸½æå–: {len(target_data)} ç­†è¨˜éŒ„")
            elif self.debug:
                print(f"      âš ï¸ æ²’æœ‰æå–åˆ°ä»»ä½•ç›®æ¨™è¨˜éŒ„")
            
            return target_data
            
        except Exception as e:
            if self.debug:
                print(f"      âŒ è™•ç†å¤±æ•— {file_path.name}: {e}")
            return []
    
    def _extract_update_time(self, root, file_path: Path, target_date: str) -> datetime:
        """æå–æ›´æ–°æ™‚é–“ - å„ªå…ˆä½¿ç”¨æª”æ¡ˆåæ™‚é–“"""
        target_date_obj = datetime.strptime(target_date, '%Y-%m-%d')
        
        # æ–¹æ³•1: å¾æª”æ¡ˆåETagPairLive_HHMM.xml.gzæå–æ™‚é–“ï¼ˆæœ€å¯é ï¼‰
        filename = file_path.stem.replace('.xml', '')  # ETagPairLive_1620
        if 'ETagPairLive_' in filename:
            time_part = filename.split('_')[-1]  # 1620
            if len(time_part) == 4 and time_part.isdigit():
                hour = int(time_part[:2])
                minute = int(time_part[2:])
                return target_date_obj.replace(hour=hour, minute=minute)
        
        # æ–¹æ³•2: å¾XMLçš„UpdateTimeæå–æ™‚é–“éƒ¨åˆ†
        update_elem = root.find('ns:UpdateTime', self.namespace)
        if update_elem is None:
            update_elem = root.find('UpdateTime')
        
        if update_elem is not None and update_elem.text:
            try:
                time_str = update_elem.text.replace('+08:00', '').replace('Z', '')
                parsed_time = datetime.strptime(time_str, '%Y-%m-%dT%H:%M:%S')
                # åªä½¿ç”¨æ™‚é–“éƒ¨åˆ†ï¼Œæ—¥æœŸä½¿ç”¨è³‡æ–™å¤¾æ—¥æœŸ
                return target_date_obj.replace(
                    hour=parsed_time.hour, 
                    minute=parsed_time.minute,
                    second=parsed_time.second
                )
            except Exception as e:
                if self.debug:
                    print(f"      âš ï¸ XMLæ™‚é–“è§£æå¤±æ•—: {e}")
        
        # æ–¹æ³•3: é è¨­ä½¿ç”¨ä¸­åˆ12:00
        return target_date_obj.replace(hour=12, minute=0)
    
    def _extract_flow_data(self, flow, pair_id: str, update_time: datetime) -> Dict[str, Any]:
        """æå–Flowæ•¸æ“š - åŒ…å«æ‰€æœ‰è»Šç¨®"""
        try:
            # æå–åŸºæœ¬æ•¸æ“š
            vehicle_type = self._get_text(flow, 'VehicleType', '31')
            travel_time = int(self._get_text(flow, 'TravelTime', '0'))
            vehicle_count = int(self._get_text(flow, 'VehicleCount', '0'))
            space_mean_speed = float(self._get_text(flow, 'SpaceMeanSpeed', '0'))
            std_deviation = float(self._get_text(flow, 'StandardDeviation', '0'))
            
            # ä¿ç•™æ‰€æœ‰Flowè¨˜éŒ„ï¼ˆåŒ…æ‹¬TravelTime=0çš„è¨˜éŒ„ï¼‰
            # é€™äº›è¨˜éŒ„åœ¨å¾ŒçºŒåˆ†æä¸­æœ‰é‡è¦æ„ç¾©
            
            pair_info = self.target_pairs[pair_id]
            
            # è»Šç¨®å°æ‡‰è¡¨
            vehicle_type_mapping = {
                '31': 'å°å®¢è»Š', '32': 'å°è²¨è»Š',
                '41': 'å¤§å®¢è»Š', '42': 'å¤§è²¨è»Š',
                '5': 'è¯çµè»Š'
            }
            
            return {
                'update_time': update_time,
                'etag_pair_id': pair_id,
                'vehicle_type_code': vehicle_type,
                'vehicle_type_name': vehicle_type_mapping.get(vehicle_type, f'æœªçŸ¥({vehicle_type})'),
                'travel_time_seconds': travel_time,
                'travel_time_minutes': round(travel_time / 60, 2) if travel_time > 0 else 0,
                'vehicle_count': vehicle_count,
                'space_mean_speed_kmh': space_mean_speed,
                'standard_deviation': std_deviation,
                'segment_name': pair_info['segment'],
                'direction': pair_info['direction'],
                'distance_km': pair_info['distance'],
                'data_valid': 1 if travel_time > 0 and vehicle_count > 0 else 0
            }
            
        except Exception as e:
            if self.debug:
                print(f"         âŒ Flowæå–å¤±æ•—: {e}")
            return None
    
    def _get_text(self, element, tag: str, default: str = "") -> str:
        """å®‰å…¨ç²å–å…ƒç´ æ–‡æœ¬"""
        # å‘½åç©ºé–“æ–¹å¼
        child = element.find(f'ns:{tag}', self.namespace)
        if child is not None and child.text:
            return child.text.strip()
        
        # ç›´æ¥æ–¹å¼
        child = element.find(tag)
        if child is not None and child.text:
            return child.text.strip()
        
        return default
    
    def process_date_folder(self, date_str: str, file_list: List[Path]) -> bool:
        """è™•ç†å–®æ—¥æœŸè³‡æ–™å¤¾"""
        if self.debug:
            print(f"ğŸ“… è™•ç† {date_str}: {len(file_list)} æª”æ¡ˆ")
        
        all_data = []
        processed_files = 0
        skipped_files = 0
        
        # è™•ç†æ‰€æœ‰æª”æ¡ˆ
        for i, file_path in enumerate(file_list):
            if self.debug and (i + 1) % 50 == 0:
                print(f"      é€²åº¦: {i+1}/{len(file_list)}")
            
            file_data = self.process_single_file(file_path, date_str)
            if file_data:
                all_data.extend(file_data)
                processed_files += 1
            else:
                skipped_files += 1
        
        if self.debug:
            print(f"   ğŸ“Š æª”æ¡ˆè™•ç†çµæœ:")
            print(f"      æœ‰æ•ˆæª”æ¡ˆ: {processed_files}/{len(file_list)}")
            print(f"      è·³éæª”æ¡ˆ: {skipped_files}")
        
        if not all_data:
            if self.debug:
                print(f"   âš ï¸ {date_str}: ç„¡ç›®æ¨™è·¯æ®µæ•¸æ“š")
                print(f"   ğŸ’¡ å¯èƒ½åŸå› : XMLå…§æ™‚é–“èˆ‡è³‡æ–™å¤¾æ—¥æœŸä¸åŒ¹é…")
            return False
        
        # æ™‚é–“åˆ†æ
        times = [record['update_time'] for record in all_data]
        time_span = (max(times) - min(times)).total_seconds() / 3600
        valid_records = sum(1 for record in all_data if record['data_valid'] == 1)
        
        # æª¢æŸ¥ç›®æ¨™è·¯æ®µåˆ†å¸ƒ
        pair_counts = {}
        for record in all_data:
            pair_id = record['etag_pair_id']
            if pair_id not in pair_counts:
                pair_counts[pair_id] = 0
            pair_counts[pair_id] += 1
        
        if self.debug:
            print(f"   ğŸ“Š çµæœçµ±è¨ˆ:")
            print(f"      ç¸½è¨˜éŒ„æ•¸: {len(all_data):,}")
            print(f"      æœ‰æ•ˆè¨˜éŒ„: {valid_records:,} ({valid_records/len(all_data)*100:.1f}%)")
            print(f"      æ™‚é–“è·¨åº¦: {time_span:.1f} å°æ™‚")
            print(f"      æ™‚é–“ç¯„åœ: {min(times)} ~ {max(times)}")
            print(f"   ğŸ¯ ç›®æ¨™è·¯æ®µåˆ†å¸ƒ:")
            for pair_id, count in pair_counts.items():
                segment_name = self.target_pairs[pair_id]['segment']
                print(f"      {pair_id} ({segment_name}): {count:,} è¨˜éŒ„")
        
        # ä¿å­˜æ•¸æ“š
        self._save_date_data(date_str, all_data)
        
        # æ­¸æª”æª”æ¡ˆ
        self._archive_date_files(date_str, file_list)
        
        return True
    
    def _save_date_data(self, date_str: str, data_list: List[Dict[str, Any]]):
        """ä¿å­˜æ—¥æœŸæ•¸æ“š"""
        date_folder = self.processed_etag_folder / date_str
        date_folder.mkdir(parents=True, exist_ok=True)
        
        # è½‰æ›ç‚ºDataFrame
        df = pd.DataFrame(data_list)
        
        # 1. å®Œæ•´æ—…è¡Œæ™‚é–“æ•¸æ“šï¼ˆæ‰€æœ‰Flowè¨˜éŒ„ï¼‰
        travel_time_csv = date_folder / "etag_travel_time.csv"
        df.to_csv(travel_time_csv, index=False, encoding='utf-8-sig')
        
        # 2. æœ‰æ•ˆæ•¸æ“šæ‘˜è¦ï¼ˆåƒ…éé›¶è¨˜éŒ„ï¼‰
        valid_df = df[df['data_valid'] == 1]
        if not valid_df.empty:
            valid_csv = date_folder / "etag_valid_data.csv"
            valid_df.to_csv(valid_csv, index=False, encoding='utf-8-sig')
        
        # 3. æŒ‰è»Šç¨®çµ±è¨ˆ
        vehicle_stats = df.groupby(['etag_pair_id', 'vehicle_type_name']).agg({
            'vehicle_count': 'sum',
            'travel_time_seconds': 'mean',
            'space_mean_speed_kmh': 'mean',
            'data_valid': 'sum'
        }).reset_index()
        
        vehicle_csv = date_folder / "etag_vehicle_stats.csv"
        vehicle_stats.to_csv(vehicle_csv, index=False, encoding='utf-8-sig')
        
        # 4. çµ±è¨ˆæ‘˜è¦
        summary = self._create_summary(df, date_str)
        summary_json = date_folder / "etag_summary.json"
        with open(summary_json, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2, default=str)
        
        if self.debug:
            print(f"   ğŸ’¾ ä¿å­˜å®Œæˆ: {travel_time_csv}")
    
    def _create_summary(self, df: pd.DataFrame, date_str: str) -> Dict[str, Any]:
        """å‰µå»ºçµ±è¨ˆæ‘˜è¦"""
        times = pd.to_datetime(df['update_time'])
        valid_df = df[df['data_valid'] == 1]
        
        return {
            'date': date_str,
            'total_records': len(df),
            'valid_records': len(valid_df),
            'validity_rate': len(valid_df) / len(df) * 100 if len(df) > 0 else 0,
            'unique_pairs': df['etag_pair_id'].nunique(),
            'time_range': {
                'start': times.min().isoformat(),
                'end': times.max().isoformat(),
                'span_hours': (times.max() - times.min()).total_seconds() / 3600
            },
            'vehicle_type_distribution': df['vehicle_type_name'].value_counts().to_dict(),
            'pair_statistics': df.groupby('etag_pair_id').agg({
                'vehicle_count': 'sum',
                'data_valid': 'sum'
            }).to_dict(),
            'processing_timestamp': datetime.now().isoformat()
        }
    
    def _archive_date_files(self, date_str: str, file_list: List[Path]):
        """æ­¸æª”è™•ç†å®Œçš„æª”æ¡ˆ"""
        if not file_list:
            return
        
        # å‰µå»ºæ­¸æª”è³‡æ–™å¤¾
        archive_date_folder = self.archive_folder / date_str
        archive_date_folder.mkdir(parents=True, exist_ok=True)
        
        archived_count = 0
        
        for file_path in file_list:
            try:
                if file_path.exists():
                    # ç§»å‹•åˆ°æ­¸æª”
                    archive_path = archive_date_folder / file_path.name
                    shutil.move(str(file_path), str(archive_path))
                    archived_count += 1
            except Exception as e:
                if self.debug:
                    print(f"      âš ï¸ æ­¸æª”å¤±æ•— {file_path.name}: {e}")
        
        if self.debug:
            print(f"   ğŸ“¦ æ­¸æª”: {archived_count}/{len(file_list)} æª”æ¡ˆ")
        
        # æ¸…ç†ç©ºçš„åŸå§‹è³‡æ–™å¤¾
        if archived_count > 0:
            try:
                original_folder = file_list[0].parent
                if original_folder.exists() and not any(original_folder.iterdir()):
                    original_folder.rmdir()
                    if self.debug:
                        print(f"   ğŸ—‘ï¸ æ¸…ç†ç©ºè³‡æ–™å¤¾: {original_folder.name}")
            except Exception as e:
                if self.debug:
                    print(f"   âš ï¸ æ¸…ç†è³‡æ–™å¤¾å¤±æ•—: {e}")
    
    def process_all_dates(self) -> Dict[str, Any]:
        """æ‰¹æ¬¡è™•ç†æ‰€æœ‰æ—¥æœŸ"""
        if self.debug:
            print("ğŸš€ æ‰¹æ¬¡è™•ç†eTagæ•¸æ“š")
            print("=" * 40)
        
        date_files = self.scan_date_folders()
        if not date_files:
            return {"success": False, "message": "ç„¡eTagæª”æ¡ˆ"}
        
        successful_dates = 0
        total_records = 0
        results = {}
        
        for date_str, file_list in date_files.items():
            success = self.process_date_folder(date_str, file_list)
            results[date_str] = success
            
            if success:
                successful_dates += 1
                # çµ±è¨ˆè¨˜éŒ„æ•¸
                summary_file = self.processed_etag_folder / date_str / "etag_summary.json"
                if summary_file.exists():
                    try:
                        with open(summary_file, 'r', encoding='utf-8') as f:
                            summary = json.load(f)
                        total_records += summary.get('total_records', 0)
                    except:
                        pass
        
        if self.debug:
            print(f"\nğŸ æ‰¹æ¬¡è™•ç†å®Œæˆ:")
            print(f"   æˆåŠŸ: {successful_dates}/{len(date_files)} æ—¥æœŸ")
            print(f"   è¨˜éŒ„: {total_records:,} ç­†")
        
        return {
            "success": True,
            "total_dates": len(date_files),
            "successful_dates": successful_dates,
            "total_records": total_records,
            "results": results
        }
    
    def get_processing_summary(self) -> Dict[str, Any]:
        """ç²å–è™•ç†æ‘˜è¦"""
        if not self.processed_etag_folder.exists():
            return {"processed_dates": 0, "total_records": 0}
        
        date_folders = [d for d in self.processed_etag_folder.iterdir() 
                       if d.is_dir() and d.name.count('-') == 2]
        
        total_records = 0
        date_details = {}
        
        for date_folder in date_folders:
            summary_file = date_folder / "etag_summary.json"
            if summary_file.exists():
                try:
                    with open(summary_file, 'r', encoding='utf-8') as f:
                        summary = json.load(f)
                    
                    date_details[date_folder.name] = {
                        "total_records": summary.get('total_records', 0),
                        "valid_records": summary.get('valid_records', 0),
                        "validity_rate": summary.get('validity_rate', 0),
                        "time_span": summary.get('time_range', {}).get('span_hours', 0)
                    }
                    total_records += summary.get('total_records', 0)
                except:
                    pass
        
        return {
            "processed_dates": len(date_folders),
            "total_records": total_records,
            "date_details": date_details
        }


# ä¾¿åˆ©å‡½æ•¸
def process_etag_data(base_folder: str = "data", debug: bool = True) -> Dict[str, Any]:
    """ä¸€éµè™•ç†eTagæ•¸æ“š"""
    processor = ETagProcessor(base_folder, debug)
    return processor.process_all_dates()


def get_etag_summary(base_folder: str = "data") -> Dict[str, Any]:
    """ç²å–eTagè™•ç†æ‘˜è¦"""
    processor = ETagProcessor(base_folder, debug=False)
    return processor.get_processing_summary()


if __name__ == "__main__":
    print("ğŸ·ï¸ eTagè™•ç†å™¨ - ç²¾ç°¡é«˜æ•ˆç‰ˆ")
    print("=" * 50)
    print("ğŸ¯ ç›®æ¨™è·¯æ®µ: åœ“å±±(23K)-å°åŒ—(25K)-ä¸‰é‡(27K)")
    print("ğŸ“ æª”æ¡ˆæ ¼å¼: ETag_Data_YYYYMMDD/ETagPairLive_HHMM.xml.gz")
    print("=" * 50)
    
    processor = ETagProcessor(debug=True)
    result = processor.process_all_dates()
    
    if result["success"]:
        print(f"\nğŸ‰ è™•ç†å®Œæˆï¼")
        summary = processor.get_processing_summary()
        
        print(f"\nğŸ“Š è™•ç†æ‘˜è¦:")
        for date_str, details in summary['date_details'].items():
            valid_rate = details['validity_rate']
            time_span = details['time_span']
            total = details['total_records']
            valid = details['valid_records']
            print(f"   {date_str}: {total:,} è¨˜éŒ„ ({valid:,} æœ‰æ•ˆ, {valid_rate:.1f}%), {time_span:.1f}h")
        
        print(f"\nğŸ“ è¼¸å‡ºä½ç½®:")
        print(f"   data/processed/etag/YYYY-MM-DD/")
        print(f"   â”œâ”€â”€ etag_travel_time.csv      # å®Œæ•´æ•¸æ“š")
        print(f"   â”œâ”€â”€ etag_valid_data.csv       # æœ‰æ•ˆæ•¸æ“š") 
        print(f"   â”œâ”€â”€ etag_vehicle_stats.csv    # è»Šç¨®çµ±è¨ˆ")
        print(f"   â””â”€â”€ etag_summary.json         # çµ±è¨ˆæ‘˜è¦")
        
        print(f"\nğŸ“¦ æ­¸æª”ä½ç½®:")
        print(f"   data/archive/etag/YYYY-MM-DD/")
    else:
        print(f"\nâŒ è™•ç†å¤±æ•—: {result.get('message', 'æœªçŸ¥éŒ¯èª¤')}")