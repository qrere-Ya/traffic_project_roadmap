"""
ç°¡åŒ–ç‰ˆäº¤é€šæµé‡æ¢ç´¢æ€§æ•¸æ“šåˆ†æå™¨
========================================

åŠŸèƒ½ï¼š
1. è¼‰å…¥å’Œåˆ†æäº¤é€šæ•¸æ“š
2. AIæ¨¡å‹é©ç”¨æ€§è©•ä¼°
3. æ™ºèƒ½æ¨¡å‹æ¨è–¦
4. ç”Ÿæˆåˆ†æå ±å‘Š

ä½œè€…: äº¤é€šé æ¸¬å°ˆæ¡ˆåœ˜éšŠ
æ—¥æœŸ: 2025-07-07 (ç°¡åŒ–ç‰ˆ)
"""

import pandas as pd
import numpy as np
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import warnings
warnings.filterwarnings('ignore')

class SimplifiedTrafficAnalyzer:
    """ç°¡åŒ–ç‰ˆäº¤é€šæµé‡åˆ†æå™¨"""
    
    def __init__(self, base_folder: str = "data"):
        self.base_folder = Path(base_folder)
        self.cleaned_folder = self.base_folder / "cleaned"
        self.datasets = {}
        self.analysis_results = {}
        self.insights = []
        
        print("ğŸ”¬ åˆå§‹åŒ–ç°¡åŒ–ç‰ˆäº¤é€šåˆ†æå™¨...")
        self._detect_data_files()
    
    def _detect_data_files(self):
        """æª¢æ¸¬å¯ç”¨çš„æ•¸æ“šæª”æ¡ˆ"""
        if not self.cleaned_folder.exists():
            print(f"âŒ æ¸…ç†æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {self.cleaned_folder}")
            return
        
        # æª¢æ¸¬æ—¥æœŸè³‡æ–™å¤¾
        date_folders = [d for d in self.cleaned_folder.iterdir() 
                       if d.is_dir() and d.name.count('-') == 2]
        
        if date_folders:
            self.available_dates = sorted([d.name for d in date_folders])
            print(f"âœ… ç™¼ç¾ {len(self.available_dates)} å€‹æ—¥æœŸè³‡æ–™å¤¾")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°æ—¥æœŸè³‡æ–™å¤¾ï¼Œå°‹æ‰¾ç›´æ¥æª”æ¡ˆ...")
            self.available_dates = []
    
    def load_data(self, merge_dates: bool = True) -> bool:
        """è¼‰å…¥æ•¸æ“š"""
        print("ğŸ“Š è¼‰å…¥æ•¸æ“š...")
        
        try:
            if self.available_dates and merge_dates:
                # è¼‰å…¥å¤šæ—¥æœŸæ•¸æ“šä¸¦åˆä½µ
                all_data = {}
                
                for date_str in self.available_dates:
                    date_folder = self.cleaned_folder / date_str
                    
                    # è¼‰å…¥ç›®æ¨™è·¯æ®µæ•¸æ“šï¼ˆAIè¨“ç·´ä¸»åŠ›ï¼‰
                    peak_file = date_folder / "target_route_peak_cleaned.csv"
                    offpeak_file = date_folder / "target_route_offpeak_cleaned.csv"
                    
                    if peak_file.exists():
                        if 'target_peak' not in all_data:
                            all_data['target_peak'] = []
                        df = pd.read_csv(peak_file)
                        df['source_date'] = date_str
                        all_data['target_peak'].append(df)
                    
                    if offpeak_file.exists():
                        if 'target_offpeak' not in all_data:
                            all_data['target_offpeak'] = []
                        df = pd.read_csv(offpeak_file)
                        df['source_date'] = date_str
                        all_data['target_offpeak'].append(df)
                
                # åˆä½µæ•¸æ“š
                for key, df_list in all_data.items():
                    if df_list:
                        self.datasets[key] = pd.concat(df_list, ignore_index=True)
                        print(f"   âœ… {key}: {len(self.datasets[key]):,} ç­†è¨˜éŒ„")
                
                return len(self.datasets) > 0
            
            else:
                print("âŒ ç„¡å¯ç”¨æ•¸æ“š")
                return False
                
        except Exception as e:
            print(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return False
    
    def analyze_data_characteristics(self) -> Dict[str, Any]:
        """åˆ†ææ•¸æ“šç‰¹æ€§"""
        print("ğŸ” åˆ†ææ•¸æ“šç‰¹æ€§...")
        
        characteristics = {
            'data_summary': {},
            'quality_metrics': {},
            'time_coverage': {},
            'feature_analysis': {}
        }
        
        total_records = 0
        all_dates = set()
        
        for name, df in self.datasets.items():
            if not df.empty:
                # åŸºæœ¬çµ±è¨ˆ
                characteristics['data_summary'][name] = {
                    'records': len(df),
                    'avg_speed': round(df['speed'].mean(), 2) if 'speed' in df.columns else 0,
                    'avg_volume': round(df['volume_total'].mean(), 2) if 'volume_total' in df.columns else 0,
                    'completeness': round(df.notna().sum().sum() / (len(df) * len(df.columns)) * 100, 1)
                }
                
                total_records += len(df)
                
                # æ”¶é›†æ—¥æœŸ
                if 'source_date' in df.columns:
                    all_dates.update(df['source_date'].unique())
        
        # æ™‚é–“è¦†è“‹åˆ†æ
        characteristics['time_coverage'] = {
            'total_records': total_records,
            'unique_dates': len(all_dates),
            'date_span_days': len(all_dates),
            'records_per_day': round(total_records / len(all_dates), 0) if all_dates else 0
        }
        
        # å“è³ªè©•ä¼°
        if total_records > 0:
            volume_score = min(100, total_records / 1000)  # æ¯1000ç­†è¨˜éŒ„å¾—1åˆ†
            time_score = min(100, len(all_dates) * 20)      # æ¯å¤©å¾—20åˆ†
            balance_score = self._calculate_balance_score()
            
            overall_quality = (volume_score * 0.4 + time_score * 0.4 + balance_score * 0.2)
            
            characteristics['quality_metrics'] = {
                'volume_score': round(volume_score, 1),
                'time_score': round(time_score, 1),
                'balance_score': round(balance_score, 1),
                'overall_quality': round(overall_quality, 1)
            }
        
        self.analysis_results['data_characteristics'] = characteristics
        
        # ç”Ÿæˆæ´å¯Ÿ
        if total_records > 50000:
            self.insights.append(f"ğŸ“Š å„ªç§€æ•¸æ“šè¦æ¨¡ï¼š{total_records:,}ç­†è¨˜éŒ„é©åˆè¤‡é›œæ¨¡å‹é–‹ç™¼")
        if len(all_dates) >= 7:
            self.insights.append(f"ğŸ“… ç†æƒ³æ™‚é–“è·¨åº¦ï¼š{len(all_dates)}å¤©æ•¸æ“šæ”¯æ´æ™‚é–“åºåˆ—åˆ†æ")
        
        return characteristics
    
    def _calculate_balance_score(self) -> float:
        """è¨ˆç®—æ•¸æ“šå¹³è¡¡æ€§è©•åˆ†"""
        if 'target_peak' in self.datasets and 'target_offpeak' in self.datasets:
            peak_count = len(self.datasets['target_peak'])
            offpeak_count = len(self.datasets['target_offpeak'])
            
            if peak_count > 0 and offpeak_count > 0:
                balance_ratio = min(peak_count, offpeak_count) / max(peak_count, offpeak_count)
                return balance_ratio * 100
        
        return 50  # é è¨­ä¸­ç­‰åˆ†æ•¸
    
    def evaluate_ai_model_suitability(self) -> Dict[str, Any]:
        """è©•ä¼°AIæ¨¡å‹é©ç”¨æ€§"""
        print("ğŸ¤– è©•ä¼°AIæ¨¡å‹é©ç”¨æ€§...")
        
        characteristics = self.analysis_results.get('data_characteristics', {})
        time_coverage = characteristics.get('time_coverage', {})
        quality_metrics = characteristics.get('quality_metrics', {})
        
        total_records = time_coverage.get('total_records', 0)
        time_span = time_coverage.get('date_span_days', 0)
        overall_quality = quality_metrics.get('overall_quality', 0)
        
        # æ¨¡å‹é©ç”¨æ€§è©•ä¼°
        model_suitability = {
            'linear_regression': self._evaluate_linear_model(total_records, overall_quality),
            'random_forest': self._evaluate_random_forest(total_records, overall_quality),
            'xgboost': self._evaluate_xgboost(total_records, overall_quality),
            'lstm': self._evaluate_lstm(total_records, time_span, overall_quality),
            'transformer': self._evaluate_transformer(total_records, time_span, overall_quality),
            'hybrid_ensemble': self._evaluate_hybrid_model(total_records, time_span, overall_quality)
        }
        
        # ç”Ÿæˆæ¨è–¦
        recommendations = self._generate_model_recommendations(model_suitability)
        
        ai_evaluation = {
            'model_suitability': model_suitability,
            'recommendations': recommendations,
            'data_readiness': {
                'records': total_records,
                'time_span': time_span,
                'quality': overall_quality,
                'lstm_ready': total_records >= 50000 and time_span >= 7,
                'production_ready': total_records >= 10000 and overall_quality >= 70
            }
        }
        
        self.analysis_results['ai_evaluation'] = ai_evaluation
        return ai_evaluation
    
    def _evaluate_linear_model(self, records: int, quality: float) -> Dict[str, Any]:
        """è©•ä¼°ç·šæ€§å›æ­¸æ¨¡å‹"""
        score = min(100, (records / 1000) * 0.5 + quality * 0.5)
        
        return {
            'score': round(score, 1),
            'suitable': records >= 1000,
            'pros': ['å¿«é€Ÿè¨“ç·´', 'æ˜“è§£é‡‹', 'ä½è³‡æºéœ€æ±‚'],
            'cons': ['ç„¡æ³•æ•æ‰è¤‡é›œæ¨¡å¼', 'å‡è¨­ç·šæ€§é—œä¿‚'],
            'best_for': 'åŸºç·šæ¨¡å‹ã€å¿«é€ŸåŸå‹'
        }
    
    def _evaluate_random_forest(self, records: int, quality: float) -> Dict[str, Any]:
        """è©•ä¼°éš¨æ©Ÿæ£®æ—æ¨¡å‹"""
        score = min(100, (records / 5000) * 30 + quality * 0.7)
        
        return {
            'score': round(score, 1),
            'suitable': records >= 5000,
            'pros': ['è™•ç†éç·šæ€§', 'ç‰¹å¾µé‡è¦æ€§', 'æŠ—éæ“¬åˆ'],
            'cons': ['è¨˜æ†¶é«”éœ€æ±‚å¤§', 'é æ¸¬é€Ÿåº¦è¼ƒæ…¢'],
            'best_for': 'ç‰¹å¾µåˆ†æã€éç·šæ€§æ¨¡å¼æ•æ‰'
        }
    
    def _evaluate_xgboost(self, records: int, quality: float) -> Dict[str, Any]:
        """è©•ä¼°XGBoostæ¨¡å‹"""
        score = min(100, (records / 10000) * 40 + quality * 0.6)
        
        return {
            'score': round(score, 1),
            'suitable': records >= 10000,
            'pros': ['é«˜é æ¸¬ç²¾åº¦', 'è™•ç†ç¼ºå¤±å€¼', 'ç‰¹å¾µé‡è¦æ€§'],
            'cons': ['è¶…åƒæ•¸æ•æ„Ÿ', 'è¨“ç·´æ™‚é–“è¼ƒé•·'],
            'best_for': 'é«˜ç²¾åº¦é æ¸¬ã€çµæ§‹åŒ–æ•¸æ“š'
        }
    
    def _evaluate_lstm(self, records: int, time_span: int, quality: float) -> Dict[str, Any]:
        """è©•ä¼°LSTMæ¨¡å‹"""
        # LSTMéœ€è¦å……è¶³çš„æ™‚åºæ•¸æ“š
        time_score = min(100, time_span * 10)  # æ¯å¤©10åˆ†
        data_score = min(100, records / 500)   # æ¯500ç­†è¨˜éŒ„1åˆ†
        score = (time_score * 0.6 + data_score * 0.3 + quality * 0.1)
        
        return {
            'score': round(score, 1),
            'suitable': records >= 50000 and time_span >= 7,
            'pros': ['æ•æ‰æ™‚åºæ¨¡å¼', 'é•·æœŸè¨˜æ†¶', 'é©åˆé æ¸¬'],
            'cons': ['è¨“ç·´æ™‚é–“é•·', 'éœ€è¦å¤§é‡æ•¸æ“š', 'GPUéœ€æ±‚'],
            'best_for': 'æ™‚é–“åºåˆ—é æ¸¬ã€é•·æœŸè¶¨å‹¢åˆ†æ'
        }
    
    def _evaluate_transformer(self, records: int, time_span: int, quality: float) -> Dict[str, Any]:
        """è©•ä¼°Transformeræ¨¡å‹"""
        # Transformeréœ€è¦æ›´å¤šæ•¸æ“š
        time_score = min(100, time_span * 8)
        data_score = min(100, records / 1000)
        score = (time_score * 0.5 + data_score * 0.4 + quality * 0.1)
        
        return {
            'score': round(score, 1),
            'suitable': records >= 100000 and time_span >= 14,
            'pros': ['ä¸¦è¡Œè¨“ç·´', 'æ³¨æ„åŠ›æ©Ÿåˆ¶', 'æœ€å…ˆé€²æ€§èƒ½'],
            'cons': ['æ¥µé«˜è³‡æºéœ€æ±‚', 'éœ€è¦å¤§é‡æ•¸æ“š', 'è¤‡é›œåº¦é«˜'],
            'best_for': 'å¤§è¦æ¨¡æ™‚åºé æ¸¬ã€è¤‡é›œæ¨¡å¼è­˜åˆ¥'
        }
    
    def _evaluate_hybrid_model(self, records: int, time_span: int, quality: float) -> Dict[str, Any]:
        """è©•ä¼°æ··åˆé›†æˆæ¨¡å‹"""
        base_score = (records / 20000) * 40 + (time_span / 14) * 30 + quality * 0.3
        score = min(100, base_score)
        
        return {
            'score': round(score, 1),
            'suitable': records >= 20000 and time_span >= 5,
            'pros': ['çµåˆå¤šæ¨¡å‹å„ªå‹¢', 'æ›´ç©©å®šé æ¸¬', 'é¢¨éšªåˆ†æ•£'],
            'cons': ['è¤‡é›œåº¦é«˜', 'è¨“ç·´æ™‚é–“é•·', 'èª¿åƒå›°é›£'],
            'best_for': 'ç”Ÿç”¢ç’°å¢ƒã€é«˜æº–ç¢ºç‡éœ€æ±‚'
        }
    
    def _generate_model_recommendations(self, suitability: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ¨¡å‹æ¨è–¦"""
        # æŒ‰è©•åˆ†æ’åº
        scored_models = [(name, info['score'], info['suitable']) 
                        for name, info in suitability.items()]
        scored_models.sort(key=lambda x: x[1], reverse=True)
        
        recommendations = []
        
        for i, (model_name, score, suitable) in enumerate(scored_models):
            if suitable and i < 3:  # æ¨è–¦å‰3å€‹é©åˆçš„æ¨¡å‹
                priority = ['ğŸ¥‡ é¦–é¸', 'ğŸ¥ˆ æ¬¡é¸', 'ğŸ¥‰ å‚™é¸'][i]
                model_info = suitability[model_name]
                
                recommendations.append({
                    'rank': i + 1,
                    'model': model_name,
                    'priority': priority,
                    'score': score,
                    'reason': model_info['best_for'],
                    'pros': model_info['pros'][:2]  # åªå–å‰å…©å€‹å„ªé»
                })
        
        return recommendations
    
    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Š"""
        print("ğŸ“‹ ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Š...")
        
        # ç¢ºä¿å·²å®Œæˆå¿…è¦åˆ†æ
        if not self.analysis_results.get('data_characteristics'):
            self.analyze_data_characteristics()
        
        if not self.analysis_results.get('ai_evaluation'):
            self.evaluate_ai_model_suitability()
        
        # å»ºæ§‹å ±å‘Š
        report = {
            'metadata': {
                'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'analyzer_version': 'simplified_v1.0',
                'total_insights': len(self.insights)
            },
            'data_summary': self.analysis_results['data_characteristics']['data_summary'],
            'quality_assessment': self.analysis_results['data_characteristics']['quality_metrics'],
            'time_coverage': self.analysis_results['data_characteristics']['time_coverage'],
            'ai_model_evaluation': self.analysis_results['ai_evaluation'],
            'key_insights': self.insights,
            'actionable_recommendations': self._generate_actionable_recommendations()
        }
        
        return report
    
    def _generate_actionable_recommendations(self) -> List[str]:
        """ç”Ÿæˆå¯è¡Œå‹•å»ºè­°"""
        recommendations = []
        
        ai_eval = self.analysis_results.get('ai_evaluation', {})
        data_readiness = ai_eval.get('data_readiness', {})
        
        total_records = data_readiness.get('records', 0)
        time_span = data_readiness.get('time_span', 0)
        quality = data_readiness.get('quality', 0)
        
        # åŸºæ–¼æ•¸æ“šç‹€æ³çš„å»ºè­°
        if total_records >= 80000:
            recommendations.append("ğŸš€ ç«‹å³é–‹å§‹æ·±åº¦å­¸ç¿’æ¨¡å‹é–‹ç™¼ï¼Œæ•¸æ“šé‡å……è¶³")
        elif total_records >= 20000:
            recommendations.append("ğŸ“Š é©åˆé–‹ç™¼ä¸­ç­‰è¤‡é›œåº¦æ¨¡å‹ï¼Œå»ºè­°å¾XGBoosté–‹å§‹")
        else:
            recommendations.append("ğŸ“ˆ å»ºè­°å¾ç·šæ€§æ¨¡å‹å’Œéš¨æ©Ÿæ£®æ—é–‹å§‹å»ºç«‹åŸºç·š")
        
        if time_span >= 7:
            recommendations.append("â° æ™‚é–“åºåˆ—æ•¸æ“šå……è¶³ï¼Œå„ªå…ˆè€ƒæ…®LSTMæ¨¡å‹")
        else:
            recommendations.append("ğŸ“… å»ºè­°æ”¶é›†æ›´å¤šæ™‚é–“æ•¸æ“šä»¥æ”¹å–„æ™‚åºæ¨¡å‹æ•ˆæœ")
        
        if quality >= 80:
            recommendations.append("âœ¨ æ•¸æ“šå“è³ªå„ªç§€ï¼Œå¯ç›´æ¥é€²è¡Œæ¨¡å‹è¨“ç·´")
        elif quality >= 70:
            recommendations.append("ğŸ”§ æ•¸æ“šå“è³ªè‰¯å¥½ï¼Œå»ºè­°é€²è¡Œè¼•åº¦æ¸…ç†å¾Œè¨“ç·´")
        else:
            recommendations.append("ğŸ› ï¸ éœ€è¦é€²ä¸€æ­¥æ”¹å–„æ•¸æ“šå“è³ª")
        
        return recommendations
    
    def save_report(self, report: Dict[str, Any], filename: str = None):
        """ä¿å­˜åˆ†æå ±å‘Š"""
        output_dir = Path("outputs/reports")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        if not filename:
            filename = f"simplified_traffic_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        output_path = output_dir / filename
        
        # ç¢ºä¿æ‰€æœ‰æ•¸æ“šéƒ½å¯ä»¥JSONåºåˆ—åŒ–
        safe_report = self._safe_json_convert(report)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(safe_report, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å ±å‘Šå·²ä¿å­˜: {output_path}")
    
    def _safe_json_convert(self, obj):
        """å®‰å…¨çš„JSONè½‰æ›"""
        if isinstance(obj, dict):
            return {str(k): self._safe_json_convert(v) for k, v in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return [self._safe_json_convert(item) for item in obj]
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif pd.isna(obj):
            return None
        else:
            return obj
    
    def print_summary(self):
        """åˆ—å°åˆ†ææ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“Š ç°¡åŒ–ç‰ˆäº¤é€šæµé‡åˆ†ææ‘˜è¦")
        print("="*60)
        
        # æ•¸æ“šæ¦‚è¦½
        if 'data_characteristics' in self.analysis_results:
            time_coverage = self.analysis_results['data_characteristics']['time_coverage']
            quality_metrics = self.analysis_results['data_characteristics']['quality_metrics']
            
            print(f"ğŸ“ˆ æ•¸æ“šè¦æ¨¡:")
            print(f"   ç¸½è¨˜éŒ„æ•¸: {time_coverage.get('total_records', 0):,}")
            print(f"   æ™‚é–“è·¨åº¦: {time_coverage.get('date_span_days', 0)} å¤©")
            print(f"   æ•´é«”å“è³ª: {quality_metrics.get('overall_quality', 0)}/100")
        
        # AIæ¨¡å‹æ¨è–¦
        if 'ai_evaluation' in self.analysis_results:
            recommendations = self.analysis_results['ai_evaluation']['recommendations']
            print(f"\nğŸ¤– AIæ¨¡å‹æ¨è–¦:")
            
            for rec in recommendations:
                print(f"   {rec['priority']} {rec['model']}: {rec['score']:.1f}åˆ†")
                print(f"      æ¨è–¦åŸå› : {rec['reason']}")
        
        # é—œéµæ´å¯Ÿ
        if self.insights:
            print(f"\nğŸ’¡ é—œéµç™¼ç¾:")
            for i, insight in enumerate(self.insights, 1):
                print(f"   {i}. {insight}")
        
        print("\nâœ… ç°¡åŒ–ç‰ˆåˆ†æå®Œæˆï¼")


def quick_analyze(base_folder: str = "data") -> Dict[str, Any]:
    """å¿«é€Ÿåˆ†æå‡½æ•¸"""
    analyzer = SimplifiedTrafficAnalyzer(base_folder)
    
    if analyzer.load_data():
        analyzer.analyze_data_characteristics()
        analyzer.evaluate_ai_model_suitability()
        report = analyzer.generate_comprehensive_report()
        analyzer.print_summary()
        analyzer.save_report(report)
        return report
    else:
        print("âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—")
        return {}


if __name__ == "__main__":
    print("ğŸš€ å•Ÿå‹•ç°¡åŒ–ç‰ˆäº¤é€šæµé‡åˆ†æ...")
    quick_analyze()