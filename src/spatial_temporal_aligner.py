# src/spatial_temporal_aligner.py - ç°¡åŒ–ç‰ˆ

"""
VDèˆ‡eTagæ•¸æ“šæ™‚ç©ºå°é½Šå™¨ - ç°¡åŒ–ç‰ˆ
================================

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. VD(1åˆ†é˜) â†” eTag(5åˆ†é˜) æ™‚é–“å°é½Š
2. åœ“å±±-å°åŒ—-ä¸‰é‡è·¯æ®µç©ºé–“æ˜ å°„
3. æ•¸æ“šå“è³ªé©—è­‰èˆ‡ä¿å­˜

ç°¡åŒ–åŸå‰‡ï¼š
- ç§»é™¤å†—é¤˜åŠŸèƒ½ï¼Œä¿ç•™æ ¸å¿ƒé‚è¼¯
- å‹•æ…‹æª¢æ¸¬å¯ç”¨è³‡æ–™
- æ¸…æ™°çš„éŒ¯èª¤è™•ç†

ä½œè€…: äº¤é€šé æ¸¬å°ˆæ¡ˆåœ˜éšŠ
æ—¥æœŸ: 2025-01-23
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional
import json
import warnings
warnings.filterwarnings('ignore')


class SpatialTemporalAligner:
    """VDèˆ‡eTagæ™‚ç©ºå°é½Šå™¨ - ç°¡åŒ–ç‰ˆ"""
    
    def __init__(self, base_folder: str = "data", debug: bool = False):
        self.base_folder = Path(base_folder)
        self.debug = debug
        
        # ç©ºé–“æ˜ å°„ï¼šVDç«™é» â†” eTagé…å°
        self.spatial_mapping = {
            'åœ“å±±': ['01F0017N-01F0005N', '01F0005S-01F0017S'],
            'å°åŒ—': ['01F0017N-01F0005N', '01F0005S-01F0017S', 
                    '01F0029N-01F0017N', '01F0017S-01F0029S'],
            'ä¸‰é‡': ['01F0029N-01F0017N', '01F0017S-01F0029S']
        }
        
        # æ™‚é–“åŒæ­¥åƒæ•¸
        self.time_window = 5  # åˆ†é˜
        self.sync_tolerance = 2  # å®¹å·®
        
        if self.debug:
            print("ğŸ”— VD+eTagæ™‚ç©ºå°é½Šå™¨åˆå§‹åŒ–")
    
    def get_available_dates(self) -> Dict[str, List[str]]:
        """æª¢æ¸¬å¯ç”¨è³‡æ–™æ—¥æœŸ"""
        vd_dates = self._scan_vd_dates()
        etag_dates = self._scan_etag_dates()
        common_dates = sorted(set(vd_dates) & set(etag_dates))
        
        if self.debug:
            print(f"ğŸ“… å¯ç”¨è³‡æ–™: VD={len(vd_dates)}, eTag={len(etag_dates)}, å…±åŒ={len(common_dates)}")
        
        return {
            'vd_dates': vd_dates,
            'etag_dates': etag_dates,
            'common_dates': common_dates
        }
    
    def _scan_vd_dates(self) -> List[str]:
        """æƒæVDæ•¸æ“šæ—¥æœŸ"""
        dates = []
        vd_folders = [
            self.base_folder / "processed" / "vd",
            self.base_folder / "cleaned"
        ]
        
        for folder in vd_folders:
            if folder.exists():
                for date_folder in folder.iterdir():
                    if date_folder.is_dir() and self._is_valid_date(date_folder.name):
                        target_file = date_folder / "target_route_data.csv"
                        cleaned_file = date_folder / "target_route_data_cleaned.csv"
                        if target_file.exists() or cleaned_file.exists():
                            dates.append(date_folder.name)
        
        return sorted(list(set(dates)))
    
    def _scan_etag_dates(self) -> List[str]:
        """æƒæeTagæ•¸æ“šæ—¥æœŸ"""
        dates = []
        etag_folder = self.base_folder / "processed" / "etag"
        
        if etag_folder.exists():
            for date_folder in etag_folder.iterdir():
                if date_folder.is_dir() and self._is_valid_date(date_folder.name):
                    etag_file = date_folder / "etag_travel_time.csv"
                    if etag_file.exists():
                        dates.append(date_folder.name)
        
        return sorted(dates)
    
    def _is_valid_date(self, date_str: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆæ—¥æœŸæ ¼å¼ YYYY-MM-DD"""
        return len(date_str.split('-')) == 3 and len(date_str) == 10
    
    def align_date_data(self, date_str: str) -> Dict:
        """å°é½Šå–®æ—¥è³‡æ–™"""
        if self.debug:
            print(f"ğŸ”— é–‹å§‹å°é½Š {date_str}")
        
        try:
            # è¼‰å…¥è³‡æ–™
            vd_data = self._load_vd_data(date_str)
            etag_data = self._load_etag_data(date_str)
            
            if vd_data.empty:
                return {'error': f'VDè³‡æ–™ä¸å­˜åœ¨: {date_str}'}
            if etag_data.empty:
                return {'error': f'eTagè³‡æ–™ä¸å­˜åœ¨: {date_str}'}
            
            # åŸ·è¡Œå°é½Š
            aligned_records = self._perform_alignment(vd_data, etag_data)
            
            if not aligned_records:
                return {'error': 'ç„¡æ³•ç”¢ç”Ÿå°é½Šè¨˜éŒ„'}
            
            # å»ºç«‹çµæœ
            aligned_df = pd.DataFrame(aligned_records)
            summary = self._generate_summary(aligned_df)
            
            # ä¿å­˜çµæœ
            self._save_results(aligned_df, summary, date_str)
            
            if self.debug:
                print(f"âœ… å°é½Šå®Œæˆ: {len(aligned_df)} ç­†è¨˜éŒ„")
            
            return {
                'aligned': aligned_df,
                'summary': summary
            }
            
        except Exception as e:
            error_msg = f'å°é½Šå¤±æ•—: {str(e)}'
            if self.debug:
                print(f"âŒ {error_msg}")
            return {'error': error_msg}
    
    def _load_vd_data(self, date_str: str) -> pd.DataFrame:
        """è¼‰å…¥VDè³‡æ–™"""
        # å„ªå…ˆè¼‰å…¥æ¸…ç†å¾Œçš„æª”æ¡ˆ
        vd_files = [
            self.base_folder / "cleaned" / date_str / "target_route_data_cleaned.csv",
            self.base_folder / "processed" / "vd" / date_str / "target_route_data.csv"
        ]
        
        for vd_file in vd_files:
            if vd_file.exists():
                try:
                    df = pd.read_csv(vd_file)
                    df['update_time'] = pd.to_datetime(df['update_time'])
                    return df
                except Exception as e:
                    if self.debug:
                        print(f"âš ï¸ VDè¼‰å…¥å¤±æ•—: {vd_file.name} - {e}")
        
        return pd.DataFrame()
    
    def _load_etag_data(self, date_str: str) -> pd.DataFrame:
        """è¼‰å…¥eTagè³‡æ–™"""
        etag_file = self.base_folder / "processed" / "etag" / date_str / "etag_travel_time.csv"
        
        if etag_file.exists():
            try:
                df = pd.read_csv(etag_file)
                df['update_time'] = pd.to_datetime(df['update_time'])
                return df
            except Exception as e:
                if self.debug:
                    print(f"âš ï¸ eTagè¼‰å…¥å¤±æ•—: {e}")
        
        return pd.DataFrame()
    
    def _perform_alignment(self, vd_data: pd.DataFrame, etag_data: pd.DataFrame) -> List[Dict]:
        """åŸ·è¡Œæ™‚ç©ºå°é½Š"""
        aligned_records = []
        
        # éæ­·æ¯å€‹å€åŸŸ
        for region, etag_pairs in self.spatial_mapping.items():
            # ç¯©é¸VDç«™é»
            vd_subset = vd_data[vd_data['vd_id'].str.contains(region, na=False)]
            if vd_subset.empty:
                continue
            
            # å°æ¯å€‹eTagé…å°é€²è¡Œæ™‚é–“å°é½Š
            for etag_pair in etag_pairs:
                etag_subset = etag_data[etag_data['etag_pair_id'] == etag_pair]
                if etag_subset.empty:
                    continue
                
                # æ™‚é–“å°é½Š
                records = self._temporal_alignment(vd_subset, etag_subset, region, etag_pair)
                aligned_records.extend(records)
        
        return aligned_records
    
    def _temporal_alignment(self, vd_data: pd.DataFrame, etag_data: pd.DataFrame, 
                           region: str, etag_pair: str) -> List[Dict]:
        """æ™‚é–“å°é½Šï¼šVD(1åˆ†é˜) â†’ eTag(5åˆ†é˜)"""
        records = []
        
        try:
            # VDæ•¸æ“šèšåˆåˆ°5åˆ†é˜
            vd_grouped = vd_data.copy()
            vd_grouped['time_bin'] = vd_grouped['update_time'].dt.floor('5min')
            
            vd_agg = vd_grouped.groupby('time_bin').agg({
                'speed': 'mean',
                'volume_total': 'sum',
                'occupancy': 'mean'
            }).reset_index()
            
            # èˆ‡eTagæ™‚é–“åŒ¹é…
            for _, etag_row in etag_data.iterrows():
                etag_time = etag_row['update_time']
                
                # æ‰¾æœ€æ¥è¿‘çš„VDæ™‚é–“çª—å£
                time_diffs = abs((vd_agg['time_bin'] - etag_time).dt.total_seconds() / 60)
                
                if len(time_diffs) > 0:
                    min_idx = time_diffs.idxmin()
                    min_diff = time_diffs.iloc[min_idx]
                    
                    if min_diff <= self.sync_tolerance:
                        vd_row = vd_agg.iloc[min_idx]
                        
                        record = {
                            'datetime': etag_time,
                            'region': region,
                            'etag_pair': etag_pair,
                            'vd_speed': float(vd_row['speed']) if pd.notna(vd_row['speed']) else 0,
                            'vd_volume': int(vd_row['volume_total']) if pd.notna(vd_row['volume_total']) else 0,
                            'vd_occupancy': float(vd_row['occupancy']) if pd.notna(vd_row['occupancy']) else 0,
                            'etag_speed': float(etag_row.get('space_mean_speed_kmh', 0)) or 0,
                            'etag_volume': int(etag_row.get('vehicle_count', 0)) or 0,
                            'time_diff_min': float(min_diff)
                        }
                        
                        records.append(record)
        
        except Exception as e:
            if self.debug:
                print(f"âš ï¸ æ™‚é–“å°é½ŠéŒ¯èª¤: {e}")
        
        return records
    
    def _generate_summary(self, aligned_df: pd.DataFrame) -> Dict:
        """ç”Ÿæˆå°é½Šæ‘˜è¦"""
        return {
            'total_records': len(aligned_df),
            'regions': int(aligned_df['region'].nunique()),
            'etag_pairs': int(aligned_df['etag_pair'].nunique()),
            'speed_correlation': float(aligned_df['vd_speed'].corr(aligned_df['etag_speed'])) 
                                if len(aligned_df) > 1 else 0,
            'sync_quality_percent': float((aligned_df['time_diff_min'] <= self.sync_tolerance).mean() * 100)
        }
    
    def _save_results(self, aligned_df: pd.DataFrame, summary: Dict, date_str: str):
        """ä¿å­˜å°é½Šçµæœ"""
        output_folder = self.base_folder / "processed" / "fusion" / date_str
        output_folder.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜å°é½Šæ•¸æ“š
        aligned_file = output_folder / "vd_etag_aligned.csv"
        aligned_df.to_csv(aligned_file, index=False, encoding='utf-8-sig')
        
        # ä¿å­˜æ‘˜è¦
        summary_file = output_folder / "alignment_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2, default=str)
        
        if self.debug:
            print(f"ğŸ’¾ çµæœå·²ä¿å­˜: {aligned_file}")
    
    def batch_align_all_available(self) -> Dict:
        """æ‰¹æ¬¡å°é½Šæ‰€æœ‰å¯ç”¨è³‡æ–™"""
        available = self.get_available_dates()
        common_dates = available['common_dates']
        
        if not common_dates:
            return {'error': 'æ²’æœ‰å¯ç”¨çš„å…±åŒæ—¥æœŸ'}
        
        if self.debug:
            print(f"ğŸš€ æ‰¹æ¬¡è™•ç† {len(common_dates)} å¤©")
        
        results = {}
        for date_str in common_dates:
            result = self.align_date_data(date_str)
            results[date_str] = result
        
        successful = sum(1 for r in results.values() if 'aligned' in r)
        if self.debug:
            print(f"ğŸ æ‰¹æ¬¡å®Œæˆ: {successful}/{len(common_dates)} æˆåŠŸ")
        
        return results
    
    def validate_alignment(self, date_str: str) -> Dict:
        """é©—è­‰å°é½Šå“è³ª"""
        aligned_file = self.base_folder / "processed" / "fusion" / date_str / "vd_etag_aligned.csv"
        
        if not aligned_file.exists():
            return {'error': 'å°é½Šæª”æ¡ˆä¸å­˜åœ¨'}
        
        try:
            df = pd.read_csv(aligned_file)
            
            return {
                'record_count': len(df),
                'time_sync_quality': (df['time_diff_min'] <= self.sync_tolerance).mean() * 100,
                'speed_correlation': df['vd_speed'].corr(df['etag_speed']),
                'data_completeness': df.notna().all(axis=1).mean() * 100
            }
            
        except Exception as e:
            return {'error': f'é©—è­‰å¤±æ•—: {str(e)}'}


# ä¾¿åˆ©å‡½æ•¸
def align_all_available_data(debug: bool = False) -> Dict:
    """å°é½Šæ‰€æœ‰å¯ç”¨è³‡æ–™çš„ä¾¿åˆ©å‡½æ•¸"""
    aligner = SpatialTemporalAligner(debug=debug)
    return aligner.batch_align_all_available()


def get_available_data_status(debug: bool = False) -> Dict:
    """ç²å–å¯ç”¨è³‡æ–™ç‹€æ…‹çš„ä¾¿åˆ©å‡½æ•¸"""
    aligner = SpatialTemporalAligner(debug=debug)
    return aligner.get_available_dates()


if __name__ == "__main__":
    print("ğŸ”— VD+eTagæ™‚ç©ºå°é½Šå™¨ - ç°¡åŒ–ç‰ˆ")
    print("=" * 40)
    
    # åˆå§‹åŒ–å°é½Šå™¨
    aligner = SpatialTemporalAligner(debug=True)
    
    # æª¢æŸ¥å¯ç”¨è³‡æ–™
    available = aligner.get_available_dates()
    print(f"\nğŸ“Š è³‡æ–™ç‹€æ…‹: {len(available['common_dates'])} å¤©å¯å°é½Š")
    
    if available['common_dates']:
        # æ‰¹æ¬¡å°é½Š
        print("\nğŸš€ é–‹å§‹æ‰¹æ¬¡å°é½Š...")
        results = aligner.batch_align_all_available()
        
        # é¡¯ç¤ºçµæœ
        for date_str, result in results.items():
            if 'aligned' in result:
                summary = result['summary']
                print(f"âœ… {date_str}: {summary['total_records']} ç­†, "
                      f"ç›¸é—œæ€§ {summary['speed_correlation']:.3f}")
            else:
                print(f"âŒ {date_str}: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
    else:
        print("\nâš ï¸ æ²’æœ‰å¯ç”¨çš„å…±åŒæ—¥æœŸè³‡æ–™")
        print("è«‹ç¢ºèª data/processed/vd/ å’Œ data/processed/etag/ ç›®éŒ„ä¸‹æœ‰ç›¸åŒæ—¥æœŸçš„è³‡æ–™")