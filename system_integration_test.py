# system_integration_test.py - å®Œæ•´ç³»çµ±æ•´åˆæ¸¬è©¦

"""
åœ‹é“1è™Ÿåœ“å±±-ä¸‰é‡è·¯æ®µäº¤é€šé æ¸¬ç³»çµ± - å®Œæ•´æ•´åˆæ¸¬è©¦
===============================================

æ¸¬è©¦ç›®æ¨™ï¼š
1. ç«¯åˆ°ç«¯æ•¸æ“šæµé©—è­‰
2. æ¨¡å‹è¨“ç·´å’Œæ€§èƒ½è©•ä¼°
3. é æ¸¬æº–ç¢ºæ€§é©—è­‰
4. ç³»çµ±ç©©å®šæ€§æ¸¬è©¦
5. æ€§èƒ½åŸºæº–æ¸¬è©¦

æ•¸æ“šæµï¼š
Raw VD/eTag â†’ æ™‚ç©ºå°é½Š â†’ ç‰¹å¾µèåˆ â†’ æ¨¡å‹è¨“ç·´ â†’ 15åˆ†é˜é æ¸¬

ä½œè€…: äº¤é€šé æ¸¬å°ˆæ¡ˆåœ˜éšŠ
æ—¥æœŸ: 2025-01-23
"""

import sys
import os
import time
import json
from datetime import datetime, timedelta
from pathlib import Path
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append('src')

class SystemIntegrationTester:
    """ç³»çµ±æ•´åˆæ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.test_results = {}
        self.performance_metrics = {}
        self.models_trained = False
        
    def test_complete_data_pipeline(self):
        """æ¸¬è©¦1: å®Œæ•´æ•¸æ“šç®¡é“"""
        print("ğŸ§ª æ¸¬è©¦1: å®Œæ•´æ•¸æ“šç®¡é“é©—è­‰")
        print("=" * 50)
        
        try:
            # æª¢æŸ¥æ™‚ç©ºå°é½Šæ•¸æ“š
            from spatial_temporal_aligner import get_available_data_status
            alignment_status = get_available_data_status(debug=False)
            
            print(f"ğŸ“Š æ™‚ç©ºå°é½Šç‹€æ…‹:")
            print(f"   å¯ç”¨æ—¥æœŸ: {alignment_status['total_days']} å¤©")
            
            if alignment_status['total_days'] == 0:
                print("âŒ æ²’æœ‰æ™‚ç©ºå°é½Šæ•¸æ“š")
                return False
            
            # æª¢æŸ¥èåˆæ•¸æ“š
            from fusion_engine import get_fusion_data_status
            fusion_status = get_fusion_data_status(debug=False)
            
            print(f"ğŸ“Š èåˆæ•¸æ“šç‹€æ…‹:")
            print(f"   å¯ç”¨æ—¥æœŸ: {fusion_status['total_days']} å¤©")
            
            if fusion_status['total_days'] == 0:
                print("âŒ æ²’æœ‰èåˆæ•¸æ“š")
                return False
            
            # æª¢æŸ¥æ•¸æ“šä¸€è‡´æ€§
            if alignment_status['total_days'] == fusion_status['total_days']:
                print("âœ… æ•¸æ“šç®¡é“å®Œæ•´ä¸”ä¸€è‡´")
                return True
            else:
                print(f"âš ï¸ æ•¸æ“šä¸ä¸€è‡´ï¼šå°é½Š{alignment_status['total_days']}å¤©ï¼Œèåˆ{fusion_status['total_days']}å¤©")
                return False
                
        except Exception as e:
            print(f"âŒ æ•¸æ“šç®¡é“æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def test_model_training_pipeline(self, sample_rate=0.3):
        """æ¸¬è©¦2: æ¨¡å‹è¨“ç·´ç®¡é“"""
        print(f"\nğŸ§ª æ¸¬è©¦2: æ¨¡å‹è¨“ç·´ç®¡é“ (æ¡æ¨£ç‡: {sample_rate})")
        print("=" * 50)
        
        try:
            from enhanced_predictor import EnhancedPredictor
            
            predictor = EnhancedPredictor(debug=True)
            
            print("ğŸš€ é–‹å§‹å®Œæ•´æ¨¡å‹è¨“ç·´...")
            start_time = time.time()
            
            # åŸ·è¡Œå®Œæ•´è¨“ç·´ç®¡é“
            result = predictor.train_complete_pipeline(
                sample_rate=sample_rate,
                test_size=0.2
            )
            
            training_time = time.time() - start_time
            
            if 'error' in result:
                print(f"âŒ è¨“ç·´å¤±æ•—: {result['error']}")
                return False
            
            # è¨˜éŒ„è¨“ç·´çµæœ
            self.models_trained = True
            self.training_result = result
            
            results = result['results']
            report = result['report']
            
            print(f"âœ… æ¨¡å‹è¨“ç·´å®Œæˆ:")
            print(f"   â±ï¸ è¨“ç·´æ™‚é–“: {training_time:.1f} ç§’")
            print(f"   ğŸ“Š è¨“ç·´æ•¸æ“š: {result['training_data_size']:,} ç­†")
            print(f"   ğŸ¯ ç‰¹å¾µæ•¸é‡: {result['feature_count']}")
            
            print(f"\nğŸ“Š æ¨¡å‹æ€§èƒ½:")
            for model_name, model_result in results.items():
                metrics = model_result['metrics']
                print(f"   {model_name}:")
                print(f"     RÂ²: {metrics['r2']:.3f}")
                print(f"     RMSE: {metrics['rmse']:.2f}")
                print(f"     MAE: {metrics['mae']:.2f}")
                print(f"     MAPE: {metrics['mape']:.1f}%")
            
            # ä¿å­˜æ€§èƒ½æŒ‡æ¨™
            self.performance_metrics = {
                'training_time': training_time,
                'data_size': result['training_data_size'],
                'feature_count': result['feature_count'],
                'model_performance': {name: res['metrics'] for name, res in results.items()}
            }
            
            # æ€§èƒ½æª¢æŸ¥
            best_r2 = max(res['metrics']['r2'] for res in results.values())
            
            if best_r2 > 0.8:
                print(f"ğŸ‰ æ¨¡å‹æ€§èƒ½å„ªç§€ (æœ€ä½³RÂ² = {best_r2:.3f})")
                return True
            elif best_r2 > 0.7:
                print(f"âœ… æ¨¡å‹æ€§èƒ½è‰¯å¥½ (æœ€ä½³RÂ² = {best_r2:.3f})")
                return True
            elif best_r2 > 0.5:
                print(f"âš ï¸ æ¨¡å‹æ€§èƒ½å¯æ¥å— (æœ€ä½³RÂ² = {best_r2:.3f})")
                return True
            else:
                print(f"âŒ æ¨¡å‹æ€§èƒ½ä¸è¶³ (æœ€ä½³RÂ² = {best_r2:.3f})")
                return False
                
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¨“ç·´æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def test_prediction_accuracy(self, test_samples=100):
        """æ¸¬è©¦3: é æ¸¬æº–ç¢ºæ€§é©—è­‰"""
        print(f"\nğŸ§ª æ¸¬è©¦3: é æ¸¬æº–ç¢ºæ€§é©—è­‰ ({test_samples} æ¨£æœ¬)")
        print("=" * 50)
        
        if not self.models_trained:
            print("âš ï¸ æ¨¡å‹å°šæœªè¨“ç·´ï¼Œè·³éé æ¸¬æ¸¬è©¦")
            return False
        
        try:
            from enhanced_predictor import load_enhanced_predictor
            
            # è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹
            predictor = load_enhanced_predictor(debug=False)
            
            # è¼‰å…¥æ¸¬è©¦æ•¸æ“š
            df = predictor.load_fusion_data(sample_rate=0.1)
            X, y = predictor.prepare_features(df)
            
            # ä½¿ç”¨æœ€å¾Œ20%ä½œç‚ºæ¸¬è©¦é›†
            test_start_idx = int(len(X) * 0.8)
            X_test = X[test_start_idx:]
            y_test = y[test_start_idx:]
            
            # éš¨æ©Ÿé¸æ“‡æ¸¬è©¦æ¨£æœ¬
            if len(X_test) > test_samples:
                indices = np.random.choice(len(X_test), test_samples, replace=False)
                X_test = X_test[indices]
                y_test = y_test[indices]
            
            print(f"ğŸ“Š é æ¸¬æº–ç¢ºæ€§æ¸¬è©¦:")
            print(f"   æ¸¬è©¦æ¨£æœ¬: {len(X_test)} å€‹")
            
            # æ‰¹æ¬¡é æ¸¬
            all_predictions = []
            prediction_times = []
            
            for i in range(len(X_test)):
                start_time = time.time()
                pred_result = predictor.predict_15_minutes(X_test[i:i+1])
                pred_time = time.time() - start_time
                
                prediction_times.append(pred_time * 1000)  # ms
                all_predictions.append(pred_result['ensemble']['predicted_speed'])
            
            predictions = np.array(all_predictions)
            
            # è¨ˆç®—æº–ç¢ºæ€§æŒ‡æ¨™
            from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
            
            rmse = np.sqrt(mean_squared_error(y_test, predictions))
            mae = mean_absolute_error(y_test, predictions)
            r2 = r2_score(y_test, predictions)
            mape = np.mean(np.abs((y_test - predictions) / (y_test + 1e-8))) * 100
            
            avg_pred_time = np.mean(prediction_times)
            
            print(f"âœ… é æ¸¬æº–ç¢ºæ€§çµæœ:")
            print(f"   RÂ²: {r2:.3f}")
            print(f"   RMSE: {rmse:.2f} km/h")
            print(f"   MAE: {mae:.2f} km/h")
            print(f"   MAPE: {mape:.1f}%")
            print(f"   å¹³å‡é æ¸¬æ™‚é–“: {avg_pred_time:.1f} ms")
            
            # æº–ç¢ºæ€§åˆ†æ
            error_rates = np.abs((y_test - predictions) / (y_test + 1e-8)) * 100
            accurate_predictions = (error_rates <= 10).sum()  # èª¤å·®<=10%
            accuracy_rate = (accurate_predictions / len(error_rates)) * 100
            
            print(f"   é æ¸¬æº–ç¢ºç‡ (èª¤å·®â‰¤10%): {accuracy_rate:.1f}%")
            
            # ä¿å­˜é æ¸¬çµæœ
            self.prediction_accuracy = {
                'r2': r2,
                'rmse': rmse,
                'mae': mae,
                'mape': mape,
                'accuracy_rate': accuracy_rate,
                'avg_prediction_time': avg_pred_time
            }
            
            # æº–ç¢ºæ€§æ¨™æº–
            if r2 > 0.8 and accuracy_rate > 80:
                print(f"ğŸ‰ é æ¸¬æº–ç¢ºæ€§å„ªç§€")
                return True
            elif r2 > 0.7 and accuracy_rate > 70:
                print(f"âœ… é æ¸¬æº–ç¢ºæ€§è‰¯å¥½")
                return True
            else:
                print(f"âš ï¸ é æ¸¬æº–ç¢ºæ€§éœ€è¦æ”¹å–„")
                return False
                
        except Exception as e:
            print(f"âŒ é æ¸¬æº–ç¢ºæ€§æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def test_system_stability(self, stress_test_duration=60):
        """æ¸¬è©¦4: ç³»çµ±ç©©å®šæ€§æ¸¬è©¦"""
        print(f"\nğŸ§ª æ¸¬è©¦4: ç³»çµ±ç©©å®šæ€§æ¸¬è©¦ ({stress_test_duration}ç§’)")
        print("=" * 50)
        
        if not self.models_trained:
            print("âš ï¸ æ¨¡å‹å°šæœªè¨“ç·´ï¼Œè·³éç©©å®šæ€§æ¸¬è©¦")
            return False
        
        try:
            from enhanced_predictor import load_enhanced_predictor
            
            predictor = load_enhanced_predictor(debug=False)
            
            # æº–å‚™æ¸¬è©¦æ•¸æ“š
            df = predictor.load_fusion_data(sample_rate=0.05)
            X, y = predictor.prepare_features(df)
            
            print(f"ğŸ”„ åŸ·è¡Œç©©å®šæ€§å£“åŠ›æ¸¬è©¦...")
            
            start_time = time.time()
            prediction_count = 0
            error_count = 0
            response_times = []
            
            while time.time() - start_time < stress_test_duration:
                try:
                    # éš¨æ©Ÿé¸æ“‡ä¸€å€‹æ¨£æœ¬
                    idx = np.random.randint(0, len(X))
                    test_sample = X[idx:idx+1]
                    
                    # é æ¸¬
                    pred_start = time.time()
                    result = predictor.predict_15_minutes(test_sample)
                    pred_time = time.time() - pred_start
                    
                    response_times.append(pred_time * 1000)  # ms
                    prediction_count += 1
                    
                except Exception as e:
                    error_count += 1
                    if error_count > 10:  # è¶…é10å€‹éŒ¯èª¤å°±åœæ­¢
                        break
            
            test_duration = time.time() - start_time
            
            if prediction_count > 0:
                avg_response_time = np.mean(response_times)
                max_response_time = np.max(response_times)
                predictions_per_second = prediction_count / test_duration
                error_rate = (error_count / (prediction_count + error_count)) * 100
                
                print(f"âœ… ç©©å®šæ€§æ¸¬è©¦çµæœ:")
                print(f"   æ¸¬è©¦æ™‚é•·: {test_duration:.1f} ç§’")
                print(f"   é æ¸¬æ¬¡æ•¸: {prediction_count}")
                print(f"   éŒ¯èª¤æ¬¡æ•¸: {error_count}")
                print(f"   éŒ¯èª¤ç‡: {error_rate:.1f}%")
                print(f"   å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_response_time:.1f} ms")
                print(f"   æœ€å¤§éŸ¿æ‡‰æ™‚é–“: {max_response_time:.1f} ms")
                print(f"   é æ¸¬ååé‡: {predictions_per_second:.1f} æ¬¡/ç§’")
                
                # ç©©å®šæ€§æ¨™æº–
                stability_good = (
                    error_rate < 1 and  # éŒ¯èª¤ç‡<1%
                    avg_response_time < 100 and  # å¹³å‡éŸ¿æ‡‰<100ms
                    predictions_per_second > 5  # ååé‡>5æ¬¡/ç§’
                )
                
                if stability_good:
                    print(f"ğŸ‰ ç³»çµ±ç©©å®šæ€§å„ªç§€")
                    return True
                else:
                    print(f"âš ï¸ ç³»çµ±ç©©å®šæ€§éœ€è¦æ”¹å–„")
                    return False
            else:
                print(f"âŒ ç©©å®šæ€§æ¸¬è©¦å¤±æ•—ï¼šç„¡æ³•å®Œæˆé æ¸¬")
                return False
                
        except Exception as e:
            print(f"âŒ ç©©å®šæ€§æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def test_real_world_scenarios(self):
        """æ¸¬è©¦5: çœŸå¯¦å ´æ™¯æ¨¡æ“¬"""
        print(f"\nğŸ§ª æ¸¬è©¦5: çœŸå¯¦å ´æ™¯æ¨¡æ“¬æ¸¬è©¦")
        print("=" * 50)
        
        if not self.models_trained:
            print("âš ï¸ æ¨¡å‹å°šæœªè¨“ç·´ï¼Œè·³éå ´æ™¯æ¸¬è©¦")
            return False
        
        try:
            from enhanced_predictor import load_enhanced_predictor
            
            predictor = load_enhanced_predictor(debug=False)
            
            # æ¨¡æ“¬ä¸åŒäº¤é€šå ´æ™¯
            scenarios = [
                {'name': 'å¹³æ—¥å°–å³°', 'speed_range': (20, 50), 'expected': 'æ“å µ'},
                {'name': 'å¹³æ—¥é›¢å³°', 'speed_range': (60, 90), 'expected': 'é †æš¢'},
                {'name': 'å‡æ—¥é›¢å³°', 'speed_range': (70, 100), 'expected': 'éå¸¸é †æš¢'},
                {'name': 'äº‹æ•…ç‹€æ³', 'speed_range': (10, 30), 'expected': 'åš´é‡æ“å µ'}
            ]
            
            print(f"ğŸš— æ¨¡æ“¬çœŸå¯¦äº¤é€šå ´æ™¯:")
            
            scenario_results = []
            
            for scenario in scenarios:
                print(f"\n   å ´æ™¯: {scenario['name']}")
                
                # å‰µå»ºæ¨¡æ“¬ç‰¹å¾µæ•¸æ“š
                num_features = len(predictor.feature_names)
                simulated_features = np.random.rand(1, num_features)
                
                # é€²è¡Œé æ¸¬
                prediction = predictor.predict_15_minutes(simulated_features)
                pred_speed = prediction['ensemble']['predicted_speed']
                confidence = prediction['ensemble']['confidence']
                
                # åˆ¤æ–·äº¤é€šç‹€æ…‹
                if pred_speed < 30:
                    traffic_state = 'åš´é‡æ“å µ'
                elif pred_speed < 50:
                    traffic_state = 'æ“å µ'
                elif pred_speed < 70:
                    traffic_state = 'é †æš¢'
                else:
                    traffic_state = 'éå¸¸é †æš¢'
                
                print(f"     é æ¸¬é€Ÿåº¦: {pred_speed:.1f} km/h")
                print(f"     äº¤é€šç‹€æ…‹: {traffic_state}")
                print(f"     é æ¸¬ä¿¡å¿ƒ: {confidence}%")
                
                scenario_results.append({
                    'scenario': scenario['name'],
                    'predicted_speed': pred_speed,
                    'traffic_state': traffic_state,
                    'confidence': confidence
                })
            
            print(f"\nâœ… çœŸå¯¦å ´æ™¯æ¨¡æ“¬å®Œæˆ")
            print(f"   æ¨¡æ“¬å ´æ™¯: {len(scenarios)} å€‹")
            print(f"   é æ¸¬ç¯„åœ: {min(r['predicted_speed'] for r in scenario_results):.1f} - {max(r['predicted_speed'] for r in scenario_results):.1f} km/h")
            
            return True
            
        except Exception as e:
            print(f"âŒ çœŸå¯¦å ´æ™¯æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def generate_integration_report(self):
        """ç”Ÿæˆæ•´åˆæ¸¬è©¦å ±å‘Š"""
        print(f"\n" + "="*60)
        print("ğŸ“‹ åœ‹é“1è™Ÿåœ“å±±-ä¸‰é‡è·¯æ®µäº¤é€šé æ¸¬ç³»çµ±æ•´åˆæ¸¬è©¦å ±å‘Š")
        print("="*60)
        
        print(f"\nğŸ¯ ç³»çµ±æ¦‚è¿°:")
        print(f"   è·¯æ®µ: åœ‹é“1è™Ÿåœ“å±±(23K)-å°åŒ—(25K)-ä¸‰é‡(27K)")
        print(f"   ç¯„åœ: 3.8å…¬é‡Œé›™å‘ï¼Œç¸½é•·7.6å…¬é‡Œ")
        print(f"   æŠ€è¡“: VD+eTagå¤šæºèåˆé æ¸¬")
        
        if hasattr(self, 'performance_metrics'):
            metrics = self.performance_metrics
            print(f"\nğŸ“Š è¨“ç·´æ•¸æ“šçµ±è¨ˆ:")
            print(f"   æ•¸æ“šé‡: {metrics['data_size']:,} ç­†è¨˜éŒ„")
            print(f"   ç‰¹å¾µæ•¸: {metrics['feature_count']} å€‹èåˆç‰¹å¾µ")
            print(f"   è¨“ç·´æ™‚é–“: {metrics['training_time']:.1f} ç§’")
        
        if hasattr(self, 'prediction_accuracy'):
            acc = self.prediction_accuracy
            print(f"\nğŸ¯ é æ¸¬æ€§èƒ½:")
            print(f"   é æ¸¬æº–ç¢ºç‡: RÂ² = {acc['r2']:.3f}")
            print(f"   å¹³å‡èª¤å·®: MAE = {acc['mae']:.1f} km/h")
            print(f"   æº–ç¢ºé æ¸¬ç‡: {acc['accuracy_rate']:.1f}% (èª¤å·®â‰¤10%)")
            print(f"   éŸ¿æ‡‰æ™‚é–“: {acc['avg_prediction_time']:.1f} ms")
        
        print(f"\nâš¡ ç³»çµ±æ€§èƒ½æŒ‡æ¨™:")
        print(f"   é æ¸¬æ™‚ç¨‹: 15åˆ†é˜çŸ­æœŸé æ¸¬")
        print(f"   æ›´æ–°é »ç‡: å¯¦æ™‚ï¼ˆæ¯«ç§’ç´šéŸ¿æ‡‰ï¼‰")
        print(f"   æ•¸æ“šä¾†æº: VDè»Šè¼›åµæ¸¬å™¨ + eTagé›»å­æ¨™ç±¤")
        print(f"   æ¨¡å‹æ¶æ§‹: XGBoost + RandomForest èåˆ")
        
        print(f"\nğŸ† é”æˆç›®æ¨™:")
        if hasattr(self, 'prediction_accuracy'):
            r2 = self.prediction_accuracy['r2']
            response_time = self.prediction_accuracy['avg_prediction_time']
            
            if r2 > 0.8:
                print(f"   âœ… é æ¸¬æº–ç¢ºç‡å„ªç§€ (ç›®æ¨™: >85%, å¯¦éš›: {r2*100:.1f}%)")
            elif r2 > 0.7:
                print(f"   âœ… é æ¸¬æº–ç¢ºç‡è‰¯å¥½ (ç›®æ¨™: >85%, å¯¦éš›: {r2*100:.1f}%)")
            else:
                print(f"   âš ï¸ é æ¸¬æº–ç¢ºç‡éœ€æ”¹å–„ (ç›®æ¨™: >85%, å¯¦éš›: {r2*100:.1f}%)")
            
            if response_time < 100:
                print(f"   âœ… éŸ¿æ‡‰æ™‚é–“é”æ¨™ (ç›®æ¨™: <100ms, å¯¦éš›: {response_time:.1f}ms)")
            else:
                print(f"   âš ï¸ éŸ¿æ‡‰æ™‚é–“éœ€å„ªåŒ– (ç›®æ¨™: <100ms, å¯¦éš›: {response_time:.1f}ms)")
        
        print(f"\nğŸš€ ç³»çµ±å°±ç·’ç‹€æ…‹:")
        models_folder = Path("models/fusion_models")
        model_files = list(models_folder.glob("*.json")) + list(models_folder.glob("*.pkl"))
        
        if len(model_files) >= 4:
            print(f"   âœ… èåˆé æ¸¬æ¨¡å‹å·²è¨“ç·´ä¸¦ä¿å­˜")
            print(f"   âœ… ç³»çµ±å¯é€²è¡Œ15åˆ†é˜äº¤é€šé æ¸¬")
            print(f"   âœ… é©ç”¨æ–¼åœ‹é“1è™Ÿåœ“å±±-ä¸‰é‡è·¯æ®µ")
        else:
            print(f"   âš ï¸ æ¨¡å‹æª”æ¡ˆä¸å®Œæ•´ï¼Œéœ€è¦é‡æ–°è¨“ç·´")
        
        print(f"\nğŸ“ˆ æ‡‰ç”¨åƒ¹å€¼:")
        print(f"   ğŸš— ç”¨è·¯äºº: ç²¾æº–å‡ºè¡Œæ™‚é–“è¦åŠƒ")
        print(f"   ğŸ›ï¸ äº¤é€šç®¡ç†: å³æ™‚æ“å µé è­¦èˆ‡ç–å°")
        print(f"   ğŸ“± å°èˆªç³»çµ±: å‹•æ…‹è·¯ç·šè¦åŠƒå„ªåŒ–")
        print(f"   ğŸ¢ ç‰©æµæ¥­: é‹è¼¸æ™‚é–“æˆæœ¬æ§åˆ¶")


def main():
    """ä¸»æ•´åˆæ¸¬è©¦ç¨‹åº"""
    print("ğŸ§ª åœ‹é“1è™Ÿåœ“å±±-ä¸‰é‡è·¯æ®µäº¤é€šé æ¸¬ç³»çµ± - å®Œæ•´æ•´åˆæ¸¬è©¦")
    print("=" * 70)
    print("ğŸ¯ ç›®æ¨™: é©—è­‰ç«¯åˆ°ç«¯é æ¸¬ç³»çµ±æ€§èƒ½èˆ‡æº–ç¢ºæ€§")
    print("=" * 70)
    
    tester = SystemIntegrationTester()
    
    # åŸ·è¡Œæ•´åˆæ¸¬è©¦
    test_sequence = [
        ("å®Œæ•´æ•¸æ“šç®¡é“é©—è­‰", tester.test_complete_data_pipeline),
        ("æ¨¡å‹è¨“ç·´ç®¡é“", lambda: tester.test_model_training_pipeline(sample_rate=0.5)),
        ("é æ¸¬æº–ç¢ºæ€§é©—è­‰", lambda: tester.test_prediction_accuracy(test_samples=200)),
        ("ç³»çµ±ç©©å®šæ€§æ¸¬è©¦", lambda: tester.test_system_stability(stress_test_duration=30)),
        ("çœŸå¯¦å ´æ™¯æ¨¡æ“¬", tester.test_real_world_scenarios)
    ]
    
    results = []
    total_start_time = time.time()
    
    for test_name, test_func in test_sequence:
        try:
            success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"âŒ {test_name} æ¸¬è©¦ç•°å¸¸: {e}")
            results.append((test_name, False))
    
    total_duration = time.time() - total_start_time
    
    # ç”Ÿæˆæœ€çµ‚å ±å‘Š
    tester.generate_integration_report()
    
    # æ¸¬è©¦ç¸½çµ
    passed_tests = sum(1 for _, success in results if success)
    total_tests = len(results)
    success_rate = (passed_tests / total_tests) * 100
    
    print(f"\n" + "="*60)
    print(f"ğŸ“Š æ•´åˆæ¸¬è©¦ç¸½çµ")
    print("="*60)
    print(f"ç¸½æ¸¬è©¦é …ç›®: {total_tests}")
    print(f"é€šéæ¸¬è©¦: {passed_tests}")
    print(f"æˆåŠŸç‡: {success_rate:.1f}%")
    print(f"ç¸½æ¸¬è©¦æ™‚é–“: {total_duration:.1f} ç§’")
    
    print(f"\nè©³ç´°çµæœ:")
    for test_name, success in results:
        status = "âœ… é€šé" if success else "âŒ å¤±æ•—"
        print(f"   â€¢ {test_name}: {status}")
    
    if success_rate >= 80:
        print(f"\nğŸ‰ ç³»çµ±æ•´åˆæ¸¬è©¦é€šéï¼äº¤é€šé æ¸¬ç³»çµ±å·²æº–å‚™å°±ç·’ï¼")
        print(f"\nğŸš€ å¯ä»¥é–‹å§‹éƒ¨ç½²å’Œä½¿ç”¨:")
        print("   1. å³æ™‚15åˆ†é˜äº¤é€šé æ¸¬")
        print("   2. äº¤é€šç‹€æ³ç›£æ§å’Œé è­¦")
        print("   3. å°èˆªç³»çµ±æ•´åˆæ‡‰ç”¨")
        return True
    else:
        print(f"\nâš ï¸ ç³»çµ±éœ€è¦é€²ä¸€æ­¥å„ªåŒ–ï¼Œå»ºè­°:")
        print("   1. æª¢æŸ¥æ•¸æ“šå“è³ªå’Œå®Œæ•´æ€§")
        print("   2. èª¿æ•´æ¨¡å‹åƒæ•¸å’Œç‰¹å¾µå·¥ç¨‹")
        print("   3. å¢åŠ è¨“ç·´æ•¸æ“šé‡")
        return False


if __name__ == "__main__":
    success = main()
    
    if success:
        print(f"\nğŸŠ åœ‹é“1è™Ÿåœ“å±±-ä¸‰é‡äº¤é€šé æ¸¬ç³»çµ±æ•´åˆæ¸¬è©¦å®Œæˆï¼")
        print(f"ğŸš— Ready for Real-world Traffic Prediction! ğŸš—")
    else:
        print(f"\nğŸ”§ è«‹æ ¹æ“šæ¸¬è©¦çµæœé€²è¡Œç³»çµ±å„ªåŒ–")