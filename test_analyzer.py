"""
ç°¡åŒ–ç‰ˆäº¤é€šæµé‡åˆ†æå™¨æ¸¬è©¦ç¨‹å¼
============================

å°ˆæ³¨æ ¸å¿ƒæ¸¬è©¦åŠŸèƒ½ï¼š
1. ğŸ§ª åˆ†æå™¨å°å…¥å’Œåˆå§‹åŒ–
2. ğŸ“Š æ•¸æ“šè¼‰å…¥å’Œç‰¹æ€§åˆ†æ
3. ğŸ¤– AIæ¨¡å‹è©•ä¼°æ¸¬è©¦
4. ğŸ“‹ å ±å‘Šç”Ÿæˆæ¸¬è©¦
5. âš¡ æ€§èƒ½æ¸¬è©¦

ä½œè€…: äº¤é€šé æ¸¬å°ˆæ¡ˆåœ˜éšŠ
æ—¥æœŸ: 2025-07-21 (ç°¡åŒ–æ ¸å¿ƒç‰ˆ)
"""

import sys
import os
import time
import psutil
from datetime import datetime
from pathlib import Path

# æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append('src')

def test_analyzer_import():
    """æ¸¬è©¦1: åˆ†æå™¨å°å…¥"""
    print("ğŸ§ª æ¸¬è©¦1: åˆ†æå™¨å°å…¥")
    print("-" * 50)
    
    try:
        from flow_analyzer import SimplifiedTrafficAnalyzer, quick_analyze
        print("âœ… æˆåŠŸå°å…¥ SimplifiedTrafficAnalyzer")
        print("âœ… æˆåŠŸå°å…¥ quick_analyze å‡½æ•¸")
        
        # æª¢æŸ¥é—œéµæ–¹æ³•
        analyzer = SimplifiedTrafficAnalyzer()
        required_methods = [
            'load_data', 'analyze_data_characteristics',
            'evaluate_ai_model_suitability', 'generate_comprehensive_report'
        ]
        
        missing_methods = []
        for method in required_methods:
            if hasattr(analyzer, method):
                print(f"âœ… æ–¹æ³• {method} å­˜åœ¨")
            else:
                print(f"âŒ æ–¹æ³• {method} ç¼ºå¤±")
                missing_methods.append(method)
        
        # æª¢æŸ¥é æ¸¬é…ç½®
        config = analyzer.prediction_config
        print(f"âœ… é æ¸¬é…ç½®:")
        print(f"   ç›®æ¨™æ¬„ä½: {config['target_columns']}")
        print(f"   LSTMæœ€å°è¨˜éŒ„: {config['min_records_for_lstm']:,}")
        
        return len(missing_methods) == 0
        
    except ImportError as e:
        print(f"âŒ å°å…¥éŒ¯èª¤: {e}")
        return False
    except Exception as e:
        print(f"âŒ å…¶ä»–éŒ¯èª¤: {e}")
        return False


def test_data_loading():
    """æ¸¬è©¦2: æ•¸æ“šè¼‰å…¥åŠŸèƒ½"""
    print("\nğŸ§ª æ¸¬è©¦2: æ•¸æ“šè¼‰å…¥åŠŸèƒ½")
    print("-" * 50)
    
    try:
        from flow_analyzer import SimplifiedTrafficAnalyzer
        
        analyzer = SimplifiedTrafficAnalyzer()
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å¯ç”¨æ•¸æ“š
        if not analyzer.available_dates:
            print("âš ï¸ æœªç™¼ç¾æ¸…ç†å¾Œæ•¸æ“šï¼Œè·³éæ•¸æ“šè¼‰å…¥æ¸¬è©¦")
            return True
        
        print(f"ğŸ” ç™¼ç¾ {len(analyzer.available_dates)} å€‹æ¸…ç†å¾Œæ—¥æœŸ")
        
        # æ¸¬è©¦æ•¸æ“šè¼‰å…¥
        start_time = time.time()
        success = analyzer.load_data(sample_rate=0.5)  # ä½¿ç”¨50%æ¡æ¨£åŠ é€Ÿæ¸¬è©¦
        load_time = time.time() - start_time
        
        if success:
            total_records = sum(len(df) for df in analyzer.datasets.values())
            print(f"âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸ")
            print(f"   è¼‰å…¥æ™‚é–“: {load_time:.2f} ç§’")
            print(f"   ç¸½è¨˜éŒ„æ•¸: {total_records:,}")
            print(f"   æ•¸æ“šé›†æ•¸: {len(analyzer.datasets)}")
            
            # æª¢æŸ¥æ•¸æ“šçµæ§‹
            for name, df in analyzer.datasets.items():
                print(f"   {name}: {len(df):,} ç­†è¨˜éŒ„")
            
            return True
        else:
            print("âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—")
            return False
            
    except Exception as e:
        print(f"âŒ æ•¸æ“šè¼‰å…¥æ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_data_analysis():
    """æ¸¬è©¦3: æ•¸æ“šç‰¹æ€§åˆ†æ"""
    print("\nğŸ§ª æ¸¬è©¦3: æ•¸æ“šç‰¹æ€§åˆ†æ")
    print("-" * 50)
    
    try:
        from flow_analyzer import SimplifiedTrafficAnalyzer
        
        analyzer = SimplifiedTrafficAnalyzer()
        
        if not analyzer.load_data(sample_rate=0.3):  # ä½¿ç”¨30%æ¡æ¨£
            print("âš ï¸ ç„¡æ•¸æ“šå¯åˆ†æï¼Œè·³éæ­¤æ¸¬è©¦")
            return True
        
        # åŸ·è¡Œæ•¸æ“šç‰¹æ€§åˆ†æ
        start_time = time.time()
        characteristics = analyzer.analyze_data_characteristics()
        analysis_time = time.time() - start_time
        
        print(f"âœ… æ•¸æ“šç‰¹æ€§åˆ†æå®Œæˆ")
        print(f"   åˆ†ææ™‚é–“: {analysis_time:.2f} ç§’")
        
        # æª¢æŸ¥åˆ†æçµæœçµæ§‹
        required_keys = ['data_summary', 'quality_metrics', 'time_coverage', 'prediction_readiness']
        for key in required_keys:
            if key in characteristics:
                print(f"   âœ… {key} åˆ†æå®Œæˆ")
            else:
                print(f"   âŒ {key} åˆ†æç¼ºå¤±")
                return False
        
        # é¡¯ç¤ºé—œéµæŒ‡æ¨™
        time_coverage = characteristics.get('time_coverage', {})
        quality_metrics = characteristics.get('quality_metrics', {})
        prediction_readiness = characteristics.get('prediction_readiness', {})
        
        print(f"ğŸ“Š é—œéµæŒ‡æ¨™:")
        print(f"   ç¸½è¨˜éŒ„æ•¸: {time_coverage.get('total_records', 0):,}")
        print(f"   æ™‚é–“è·¨åº¦: {time_coverage.get('date_span_days', 0)} å¤©")
        print(f"   æ•´é«”å“è³ª: {quality_metrics.get('overall_quality', 0):.1f}/100")
        print(f"   VDç«™é»æ•¸: {prediction_readiness.get('unique_vd_stations', 0)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•¸æ“šåˆ†ææ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_ai_model_evaluation():
    """æ¸¬è©¦4: AIæ¨¡å‹è©•ä¼°åŠŸèƒ½"""
    print("\nğŸ§ª æ¸¬è©¦4: AIæ¨¡å‹è©•ä¼°åŠŸèƒ½")
    print("-" * 50)
    
    try:
        from flow_analyzer import SimplifiedTrafficAnalyzer
        
        analyzer = SimplifiedTrafficAnalyzer()
        
        if not analyzer.load_data(sample_rate=0.3):
            print("âš ï¸ ç„¡æ•¸æ“šå¯è©•ä¼°ï¼Œè·³éæ­¤æ¸¬è©¦")
            return True
        
        # å…ˆé€²è¡Œæ•¸æ“šç‰¹æ€§åˆ†æï¼ˆAIè©•ä¼°çš„å‰æï¼‰
        analyzer.analyze_data_characteristics()
        
        # åŸ·è¡ŒAIæ¨¡å‹è©•ä¼°
        start_time = time.time()
        ai_evaluation = analyzer.evaluate_ai_model_suitability()
        eval_time = time.time() - start_time
        
        print(f"âœ… AIæ¨¡å‹è©•ä¼°å®Œæˆ")
        print(f"   è©•ä¼°æ™‚é–“: {eval_time:.2f} ç§’")
        
        # æª¢æŸ¥è©•ä¼°çµæœ
        required_keys = ['model_suitability', 'recommendations', 'data_readiness']
        for key in required_keys:
            if key in ai_evaluation:
                print(f"   âœ… {key} è©•ä¼°å®Œæˆ")
            else:
                print(f"   âŒ {key} è©•ä¼°ç¼ºå¤±")
                return False
        
        # é¡¯ç¤ºæ¨¡å‹æ¨è–¦çµæœ
        recommendations = ai_evaluation.get('recommendations', [])
        print(f"ğŸ¤– AIæ¨¡å‹æ¨è–¦çµæœ:")
        
        if recommendations:
            for rec in recommendations:
                print(f"   {rec['priority']} {rec['model']}: {rec['score']:.1f}åˆ†")
                print(f"      é æœŸæº–ç¢ºç‡: {rec['expected_accuracy']}")
        else:
            print("   âš ï¸ æœªç”Ÿæˆæ¨¡å‹æ¨è–¦")
        
        # æª¢æŸ¥æ•¸æ“šå°±ç·’åº¦
        data_readiness = ai_evaluation.get('data_readiness', {})
        lstm_ready = data_readiness.get('lstm_ready', False)
        xgboost_ready = data_readiness.get('xgboost_ready', False)
        rf_ready = data_readiness.get('rf_ready', False)
        
        print(f"ğŸ“ˆ æ¨¡å‹å°±ç·’åº¦:")
        print(f"   LSTMå°±ç·’: {'âœ… æ˜¯' if lstm_ready else 'âŒ å¦'}")
        print(f"   XGBoostå°±ç·’: {'âœ… æ˜¯' if xgboost_ready else 'âŒ å¦'}")
        print(f"   éš¨æ©Ÿæ£®æ—å°±ç·’: {'âœ… æ˜¯' if rf_ready else 'âŒ å¦'}")
        
        return True
        
    except Exception as e:
        print(f"âŒ AIæ¨¡å‹è©•ä¼°æ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_report_generation():
    """æ¸¬è©¦5: å ±å‘Šç”ŸæˆåŠŸèƒ½"""
    print("\nğŸ§ª æ¸¬è©¦5: å ±å‘Šç”ŸæˆåŠŸèƒ½")
    print("-" * 50)
    
    try:
        from flow_analyzer import SimplifiedTrafficAnalyzer
        
        analyzer = SimplifiedTrafficAnalyzer()
        
        if not analyzer.load_data(sample_rate=0.3):
            print("âš ï¸ ç„¡æ•¸æ“šå¯ç”Ÿæˆå ±å‘Šï¼Œè·³éæ­¤æ¸¬è©¦")
            return True
        
        # åŸ·è¡Œå®Œæ•´åˆ†æä¸¦ç”Ÿæˆå ±å‘Š
        start_time = time.time()
        report = analyzer.generate_comprehensive_report()
        report_time = time.time() - start_time
        
        print(f"âœ… ç¶œåˆå ±å‘Šç”Ÿæˆå®Œæˆ")
        print(f"   ç”Ÿæˆæ™‚é–“: {report_time:.2f} ç§’")
        
        # æª¢æŸ¥å ±å‘Šçµæ§‹
        required_sections = [
            'metadata', 'data_summary', 'quality_assessment',
            'time_coverage', 'prediction_readiness', 'ai_model_evaluation',
            'key_insights', 'actionable_recommendations'
        ]
        
        missing_sections = []
        for section in required_sections:
            if section in report:
                print(f"   âœ… {section} ç« ç¯€å®Œæˆ")
            else:
                print(f"   âŒ {section} ç« ç¯€ç¼ºå¤±")
                missing_sections.append(section)
        
        # é¡¯ç¤ºå ±å‘Šæ‘˜è¦
        metadata = report.get('metadata', {})
        insights_count = metadata.get('total_insights', 0)
        
        print(f"ğŸ“‹ å ±å‘Šæ‘˜è¦:")
        print(f"   åˆ†ææ™‚é–“: {metadata.get('analysis_date', 'N/A')}")
        print(f"   æ´å¯Ÿæ•¸é‡: {insights_count}")
        print(f"   ç‰ˆæœ¬: {metadata.get('analyzer_version', 'N/A')}")
        
        # æ¸¬è©¦å ±å‘Šä¿å­˜
        try:
            test_filename = f"test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            analyzer.save_report(report, test_filename)
            print(f"   âœ… å ±å‘Šä¿å­˜æˆåŠŸ: {test_filename}")
        except Exception as save_error:
            print(f"   âŒ å ±å‘Šä¿å­˜å¤±æ•—: {save_error}")
            return False
        
        return len(missing_sections) == 0
        
    except Exception as e:
        print(f"âŒ å ±å‘Šç”Ÿæˆæ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_quick_analyze_function():
    """æ¸¬è©¦6: å¿«é€Ÿåˆ†æå‡½æ•¸"""
    print("\nğŸ§ª æ¸¬è©¦6: å¿«é€Ÿåˆ†æå‡½æ•¸")
    print("-" * 50)
    
    try:
        from flow_analyzer import quick_analyze
        
        print("ğŸš€ åŸ·è¡Œå¿«é€Ÿåˆ†æ...")
        start_time = time.time()
        result = quick_analyze(sample_rate=0.2)  # ä½¿ç”¨20%æ¡æ¨£åŠ é€Ÿ
        total_time = time.time() - start_time
        
        if result:
            print(f"âœ… å¿«é€Ÿåˆ†ææˆåŠŸ")
            print(f"   ç¸½åŸ·è¡Œæ™‚é–“: {total_time:.2f} ç§’")
            
            # æª¢æŸ¥è¿”å›çµæœ
            required_keys = ['metadata', 'ai_model_evaluation', 'prediction_readiness']
            
            missing_keys = []
            for key in required_keys:
                if key in result:
                    print(f"   âœ… {key} çµæœå®Œæ•´")
                else:
                    print(f"   âŒ {key} çµæœç¼ºå¤±")
                    missing_keys.append(key)
            
            # é¡¯ç¤ºé—œéµçµæœ
            ai_eval = result.get('ai_model_evaluation', {})
            if ai_eval:
                recommendations = ai_eval.get('recommendations', [])
                if recommendations:
                    top_model = recommendations[0]
                    print(f"ğŸ¯ å¿«é€Ÿåˆ†æçµæœ:")
                    print(f"   æ¨è–¦æ¨¡å‹: {top_model.get('model', 'N/A')}")
                    print(f"   æ¨è–¦è©•åˆ†: {top_model.get('score', 0):.1f}")
                    print(f"   é æœŸæº–ç¢ºç‡: {top_model.get('expected_accuracy', 'N/A')}")
            
            return len(missing_keys) == 0
        else:
            print("âŒ å¿«é€Ÿåˆ†æè¿”å›ç©ºçµæœ")
            return False
            
    except Exception as e:
        print(f"âŒ å¿«é€Ÿåˆ†ææ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_performance_benchmark():
    """æ¸¬è©¦7: æ€§èƒ½åŸºæº–æ¸¬è©¦"""
    print("\nğŸ§ª æ¸¬è©¦7: æ€§èƒ½åŸºæº–æ¸¬è©¦")
    print("-" * 50)
    
    try:
        from flow_analyzer import SimplifiedTrafficAnalyzer
        
        print("â±ï¸ åŸ·è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦...")
        
        # è¨˜éŒ„åˆå§‹è¨˜æ†¶é«”
        initial_memory = psutil.virtual_memory().percent
        print(f"   åˆå§‹è¨˜æ†¶é«”: {initial_memory:.1f}%")
        
        # æ¸¬è©¦å¤šæ¬¡é‹è¡Œçš„ä¸€è‡´æ€§å’Œé€Ÿåº¦
        times = []
        
        for i in range(3):
            print(f"   ç¬¬ {i+1} è¼ªæ¸¬è©¦...")
            start_time = time.time()
            
            analyzer = SimplifiedTrafficAnalyzer()
            if analyzer.load_data(sample_rate=0.2):  # ä½¿ç”¨20%æ¡æ¨£åŠ é€Ÿ
                analyzer.analyze_data_characteristics()
                analyzer.evaluate_ai_model_suitability()
                report = analyzer.generate_comprehensive_report()
            
            run_time = time.time() - start_time
            times.append(run_time)
            print(f"      åŸ·è¡Œæ™‚é–“: {run_time:.2f} ç§’")
            
            # æ¸…ç†
            del analyzer
            if 'report' in locals():
                del report
        
        # æ€§èƒ½çµ±è¨ˆ
        if times:
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            
            print(f"ğŸ“Š æ€§èƒ½çµ±è¨ˆ:")
            print(f"   å¹³å‡åŸ·è¡Œæ™‚é–“: {avg_time:.2f} ç§’")
            print(f"   æœ€å¿«åŸ·è¡Œæ™‚é–“: {min_time:.2f} ç§’")
            print(f"   æœ€æ…¢åŸ·è¡Œæ™‚é–“: {max_time:.2f} ç§’")
            print(f"   æ€§èƒ½ç©©å®šæ€§: {((max_time - min_time) / avg_time * 100):.1f}% è®Šç•°")
            
            # æ€§èƒ½è©•ç´š
            if avg_time < 10:
                performance_grade = "ğŸš€ å„ªç§€"
            elif avg_time < 20:
                performance_grade = "âœ… è‰¯å¥½"
            elif avg_time < 40:
                performance_grade = "âš¡ å¯æ¥å—"
            else:
                performance_grade = "âš ï¸ éœ€å„ªåŒ–"
            
            print(f"   æ€§èƒ½è©•ç´š: {performance_grade}")
            
            return avg_time < 60  # 60ç§’å…§å®Œæˆç®—é€šé
        else:
            print("âŒ ç„¡æ³•å®Œæˆæ€§èƒ½æ¸¬è©¦")
            return False
            
    except Exception as e:
        print(f"âŒ æ€§èƒ½æ¸¬è©¦å¤±æ•—: {e}")
        return False


def generate_test_summary(test_results):
    """ç”Ÿæˆæ¸¬è©¦æ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸ“‹ ç°¡åŒ–ç‰ˆäº¤é€šåˆ†æå™¨æ¸¬è©¦æ‘˜è¦")
    print("="*60)
    
    passed_tests = sum(1 for result in test_results if result[1])
    total_tests = len(test_results)
    
    print(f"ğŸ“Š æ¸¬è©¦çµ±è¨ˆ:")
    print(f"   ç¸½æ¸¬è©¦é …ç›®: {total_tests}")
    print(f"   é€šéæ¸¬è©¦: {passed_tests}")
    print(f"   æˆåŠŸç‡: {passed_tests/total_tests*100:.1f}%")
    
    # ç³»çµ±ç‹€æ…‹
    memory = psutil.virtual_memory()
    print(f"\nğŸ’» ç•¶å‰ç³»çµ±ç‹€æ…‹:")
    print(f"   è¨˜æ†¶é«”ä½¿ç”¨: {memory.percent:.1f}%")
    print(f"   å¯ç”¨è¨˜æ†¶é«”: {memory.available/(1024**3):.1f}GB")
    
    # è©³ç´°çµæœ
    print(f"\nğŸ“‹ è©³ç´°çµæœ:")
    for test_name, success in test_results:
        status = "âœ… é€šé" if success else "âŒ å¤±æ•—"
        print(f"   â€¢ {test_name}: {status}")
    
    if passed_tests == total_tests:
        print(f"\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼ç°¡åŒ–ç‰ˆåˆ†æå™¨é‹è¡Œæ­£å¸¸ï¼")
        
        print(f"\nğŸ”§ ç°¡åŒ–ç‰ˆç‰¹è‰²:")
        print("   âœ… ç¨‹å¼ç¢¼å¤§å¹…ç°¡åŒ–ï¼Œä¿ç•™æ ¸å¿ƒåŠŸèƒ½")
        print("   âœ… AIæ¨¡å‹æ™ºèƒ½æ¨è–¦ç³»çµ±")
        print("   âœ… å¿«é€Ÿåˆ†æåŠŸèƒ½")
        print("   âœ… æ€§èƒ½å„ªåŒ–")
        
        print(f"\nğŸ¯ æ¨è–¦ä½¿ç”¨æ–¹å¼:")
        print("   1. å¿«é€Ÿåˆ†æ: quick_analyze()")
        print("   2. è©³ç´°åˆ†æ: SimplifiedTrafficAnalyzer()")
        print("   3. æ¨¡å‹é¸æ“‡: åƒè€ƒAIæ¨¡å‹æ¨è–¦çµæœ")
        
        print(f"\nğŸ“ˆ ä¸‹ä¸€æ­¥å»ºè­°:")
        print("   1. ä½¿ç”¨æ¨è–¦çš„AIæ¨¡å‹é–‹å§‹è¨“ç·´")
        print("   2. é–‹ç™¼é æ¸¬ç³»çµ±")
        print("   3. å»ºç«‹ç›£æ§å’Œè©•ä¼°æ©Ÿåˆ¶")
        
        return True
    else:
        failed_count = total_tests - passed_tests
        print(f"\nâŒ æœ‰ {failed_count} å€‹æ¸¬è©¦å¤±æ•—")
        print("   å»ºè­°æª¢æŸ¥ç›¸é—œåŠŸèƒ½å¾Œå†ä½¿ç”¨")
        return False


def main():
    """ä¸»æ¸¬è©¦ç¨‹åº"""
    print("ğŸ§ª ç°¡åŒ–ç‰ˆäº¤é€šæµé‡åˆ†æå™¨æ¸¬è©¦")
    print("=" * 60)
    print("ğŸ¯ æ ¸å¿ƒæ¸¬è©¦å…§å®¹:")
    print("â€¢ æ•¸æ“šè¼‰å…¥å’Œåˆ†æ")
    print("â€¢ AIæ¨¡å‹è©•ä¼°å’Œæ¨è–¦") 
    print("â€¢ å ±å‘Šç”Ÿæˆ")
    print("â€¢ æ€§èƒ½åŸºæº–æ¸¬è©¦")
    print("=" * 60)
    
    start_time = datetime.now()
    
    # é¡¯ç¤ºæ¸¬è©¦ç’°å¢ƒ
    memory = psutil.virtual_memory()
    print(f"\nğŸ’» æ¸¬è©¦ç’°å¢ƒ:")
    print(f"   è¨˜æ†¶é«”ä½¿ç”¨: {memory.percent:.1f}%")
    print(f"   å¯ç”¨è¨˜æ†¶é«”: {memory.available/(1024**3):.1f}GB")
    print(f"   ç¸½è¨˜æ†¶é«”: {memory.total/(1024**3):.1f}GB")
    
    # åŸ·è¡Œæ¸¬è©¦åºåˆ—
    test_results = []
    
    # åŸºç¤åŠŸèƒ½æ¸¬è©¦
    success = test_analyzer_import()
    test_results.append(("åˆ†æå™¨å°å…¥", success))
    
    if success:
        # æ ¸å¿ƒåŠŸèƒ½æ¸¬è©¦
        success = test_data_loading()
        test_results.append(("æ•¸æ“šè¼‰å…¥", success))
        
        success = test_data_analysis()
        test_results.append(("æ•¸æ“šç‰¹æ€§åˆ†æ", success))
        
        success = test_ai_model_evaluation()
        test_results.append(("AIæ¨¡å‹è©•ä¼°", success))
        
        success = test_report_generation()
        test_results.append(("å ±å‘Šç”Ÿæˆ", success))
        
        success = test_quick_analyze_function()
        test_results.append(("å¿«é€Ÿåˆ†æå‡½æ•¸", success))
        
        success = test_performance_benchmark()
        test_results.append(("æ€§èƒ½åŸºæº–æ¸¬è©¦", success))
    
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    # ç”Ÿæˆæ¸¬è©¦æ‘˜è¦
    all_passed = generate_test_summary(test_results)
    
    print(f"\nâ±ï¸ ç¸½æ¸¬è©¦æ™‚é–“: {duration:.1f} ç§’")
    
    if all_passed:
        print(f"\nâœ… ç°¡åŒ–ç‰ˆåˆ†æå™¨å·²æº–å‚™å°±ç·’ï¼")
        print(f"\nğŸš€ å¯ä»¥é–‹å§‹ä½¿ç”¨ä»¥ä¸‹åŠŸèƒ½:")
        print(f"   â€¢ å¿«é€Ÿåˆ†æ: python -c \"from src.flow_analyzer import quick_analyze; quick_analyze()\"")
        print(f"   â€¢ æŸ¥çœ‹AIæ¨¡å‹æ¨è–¦")
        print(f"   â€¢ ç”Ÿæˆåˆ†æå ±å‘Š")
        return True
    else:
        print(f"\nâŒ æ¸¬è©¦æœªå®Œå…¨é€šéï¼Œè«‹æª¢æŸ¥ç›¸é—œåŠŸèƒ½")
        return False


if __name__ == "__main__":
    main()